<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>使用Python对淘宝用户行为进行数据分析</title>
    <url>/2020/06/18/%E4%BD%BF%E7%94%A8Python%E5%AF%B9%E6%B7%98%E5%AE%9D%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200429154952128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>


<h1 id="1-分析背景与意义"><a href="#1-分析背景与意义" class="headerlink" title="1  分析背景与意义"></a>1  分析背景与意义</h1><p>淘宝网是中国深受欢迎的网购零售平台，拥有近5亿的注册用户数，每天有超过6000万的固定访客，同时每天的在线商品数已经超过了8亿件，平均每分钟售出4.8万件商品。<br>用户行为分析则是电商平台的重要事务，通过对用户行为的分析，有助于企业根据用户的行为习惯，找出网站、推广渠道等企业营销环境存在的问题，从而让企业的营销更加精准、有效，提升企业的广告收益。</p>
<h1 id="2-分析思路"><a href="#2-分析思路" class="headerlink" title="2  分析思路"></a>2  分析思路</h1><p>针对数据集中的用户、商品、商品种类、用户行为、时间等信息，使用Python对数据进行切片分类汇总等多种数据分析手段，从不同角度挖掘蕴含的价值。本次通过以下四个方向探索淘宝用户行为：<br><img src="https://img-blog.csdnimg.cn/20200428165245175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="3-分析内容"><a href="#3-分析内容" class="headerlink" title="3  分析内容"></a>3  分析内容</h1><h2 id="3-1-提出问题"><a href="#3-1-提出问题" class="headerlink" title="3.1  提出问题"></a>3.1  提出问题</h2><p>本次通过对淘宝用户行为数据分析，期望解决以下业务问题：</p>
<p> 1） 用户从浏览到最终购买整个过程的流失情况，确定夹点位置。<br> 2） 找出用户最活跃的日期以及活跃时间段，了解用户的行为时间模式。<br> 3） 找出最具价值的核心付费用户群。<br> 4） 找出最受用户青睐的产品。</p>
<h2 id="3-2-理解数据"><a href="#3-2-理解数据" class="headerlink" title="3.2  理解数据"></a>3.2  理解数据</h2><p>数据集：UserBehavior.csv。本次报告随机采集了在2017年11月25日至2017年12月3日之间，淘宝用户的行为，其中行为包括浏览、加购物车、收藏、购买等。数据集主要包含：用户数量约3万（37,376），商品数量约9万（930,607），商品类目数量7106以及总的淘宝用户行为记录数量为3百万（3,835,329）。<br>数据来源：<a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=649&amp;userId=1" target="_blank" rel="noopener">https://tianchi.aliyun.com/dataset/dataDetail?dataId=649&amp;userId=1</a><br>字段含义：<br>| 列名称 | 说明 |<br>|–|–|<br>|User ID  | 整数类型，序列化后的用户ID |<br>|Item ID| 整数类型，序列化后的商品ID |<br>|Category ID | 整数类型，序列化后的商品所属类目ID |<br>|Behavior type  | 字符串，枚举类型，包括(‘pv’, ‘buy’, ‘cart’, ‘fav’) |<br>|Timestamp | 行为发生的时间戳 |</p>
<p>用户行为类型共有四种，它们分别是：</p>
<table>
<thead>
<tr>
<th>行为类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>pv</td>
<td>商品详情页pv，等价于点击</td>
</tr>
<tr>
<td>buy</td>
<td>商品购买</td>
</tr>
<tr>
<td>cart</td>
<td>将商品加入购物车</td>
</tr>
<tr>
<td>fav</td>
<td>收藏商品</td>
</tr>
</tbody></table>
<h2 id="3-3-数据清洗"><a href="#3-3-数据清洗" class="headerlink" title="3.3  数据清洗"></a>3.3  数据清洗</h2><h3 id="3-3-1-数据导入"><a href="#3-3-1-数据导入" class="headerlink" title="3.3.1 数据导入"></a>3.3.1 数据导入</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]</span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">path = <span class="string">'./data/UserBehavior.csv'</span></span><br><span class="line">data_user = pd.read_csv(path)</span><br><span class="line">cols = [<span class="string">'UserID'</span>, <span class="string">'ItemID'</span>, <span class="string">'CatogoryID'</span>, <span class="string">'BehaviorType'</span>, <span class="string">'TimeStamps'</span>]</span><br><span class="line">data_user.columns = cols</span><br><span class="line">data_user.head()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200428182653709.PNG" alt="UserID    ItemID    CatogoryID    BehaviorType    TimeStamps
0    1    2333346    2520771    pv    1.511562e+09
1    1    2576651    149192    pv    1.511573e+09
2    1    3830808    4181361    pv    1.511593e+09
3    1    4365585    2520377    pv    1.511596e+09
4    1    4606018    2735466    pv    1.511616e+09"></p>
<h3 id="3-3-2-缺失值分析"><a href="#3-3-2-缺失值分析" class="headerlink" title="3.3.2 缺失值分析"></a>3.3.2 缺失值分析</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_user.apply(<span class="keyword">lambda</span> x: sum(x.isnull()))</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200428182746692.PNG" alt="UserID          0
ItemID          0
CatogoryID      0
BehaviorType    0
TimeStamps      1
dtype: int64"></p>
<p>仅一条数据含有缺失值，删除即可。</p>
<h3 id="3-3-3-选取时间范围"><a href="#3-3-3-选取时间范围" class="headerlink" title="3.3.3 选取时间范围"></a>3.3.3 选取时间范围</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_unixtime</span><span class="params">(timeStr)</span>:</span></span><br><span class="line">    formatStr = <span class="string">"%Y-%m-%d %H:%M:%S"</span></span><br><span class="line">    tmObject = time.strptime(timeStr, formatStr)</span><br><span class="line">    tmStamp = time.mktime(tmObject)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> int(tmStamp)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 数据集描述的时间范围</span></span><br><span class="line">startTime = get_unixtime(<span class="string">"2017-11-25 00:00:00"</span>)</span><br><span class="line">endTime = get_unixtime(<span class="string">"2017-12-3 23:59:59"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选出符合时间范围的数据</span></span><br><span class="line">data_user[<span class="string">'TimeStamps'</span>] = data_user[<span class="string">'TimeStamps'</span>].astype(<span class="string">'int64'</span>)</span><br><span class="line">data_user = data_user.loc[(data_user[<span class="string">'TimeStamps'</span>] &gt;= startTime) &amp; (data_user[<span class="string">'TimeStamps'</span>] &lt;= endTime)]</span><br></pre></td></tr></table></figure>

<h3 id="3-3-4-时间格式处理"><a href="#3-3-4-时间格式处理" class="headerlink" title="3.3.4 时间格式处理"></a>3.3.4 时间格式处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#时间处理</span></span><br><span class="line">data_user[<span class="string">'time'</span>] = data_user[<span class="string">'TimeStamps'</span>].apply(<span class="keyword">lambda</span> t: time.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>, time.localtime(t)))</span><br><span class="line">data_user[<span class="string">'date'</span>] = data_user[<span class="string">'time'</span>].str[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">data_user[<span class="string">'hour'</span>] = data_user[<span class="string">'time'</span>].str[<span class="number">11</span>:<span class="number">13</span>].astype(int)</span><br><span class="line">data_user[<span class="string">'date'</span>] = pd.to_datetime(data_user[<span class="string">'date'</span>])</span><br><span class="line"></span><br><span class="line">data_user.head()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200428182859412.PNG" alt="在这里插入图片描述"></p>
<h2 id="3-4-构建模型"><a href="#3-4-构建模型" class="headerlink" title="3.4 构建模型"></a>3.4 构建模型</h2><h3 id="3-4-1-用户行为转化（AARRR模型）"><a href="#3-4-1-用户行为转化（AARRR模型）" class="headerlink" title="3.4.1 用户行为转化（AARRR模型）"></a>3.4.1 用户行为转化（AARRR模型）</h3><p><strong>跳失率计算：</strong><br>跳失率 = 只浏览一个页面就离开的访问次数 / 该页面的全部访问次数<br>结果显示只有点击行为没有收藏、加购物车以及购买行为的总用户数是2196，除以总用户数37376得到跳失率为5.88%。说明用户对商品详情页的关注很大，商品详情页的商品描述，细节等吸引点不足，是流失用户的的重要原因之一。具体造成用户在浏览商品详情页后流失的原因，要根据实际情况分析，建议可以采用在线问卷调查的方式get用户的痛点，针对性调整。</p>
<p><strong>日ARPPU计算：</strong><br>ARPPU全称为Average Revenue Per Paying User，也就是每付费用户平均收益。这个指标考核的是某时间段内平均每个付费用户为应用创造的收入。在用户数量上，ARPPU只考虑某一时间段内的付费用户，而非该时间段内所有的活跃用户。<br>对于同一时间的同一应用而言，ARPPU的数值会明显高于ARPU。<br>ARPPU能够反映付费用户为你的应用带来了多少收益，显示出一个忠诚付费用户实际上愿意支付的金额。同时，这个指标也可以显示用户对一些付费项目的反应。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_user_buy1 = data_user[data_user.BehaviorType == <span class="string">'buy'</span>].groupby([<span class="string">'date'</span>,<span class="string">'UserID'</span>]).count()[<span class="string">'BehaviorType'</span>].reset_index().rename(columns=&#123;<span class="string">'BehaviorType'</span>:<span class="string">'total'</span>&#125;)</span><br><span class="line"></span><br><span class="line">data_user_buy2 = data_user_buy1.groupby(<span class="string">'date'</span>).sum()[<span class="string">'total'</span>] / data_user_buy1.groupby(<span class="string">'date'</span>).count()[<span class="string">'total'</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">data_user_buy2.plot()</span><br><span class="line">plt.ylabel(<span class="string">'日ARPPU'</span>)</span><br><span class="line">plt.title(<span class="string">'ARPPU变化情况'</span>)</span><br><span class="line">plt.savefig(<span class="string">'ARPPU变化情况'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200428195148932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt=""><br><img src="https://img-blog.csdnimg.cn/20200428195401501.PNG" alt="在这里插入图片描述"><br>由图像可以看出，在12月2日及12月3日的日ARPPU为最低位，分析可能是由于高的PV值但实际消费的用户数并不多。</p>
<p><strong>日ARPU计算：</strong><br>ARPU的全称是Average Revenue Per User，也就是每用户平均收入。这个指标计算的是某时间段内平均每个活跃用户为应用创造的收入。<br>ARPU的计算中，所有的用户都被纳入了计算范围——无论是付费用户或非付费用户。ARPU是评估应用变现有效性的指标：ARPU越高，就代表用户在这段时间内为应用带来的变现收入就越多。<br>ARPU可用于评估应用中的变动是否能有效提升变现收益：如果ARPU提升，证明应用的变动有利于提升应用变现收益；如果ARPU不升反降，应用开发者可能就需要确认一下变动的有效性了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_user[<span class="string">'operation'</span>] = <span class="number">1</span></span><br><span class="line">data_user_buy2 = data_user.groupby([<span class="string">'date'</span>, <span class="string">'UserID'</span>, <span class="string">'BehaviorType'</span>])[<span class="string">'operation'</span>].count().reset_index().rename(columns = &#123;<span class="string">'operation'</span>:<span class="string">'total'</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#每天消费总次数/每天总活跃人数</span></span><br><span class="line">data_user_buy2.groupby(<span class="string">'date'</span>).apply(<span class="keyword">lambda</span> x: x[x[<span class="string">'BehaviorType'</span>] == <span class="string">'buy'</span>].total.sum()/len(x.UserID.unique()) ).plot()</span><br><span class="line">plt.ylabel(<span class="string">'日ARPU'</span>)</span><br><span class="line">plt.title(<span class="string">'ARPU变化情况'</span>)</span><br><span class="line">plt.savefig(<span class="string">'ARPU变化情况'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200429160428770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#（付费率）每天消费人数/每天总活跃人数</span></span><br><span class="line">data_user_buy2.groupby(<span class="string">'date'</span>).apply(<span class="keyword">lambda</span> x: x[x[<span class="string">'BehaviorType'</span>] == <span class="string">'buy'</span>].total.count()/len(x.UserID.unique()) ).plot()</span><br><span class="line">plt.ylabel(<span class="string">'付费率'</span>)</span><br><span class="line">plt.title(<span class="string">'付费率变化情况'</span>)</span><br><span class="line">plt.savefig(<span class="string">'付费率变化情况'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200429160413221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>日ARPU图像、付费率图像相似，均在12月2日和12月3日处于低位，而在工作日处于较高的水平。</p>
<p><strong>用户行为情况</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 多子图绘制 如：将上面用到的图形一起绘制</span></span><br><span class="line"><span class="comment"># 导入subplots（类似matplotlib）</span></span><br><span class="line"><span class="keyword">from</span> plotly.subplots <span class="keyword">import</span> make_subplots</span><br><span class="line"></span><br><span class="line">labels = df_userbehavior[<span class="string">'behavior'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create subplots: use 'domain' type for Pie subplot</span></span><br><span class="line">fig = make_subplots(rows=<span class="number">1</span>, cols=<span class="number">2</span>, specs=[[&#123;<span class="string">'type'</span>:<span class="string">'domain'</span>&#125;, &#123;<span class="string">'type'</span>:<span class="string">'domain'</span>&#125;]])</span><br><span class="line">fig.add_trace(go.Pie(labels=labels, values=data_user_count.values, name=<span class="string">"淘宝用户行为"</span>),</span><br><span class="line">              <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">fig.add_trace(go.Pie(labels=labels, values=df_userbehavior[<span class="string">'count'</span>], name=<span class="string">"淘宝独立用户行为"</span>),</span><br><span class="line">              <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use `hole` to create a donut-like pie chart</span></span><br><span class="line">fig.update_traces(hole=<span class="number">.4</span>, hoverinfo=<span class="string">"label+percent+name"</span>)</span><br><span class="line"></span><br><span class="line">fig.update_layout(</span><br><span class="line">    title_text=<span class="string">"淘宝用户行为情况 | 左：淘宝用户行为， 右：淘宝独立用户行为"</span>,</span><br><span class="line">    <span class="comment"># Add annotations in the center of the donut pies.</span></span><br><span class="line">    annotations=[dict(text=<span class="string">'非独立'</span>, x=<span class="number">0.18</span>, y=<span class="number">0.5</span>, font_size=<span class="number">20</span>, showarrow=<span class="literal">False</span>),</span><br><span class="line">                 dict(text=<span class="string">'独立'</span>, x=<span class="number">0.8</span>, y=<span class="number">0.5</span>, font_size=<span class="number">20</span>, showarrow=<span class="literal">False</span>)])</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200430152910340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>用户点击行为占总行为数的89.5%，收藏和加购行为加起来的行为数只占总行为数的8.47%，而对于独立用户来说，点击行为的占比明显缩小为35.2%。推测用户可能在挑选产品环节浪费了较多的时间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Funnel</span><br><span class="line"><span class="keyword">from</span> pyecharts.faker <span class="keyword">import</span> Faker</span><br><span class="line"></span><br><span class="line">attr = [<span class="string">'浏览'</span>, <span class="string">'放入购物车'</span>, <span class="string">'收藏'</span>, <span class="string">'购买'</span>]</span><br><span class="line">value = [<span class="number">3431904</span>, <span class="number">213634</span>, <span class="number">111140</span>, <span class="number">76707</span>]    <span class="comment">#这里有个bug</span></span><br><span class="line">funnel = Funnel()</span><br><span class="line">funnel.add(<span class="string">"淘宝用户行为"</span>, [list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)])</span><br><span class="line">funnel.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"淘宝用户行为"</span>))</span><br><span class="line">funnel.render(<span class="string">"funnel_base.html"</span>) </span><br><span class="line">funnel.render_notebook()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200429202820614.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<table>
<thead>
<tr>
<th>项目</th>
<th>流失率</th>
</tr>
</thead>
<tbody><tr>
<td>pv_to_cart</td>
<td>93.78%</td>
</tr>
<tr>
<td>cart_to_fav</td>
<td>47.98%</td>
</tr>
<tr>
<td>fav_to_buy</td>
<td>30.98%</td>
</tr>
<tr>
<td>pv_to_buy</td>
<td>97.76%</td>
</tr>
</tbody></table>
<p>从点击到购买的全过程中，流失率主要集中在点击到加入购物车这一环节，流失率高达93.78%，收藏及加入购物车后购买商品的可能性增大。</p>
<p><strong>用户留存率</strong><br>留存用户：在某段时间开始使用产品，经过一段时间后仍然继续使用产品的用户，即为留存用户。<br>留存率=仍旧使用产品的用户量/最初的总用户量。<br>根据时间维度进行分类，留存率经常分为次日留存、3日留存、7日留存以及30日留存等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立n日留存率计算函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_retention</span><span class="params">(data,n)</span>:</span> <span class="comment">#n为n日留存</span></span><br><span class="line">    user=[]</span><br><span class="line">    date=pd.Series(data.date.unique()).sort_values()[:-n] <span class="comment">#时间截取至最后一天的前n天</span></span><br><span class="line">    retention_rates=[]</span><br><span class="line">    new_users=[]</span><br><span class="line">    retention_user=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> date:</span><br><span class="line">        new_user=set(data[data.date==i].UserID.unique())-set(user) <span class="comment">#识别新用户，本案例中设初始用户量为零</span></span><br><span class="line">        user.extend(new_user)  <span class="comment">#将新用户加入用户群中</span></span><br><span class="line">        <span class="comment">#第n天留存情况</span></span><br><span class="line">        user_nday=data[data.date==i+timedelta(n)].UserID.unique() <span class="comment">#第n天登录的用户情况</span></span><br><span class="line">        a=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> UserID <span class="keyword">in</span> user_nday:</span><br><span class="line">            <span class="keyword">if</span> UserID <span class="keyword">in</span> new_user:</span><br><span class="line">                a+=<span class="number">1</span></span><br><span class="line">        b = len(new_user)</span><br><span class="line">        retention_rate=a/b <span class="comment">#计算该天第n日留存率</span></span><br><span class="line">        retention_rates.append(retention_rate) <span class="comment">#汇总n日留存数据</span></span><br><span class="line">        new_users.append(b) <span class="comment">#汇总n日的新用户数</span></span><br><span class="line">        retention_user.append(a) <span class="comment">#汇总n日留存的用户数</span></span><br><span class="line">    data_new_user = pd.Series(new_users, index=date)</span><br><span class="line">    data_retention_user = pd.Series(retention_user, index=date)</span><br><span class="line">    data_retention_rate = pd.Series(retention_rates,index=date)</span><br><span class="line">    data_retention = pd.concat([data_new_user,data_retention_user,data_retention_rate], axis=<span class="number">1</span>)</span><br><span class="line">    data_retention.columns=[<span class="string">'new_user'</span>,<span class="string">'retention_user'</span>,<span class="string">'retention_rate'</span>]</span><br><span class="line">    <span class="keyword">return</span> data_retention</span><br><span class="line"></span><br><span class="line">data_retention1=cal_retention(data_user,<span class="number">1</span>)</span><br><span class="line">data_retention2=cal_retention(data_user,<span class="number">2</span>)</span><br><span class="line">data_retention6=cal_retention(data_user,<span class="number">6</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429202657966.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>用户的次日留存率及3日留存率均约为60%-70%的范围内，现有数据可以看出7日的留存率较高，推测是由于临近双十二，商家纷纷举办活动，促使留存率提高。可继续观测留存率等指标，以确定留存率的变化规律。</p>
<p><strong>复购</strong><br><img src="https://img-blog.csdnimg.cn/20200429160546213.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200429144949479.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_rebuy[data_rebuy&gt;=<span class="number">2</span>].count()/data_rebuy.count()</span><br></pre></td></tr></table></figure>
<p>复购率=54.94%<br><img src="https://img-blog.csdnimg.cn/20200429221206329.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200429221828232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>淘宝平台和用户的粘性很高，9日内的复购率达到54.94%。但有的用户购买次数高达到84次。9天里有84次的购买行为，平均一天有9次购买行为，这不符合常理，为什么他们的购买次数如此高呢？是否存在刷单现象？进一步分析验证购买次数较高的用户平时购买情况，以及账户，购物，物流等信息才能判断。这里数据有限，不深入探究其原由。</p>
<h3 id="3-4-2-用户活跃时间"><a href="#3-4-2-用户活跃时间" class="headerlink" title="3.4.2 用户活跃时间"></a>3.4.2 用户活跃时间</h3><p>找出用户最活跃的日期以及活跃时间段，了解用户的行为时间模式。</p>
<p> <strong>按日统计流量指标</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pv_daily = data_user.groupby(<span class="string">'date'</span>).count()[<span class="string">'UserID'</span>]</span><br><span class="line">uv_daily = data_user.groupby(<span class="string">'date'</span>)[<span class="string">'UserID'</span>].apply(<span class="keyword">lambda</span> x: x.drop_duplicates().count())</span><br><span class="line"></span><br><span class="line">pv_uv_daily = pd.concat([pv_daily,uv_daily], axis=<span class="number">1</span>)</span><br><span class="line">pv_uv_daily.columns=[<span class="string">'pv'</span>,<span class="string">'uv'</span>]</span><br><span class="line">pv_uv_daily</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200428182946544.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428183309451.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2020042818371289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>可以发现，PV与UV的每日变化趋势大致相同：工作日维持在低值，其中周二（11-27）的访问量达到统计范围内最低值；而11月25日、11月26日和12月2日、12月3日同为周末，但后者却有更多的活跃用户，环比增长率约为32%，推测可能是平台做促销活动。检索可知正值“双十二”前夕，各类预热活动促进用户访问增长。</p>
<p><strong>按小时统计流量指标</strong><br><img src="https://img-blog.csdnimg.cn/20200428183945718.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428183945615.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428184115560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428185100247.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>结合人们日常作息规律，0点至6点是休息时间，点击量处于低谷阶段；6点至10点，人们慢慢开始工作，点击量开始回暖；10点至18点为正常工作时间，点击量保持平稳；18点至20点，人们相继下班休息，点击量不断升高；在21点至22点期间，点击量到达高峰。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数值</th>
</tr>
</thead>
<tbody><tr>
<td>pv</td>
<td>3833385</td>
</tr>
<tr>
<td>uv</td>
<td>264304</td>
</tr>
<tr>
<td>pv/uv</td>
<td>14.50</td>
</tr>
</tbody></table>
<h3 id="3-4-3-用户价值分析（RFM模型）"><a href="#3-4-3-用户价值分析（RFM模型）" class="headerlink" title="3.4.3 用户价值分析（RFM模型）"></a>3.4.3 用户价值分析（RFM模型）</h3><p>因为本数据集没有提供M（消费金额）列，因此只能通过R（最近一次购买时间）和F（消费频率）的数据对客户价值进行打分。<br>|RFM|业务含义|1分|2分|<br>|–|–|–|–|<br>|R|最近交易日期与2017.12.4距离天数|3<del>9|0</del>3|<br>|F|购买次数|0<del>2|2</del>84|<br>其中，<br>RF=11为重要挽回客户；<br>RF=12为重要唤回客户；<br>RF=21为重要深耕客户：<br>RF=22为重要价值客户。</p>
<p><img src="https://img-blog.csdnimg.cn/20200429205729118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trace_basic = [go.Bar(x = rfm[<span class="string">'rank'</span>].value_counts().index,</span><br><span class="line">                     y = rfm[<span class="string">'rank'</span>].value_counts().values,</span><br><span class="line">                     marker = dict(color=<span class="string">'orange'</span>), opacity=<span class="number">0.50</span>)]</span><br><span class="line">layout = go.Layout(title=<span class="string">'用户等级情况'</span>, xaxis=dict(title=<span class="string">'用户重要度'</span>))</span><br><span class="line">figure_basic = go.Figure(data=trace_basic, layout=layout)</span><br><span class="line">figure_basic</span><br><span class="line"></span><br><span class="line">trace = [go.Pie(labels=rfm[<span class="string">'rank'</span>].value_counts().index,</span><br><span class="line">                values = rfm[<span class="string">'rank'</span>].value_counts().values,</span><br><span class="line">               textfont = dict(size=<span class="number">12</span>,color=<span class="string">'white'</span>))]</span><br><span class="line">layout = go.Layout(title=<span class="string">'用户等级比例'</span>)</span><br><span class="line">figure_pie = go.Figure(data=trace, layout=layout)</span><br><span class="line">figure_pie</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429134429735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200429134429728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-4-4-用户产品偏好"><a href="#3-4-4-用户产品偏好" class="headerlink" title="3.4.4 用户产品偏好"></a>3.4.4 用户产品偏好</h3><p><strong>商品</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>,<span class="number">12</span>))</span><br><span class="line"><span class="comment">#柱形图</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">ax1.bar(data_item_count.index, data_item_count.values)</span><br><span class="line"><span class="keyword">for</span> a,b <span class="keyword">in</span> zip(data_item_count.index,data_item_count.values):</span><br><span class="line">    plt.text(a, b+<span class="number">100</span>,<span class="string">'%s'</span>% b, ha=<span class="string">'center'</span>, va= <span class="string">'bottom'</span>,fontsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#平滑化</span></span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"></span><br><span class="line">x = data_item_count.index</span><br><span class="line">y = df_item_count[<span class="string">'percentage'</span>]</span><br><span class="line">tck = interpolate.splrep(x, y, s=<span class="number">0</span>)</span><br><span class="line">xnew = np.linspace(x.min(),x.max(),<span class="number">100</span>)</span><br><span class="line">ynew = interpolate.splev(xnew, tck, der=<span class="number">0</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">#折线图</span></span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">ax2.plot(xnew, ynew, label=<span class="string">"percentage"</span>, color=<span class="string">'red'</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_ylabel(<span class="string">'商品数目'</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">'所占百分比'</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">'购买次数'</span>)</span><br><span class="line">plt.title(<span class="string">'商品销售分布'</span>, fontsize=<span class="number">25</span>)</span><br><span class="line">plt.savefig(<span class="string">'商品销售分布'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429134737600.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>没有出现购买数量非常集中的商品，说明店铺盈利主要依靠长尾商品的累积效应。在电子商务行业中，相较于传统零售行业成本减少，使得后80%的商品也可以销售出去，并且实现盈利，因此将长尾部分的商品优化推荐好，能够给企业带来更大的收益。</p>
<p><strong>商品种类</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax1 = df_catogory_buy[[<span class="string">'buy'</span>, <span class="string">'fav'</span>, <span class="string">'cart'</span>, <span class="string">'pv'</span>]].plot.bar()</span><br><span class="line"></span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">df_catogory_buy.index = df_catogory_buy.index.astype(str)</span><br><span class="line">ax2.plot(df_catogory_buy.index, df_catogory_buy[[<span class="string">'buy/pv'</span>]])</span><br><span class="line"></span><br><span class="line">ax1.set_ylabel(<span class="string">'次数'</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">'转化率'</span>)</span><br><span class="line">plt.title(<span class="string">'购买次数前二十的商品种类'</span>)</span><br><span class="line">plt.savefig(<span class="string">'购买次数前二十的商品种类'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429134857925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line">fig = px.treemap(</span><br><span class="line">    df_buy, path=[<span class="string">'CatogoryID'</span>], values=<span class="string">'购买次数'</span>, title=<span class="string">'购买次数前二十的商品种类'</span></span><br><span class="line">)</span><br><span class="line">fig.show() </span><br><span class="line"></span><br><span class="line">fig = px.treemap(</span><br><span class="line">    df_item_buy, path=[<span class="string">'CatogoryID'</span>,<span class="string">'ItemID'</span>], values=<span class="string">'count'</span>, title=<span class="string">'商品购买情况(销量前100)'</span></span><br><span class="line">)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429150740642.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200429154952128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="4-结论与建议"><a href="#4-结论与建议" class="headerlink" title="4 结论与建议"></a>4 结论与建议</h1><p>本报告基于AARRR模型和RFM模型，从四个维度提出关于淘宝业务问题。<br><strong>A.  通过AARRR模型分析用户行为转化的各个环节</strong></p>
<p><strong>获取用户（Acquisition）</strong><br>根据12月2日和12月3日活跃用户明显增长，推测在此期间店铺举办了营销活动。检索可知正值“双十二”前夕，各类预热活动促进用户访问增长。<br>获取用户意味着需要拓展页面流量，相对较大型的电商营销活动至少可以从以下三个方面获取流量：</p>
<ul>
<li><input disabled="" type="checkbox"> 充分利用站内资源</li>
<li><input disabled="" type="checkbox"> 跨行合作</li>
<li><input disabled="" type="checkbox"> 产品功能辅助流量增长（场次预约、SNS后置奖品分享）</li>
</ul>
<p><strong>激活用户（Activation）</strong><br>计算跳失率为5.88%，独立访客从浏览到购买的转化率为xxx%，说明产品详情页对用户有着不错的吸引力；但从用户行为转化漏斗来看，用户行为转化夹点位置在点击-加购环节，其中用户点击行为占总行为数的89.50%，而收藏和加购行为加起来的行为数只占总行为数的8.47%，推测用户可能在挑选产品环节浪费了较多的时间，另外低购买意愿转化率还可能与刚完成的双11大促有关。</p>
<p>提高加购转化率的建议：</p>
<ul>
<li><input disabled="" type="checkbox"> 优化搜索引擎，利用用户画像优化商品匹配，个性化地推荐用户感兴趣的商品</li>
<li><input disabled="" type="checkbox"> 优化商品界面加购与收藏按键布局，以便用户触达</li>
<li><input disabled="" type="checkbox"> 分析双十一活动对双十二的影响，合理设置活动内容</li>
</ul>
<p><strong>留存用户（Retention）</strong><br>用户留存其指标之于电商就是回访率。用户的次日留存率及3日留存率均约为60%-70%的范围内，现有数据可以看出7日的留存率较高，推测是由于临近双十二，商家纷纷举办活动，促使留存率提高。<br>活动基本都会划分为三个阶段：</p>
<ul>
<li><input disabled="" type="checkbox"> 预热期：预约造势，通过sns、定金裂变等玩法吸引用户关注</li>
<li><input disabled="" type="checkbox"> 正式期：前面如果证实是好的激励体系，可以让活动健康持续发展</li>
<li><input disabled="" type="checkbox"> 高潮期：进一步引爆高潮，使用的激励方式，成长值会员体系、签到体系、积分任务体系等</li>
</ul>
<p><strong>增加收入（Revenue）</strong><br>在有购买行为的用户中，54.94%的用户选择重复购买。<br>对于用户复购情况，9天内网站有复购现象的用户数接近60%，但是总体上约30%的用户产生了80%的消费次数，复购次数多的用户偏少，可能与双11刚结束，双12未开始的特殊时段有关，建议拉长分析区间分析复购情况。<br>提高收入的建议：</p>
<ul>
<li><input disabled="" type="checkbox"> 开展营销活动，比如淘宝的达成金主的条件限制，鼓励用户复购</li>
<li><input disabled="" type="checkbox"> 在客户发生首购行为后，定时通过客服/短信发放特殊优惠，以提高复购率</li>
<li><input disabled="" type="checkbox"> 优惠券的和优惠策略的在制定时需考虑成本，充分使用推广资金</li>
</ul>
<p><strong>自传播（Refer）</strong><br>通过自传播获取用户的成本很低，而且效果有可能非常好，唯一的前提是产品自身要足够好，有很好的口碑。因此平台需要建立对产品的质量监控机制，如在产品的差评率较高时需对产品进行检测。</p>
<ul>
<li><input disabled="" type="checkbox"> 优化产品，保证产品的质量</li>
<li><input disabled="" type="checkbox"> 提高服务售前及售后质量</li>
</ul>
<p><strong>B.  研究用户时间模式，找到用户在不同时间周期下的活跃规律</strong><br>a)  分析2017年11月25日至12月3日9天里用户每天的点击量：</p>
<p>发现工作日维持在低值，其中周二（11-27）的访问量达到统计范围内最低值；而11月25日、11月26日和12月2日、12月3日同为周末，但后者却有更多的活跃用户，环比增长率约为32%，推测可能是平台做促销活动。检索可知正值“双十二”前夕，各类预热活动促进用户访问增长。</p>
<p>b)  分析2017年11月25日至12月3日9天里用户每时段的点击量：</p>
<p>结合人们日常作息规律，0点至6点是休息时间，点击量处于低谷阶段；6点至10点，人们慢慢开始工作，点击量开始回暖；10点至18点为正常工作时间，点击量保持平稳；18点至20点，人们相继下班休息，点击量不断升高；在21点至22点期间，点击量到达高峰。高峰期用户最活跃，建议商家在用户该时段，经常更新产品信息，黄金展位，活动推荐商品等 。 </p>
<p><strong>C.  通过RFM模型对用户价值分层</strong><br>通过RFM模型分析得到的不同类型的用户，应该采取不同的激励方案。<br>对于RF=22的重要价值客户，应该提高满意度，增加留存。<br>对于RF=21的重要深耕客户，可通过折扣或捆绑销售等活动，提高购买频率。<br>对于RF=12的重要唤回客户，分析其偏好，更精准地推送商品，以防流失。<br>对于RF=11的重要挽回客户，可考虑发放限时优惠券，促进关注与消费。</p>
<p><strong>D.  找出用户产品偏好，制定商品营销策略</strong><br>用户偏好商品类别里并没有出现购买数量非常集中的商品，说明商品售卖主要依靠长尾商品的累积效应，而非爆款商品的带动，这也是双11之后用户的补充采买的特征，同时发现此时用户购买的品类以及商品的浏览量很低，用户的个人喜好特征表现明显，同时浏览量高的商品购买转化率低。<br>对于高浏览量商品，可以将重心转移至定价上，实行差异化定价，同时改善商品页面、详情页以及评论区的管理，以提高购买量<br>对于高购买率商品，建议提高曝光率，结合多平台宣传，提高浏览量<br>对于明星商品，建议平台给予表扬与内部公开，以保证持续的优质</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1] <a href="http://www.zuopm.com/data/188.html" target="_blank" rel="noopener">http://www.zuopm.com/data/188.html</a><br>[2] <a href="https://blog.csdn.net/MsSpark/article/details/86727058" target="_blank" rel="noopener">https://blog.csdn.net/MsSpark/article/details/86727058</a><br>[3] <a href="https://zhuanlan.zhihu.com/p/63853715" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63853715</a></p>
]]></content>
      <categories>
        <category>python</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>用户行为</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>关于SQL易忘的知识点</title>
    <url>/2020/06/19/%E5%85%B3%E4%BA%8ESQL%E6%98%93%E5%BF%98%E7%9A%84%E5%8D%81%E4%BA%94%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200619102150246.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<p>主要记录SQL尤其是MySQL中，一些看了就忘，需要经常查的小知识点~</p>
<h2 id="1-下划线-通配符与百分号-通配符的区别"><a href="#1-下划线-通配符与百分号-通配符的区别" class="headerlink" title="1. 下划线_通配符与百分号%通配符的区别"></a>1. 下划线_通配符与百分号%通配符的区别</h2><p>下划线的用途与%一样，但是%能匹配0个字符不一样，_总是匹配一个字符，不能多也不能少。<br><img src="https://img-blog.csdnimg.cn/20200502213747941.png" alt="在这里插入图片描述"></p>
<h2 id="2-匹配不区分大小写"><a href="#2-匹配不区分大小写" class="headerlink" title="2. 匹配不区分大小写"></a>2. 匹配不区分大小写</h2><p>通过使用BINARY可以区分，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">WHERE prod_name REGEXP BINARY 'JetPack .000'</span><br></pre></td></tr></table></figure>

<h2 id="3-MySQL正则表达式"><a href="#3-MySQL正则表达式" class="headerlink" title="3. MySQL正则表达式"></a>3. MySQL正则表达式</h2><p>正则表达式的作用是匹配文本，将一个模式（正则表达式）与一个文本串进行比较。MySQL<br>用WHERE子句对正则表达式提供了初步的支持，允许你指定正则表达式，过滤SELECT检索出的数据。</p>
<h2 id="4-LIKE和REGEXP的区别"><a href="#4-LIKE和REGEXP的区别" class="headerlink" title="4. LIKE和REGEXP的区别"></a>4. LIKE和REGEXP的区别</h2><p>LIKE匹配整个列。如果被匹配的文本在列值中出现，LIKE将不会找到它，相应的行也不被返回（除非使用通配符）。而REGEXP在列值内进行匹配，如果被匹配的文本在列值中出现，REGEXP将会找到它，相应的行将被返回。这是一个非常重要的差别。</p>
<h2 id="5-匹配"><a href="#5-匹配" class="headerlink" title="5. 匹配"></a>5. 匹配</h2><p><strong>匹配字符</strong><br><img src="https://img-blog.csdnimg.cn/20200502215248363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>匹配特殊字符</strong><br>为了匹配特殊字符，必须用\为前导。\-表示查找-，\.表示查找.。这种处理就是所谓的转义（escaping），正则表达式内具有特殊意义的所有字符都必须以这种方式转义。这包括.、|、[]以及迄今为止使用过的其他特殊字符。<br>\也用来引用元字符（具有特殊含义的字符）。<br><img src="https://img-blog.csdnimg.cn/20200502220002901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>例：<br><img src="https://img-blog.csdnimg.cn/20200502220945880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>定位符</strong><br><img src="https://img-blog.csdnimg.cn/20200502221139784.png" alt="在这里插入图片描述"><br>例：<br><img src="https://img-blog.csdnimg.cn/2020050222152389.png" alt="在这里插入图片描述"><br><strong>注：^的双重用途</strong><br>^有两种用法。在集合中（用[和]定义），用它来否定该集合，否则，用来指串的开始处。</p>
<h2 id="6-文本处理函数"><a href="#6-文本处理函数" class="headerlink" title="6. 文本处理函数"></a>6. 文本处理函数</h2><p><img src="https://img-blog.csdnimg.cn/20200502224543982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>SOUNDEX是一个将任何文本串转换为描述其语音表示的字母数字模式的算法。使用Soundex()函数进行搜索，它匹配所有发音类似于Y.Lie的联系名：<br><img src="https://img-blog.csdnimg.cn/2020050222515799.png" alt="在这里插入图片描述"><br>拼接：将值联结到一起构成单个值。<br>解决办法是把两个列拼接起来。在MySQL的SELECT语句中，可使用Concat()函数来拼接两个列。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">Concat</span>(ven_name, <span class="string">'('</span>, vend_country, <span class="string">')'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="7-日期和时间处理函数"><a href="#7-日期和时间处理函数" class="headerlink" title="7. 日期和时间处理函数"></a>7. 日期和时间处理函数</h2><p><img src="https://img-blog.csdnimg.cn/20200502225707163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200502231413483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="8-数值处理函数"><a href="#8-数值处理函数" class="headerlink" title="8. 数值处理函数"></a>8. 数值处理函数</h2><p><img src="https://img-blog.csdnimg.cn/20200502231547428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="9-聚集函数"><a href="#9-聚集函数" class="headerlink" title="9. 聚集函数"></a>9. 聚集函数</h2><p><img src="https://img-blog.csdnimg.cn/20200503104310481.png" alt="在这里插入图片描述"><br>其中，在用于文本数据时，如果数据按相应的列排序，则MAX()返回最后一行，MIN()返回第一行。<br>COUNT()函数有两种使用方式。使用COUNT(*)对表中行的数目进行计数，不管表列中包含的是空值（NULL）还是非空值。使用COUNT(column)对特定列中具有值的行进行计数，忽略NULL值。</p>
<h2 id="10-HAVING和WHERE的区别"><a href="#10-HAVING和WHERE的区别" class="headerlink" title="10. HAVING和WHERE的区别"></a>10. HAVING和WHERE的区别</h2><p>“Where” 是一个约束声明，使用Where来约束来之数据库的数据，Where是在结果返回之前起作用的，且Where中不能使用聚合函数。<br>“Having”是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。<br><img src="https://img-blog.csdnimg.cn/2020050310553535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="11-组合查询UNION"><a href="#11-组合查询UNION" class="headerlink" title="11. 组合查询UNION"></a>11. 组合查询UNION</h2><p>UNION 返回匹配行，不保留重复行<br>UNION ALL 返回匹配行，包括重复行</p>
<p>UNION中的每个查询必须包含相同的列、表达式或聚集函数（不过各个列不需要以相同的次序列出）。<br>在用UNION组合查询时，只能使用一条ORDER BY子句，它必须出现在最后一条SELECT语句之后。对于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一部分的情况，因此不允许使用多条ORDER BY子句。</p>
<h2 id="12-全文本搜索"><a href="#12-全文本搜索" class="headerlink" title="12. 全文本搜索"></a>12. 全文本搜索</h2><p><img src="https://img-blog.csdnimg.cn/2020050311335215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>查询扩展<br><img src="https://img-blog.csdnimg.cn/20200503113851840.png" alt="在这里插入图片描述"><br>表中的行越多（这些行中的文本就越多），使用查询扩展返回的结果越好。</p>
<p>布尔文本搜索<br><img src="https://img-blog.csdnimg.cn/20200503114745745.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200503115115309.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在布尔方式中，不按等级值降序排序返回的行。</p>
<h2 id="13-数据插入"><a href="#13-数据插入" class="headerlink" title="13. 数据插入"></a>13. 数据插入</h2><p>插入一行<br><img src="https://img-blog.csdnimg.cn/20200503152023293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>插入多行<br><img src="https://img-blog.csdnimg.cn/20200503152023113.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>插入检索出的数据<br><img src="https://img-blog.csdnimg.cn/20200503152215262.png" alt="在这里插入图片描述"></p>
<h2 id="14-更新数据、删除数据"><a href="#14-更新数据、删除数据" class="headerlink" title="14. 更新数据、删除数据"></a>14. 更新数据、删除数据</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新多个列</span></span><br><span class="line"><span class="keyword">UPDATE</span> customers</span><br><span class="line"><span class="keyword">SET</span> cust_name = <span class="string">'The Fudds'</span>,</span><br><span class="line">	cust_email = <span class="string">'elmer@fudd.com'</span></span><br><span class="line"><span class="keyword">WHERE</span> cust_id = <span class="number">10005</span> ;     <span class="comment">#不要省略WHERE子句</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#删除某个列的值</span></span><br><span class="line"><span class="keyword">UPDATE</span> customers</span><br><span class="line"><span class="keyword">SET</span> cust_email = <span class="literal">NULL</span>    <span class="comment">#其中NULL用来去除cust_email列中的值。</span></span><br><span class="line"><span class="keyword">WHERE</span> cust_id = <span class="number">10005</span> ; </span><br><span class="line"></span><br><span class="line"><span class="comment">#删除数据</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> customers</span><br><span class="line"><span class="keyword">WHERE</span> cust_id = <span class="number">10005</span> ;</span><br><span class="line"><span class="comment">#DELETE不需要列名或通配符。DELETE删除整行而不是删除列,但DELETE不删除表本身。为了删除指定的列，请使用UPDATE语句。</span></span><br></pre></td></tr></table></figure>

<h2 id="15-主键、索引和外键"><a href="#15-主键、索引和外键" class="headerlink" title="15. 主键、索引和外键"></a>15. 主键、索引和外键</h2><p>主键的作用：</p>
<ul>
<li>惟一地标识一行。 </li>
<li>作为一个可以被外键有效引用的对象。</li>
</ul>
<p>索引：索引分为主键索引、唯一索引、普通索引、全文索引、组合索引等</p>
<ul>
<li>主键索引（PRIMARY KEY）：<strong>不可以为空</strong>，<strong>可以做外键</strong>，一张表中只能有一个主键索引。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> PRIMARY <span class="keyword">KEY</span> ( <span class="string">`column`</span> )</span><br></pre></td></tr></table></figure>

<ul>
<li>唯一索引（UNIQUE）：被索引的数据列不允许包含重复的值，但<strong>允许有空值。</strong></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> <span class="keyword">UNIQUE</span> (<span class="string">`column`</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>普通索引（INDEX）：用来加速数据访问速度而建立的索引。多建立在经常出现在查询条件的字段和经常用于排序的字段。被索引的数据列允许包含重复的值。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> <span class="keyword">INDEX</span> index_name ( <span class="string">`column`</span> )</span><br></pre></td></tr></table></figure>

<ul>
<li>全文索引（FULLTEXT）：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时好空间。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> FULLTEXT ( <span class="string">`column`</span> )</span><br></pre></td></tr></table></figure>

<ul>
<li>组合索引：为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> <span class="keyword">INDEX</span> index_name ( <span class="string">`column1`</span>, <span class="string">`column2`</span>, <span class="string">`column3`</span> )</span><br></pre></td></tr></table></figure>


<p>主键和索引：主键是为了标识数据库记录唯一性，不允许记录重复，且键值不能为空，主也是一个特殊索引。数据表中只允许有一个主键，但是可以有多个索引。</p>
<p>外键：<br><img src="https://img-blog.csdnimg.cn/20200524190007537.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>《MySQL必知必会》Ben Forta 著，刘晓霞 钟鸣 译<br><a href="https://www.liaoxuefeng.com/wiki/1177760294764384/1218728424164736" target="_blank" rel="noopener">SQL教程 廖雪峰。</a></p>
]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫爬取招聘信息并进行数据分析</title>
    <url>/2020/06/18/%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%E5%B9%B6%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200618161152222.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h1 id="一、结果放在最前面"><a href="#一、结果放在最前面" class="headerlink" title="一、结果放在最前面"></a>一、结果放在最前面</h1><p><img src="https://img-blog.csdnimg.cn/20200531144422829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="请忽略"><br>（请忽略截图右边的蓝色正方形）<br>使用爬虫爬取智联招聘上关于“数据分析师”岗位的信息，并应用flask和echarts技术实现数据分析结果。</p>
<h1 id="二、爬虫"><a href="#二、爬虫" class="headerlink" title="二、爬虫"></a>二、爬虫</h1><p>主函数(main)：实现网页解析以及数据存储。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    kw = input(<span class="string">"请输入你要搜索的岗位关键字："</span>).strip()</span><br><span class="line">    keyword = urllib.parse.quote(urllib.parse.quote(kw))   <span class="comment">#二次编码</span></span><br><span class="line">    <span class="comment"># ka = input("请输入你要搜索的地区：").strip()</span></span><br><span class="line">    <span class="comment"># karea = getArea(ka)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">165</span>):</span><br><span class="line">        print(<span class="string">'正在爬取第&#123;&#125;页信息'</span>.format(i))</span><br><span class="line">        baseurl = <span class="string">"https://search.51job.com/list/"</span>+ str(<span class="number">000000</span>) +<span class="string">",000000,0000,00,9,99,"</span>+ keyword +<span class="string">",2,"</span>+ str(i) +<span class="string">".html"</span>    <span class="comment">#全国+keyword</span></span><br><span class="line">        html = askURL(baseurl)</span><br><span class="line">        bs = BeautifulSoup(html,<span class="string">"html.parser"</span>)</span><br><span class="line"></span><br><span class="line">        datalist = getData(bs)</span><br><span class="line">        dbpath = <span class="string">"./51job.db"</span></span><br><span class="line">        saveDB(datalist, dbpath)</span><br></pre></td></tr></table></figure>
<p>网页解析(askURL)：调用request和BeautifulSoup实现网页解析。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">askURL</span><span class="params">(url)</span>:</span></span><br><span class="line">    head = &#123;</span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url,headers=head)</span><br><span class="line">    html = <span class="string">""</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = urllib.request.urlopen(request)</span><br><span class="line">        html = response.read().decode(<span class="string">'gbk'</span>, <span class="string">'ignore'</span>)</span><br><span class="line">        <span class="comment"># print(html)</span></span><br><span class="line">    <span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> hasattr(e, <span class="string">"code"</span>):</span><br><span class="line">            print(e.code)</span><br><span class="line">        <span class="keyword">if</span> hasattr(e,<span class="string">"reason"</span>):</span><br><span class="line">            print(e.reason)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> html</span><br></pre></td></tr></table></figure>
<p>数据爬取(getData)：获取招聘信息，公司链接、招聘岗位链接、公司名称、岗位名称、地区、薪水；调用getCOM获取公司链接内的信息，调用getREC获取招聘岗位信息，并合并返回给main()。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getData</span><span class="params">(bs)</span>:</span></span><br><span class="line">    datalist = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> bs.select(<span class="string">".dw_table &gt; div.el"</span>):</span><br><span class="line">        data = &#123;&#125;</span><br><span class="line">        item = str(item)</span><br><span class="line"></span><br><span class="line">        link = re.findall(findLink, item)</span><br><span class="line">        data[<span class="string">'link'</span>] = <span class="string">''</span>.join(link)</span><br><span class="line"></span><br><span class="line">        title = re.findall(findTitle, item)</span><br><span class="line">        data[<span class="string">'title'</span>] = <span class="string">''</span>.join(title)</span><br><span class="line"></span><br><span class="line">        area = re.findall(findArea, item)</span><br><span class="line">        data[<span class="string">'area'</span>] = <span class="string">''</span>.join(area)</span><br><span class="line"></span><br><span class="line">        com = re.findall(findCom, item)</span><br><span class="line">        data[<span class="string">'com'</span>] = <span class="string">''</span>.join(com)</span><br><span class="line"></span><br><span class="line">        comlink = re.findall(findComLink, item)</span><br><span class="line">        data[<span class="string">'comlink'</span>] = <span class="string">''</span>.join(comlink)</span><br><span class="line"></span><br><span class="line">        salary = re.findall(findSalary, item)</span><br><span class="line">        data[<span class="string">'salary'</span>] = <span class="string">''</span>.join(salary)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        strhtml = <span class="string">'https://jobs.51job.com/'</span></span><br><span class="line">        <span class="keyword">if</span> data[<span class="string">"link"</span>].startswith(strhtml) <span class="keyword">and</span> data[<span class="string">'comlink'</span>].startswith(strhtml):</span><br><span class="line"></span><br><span class="line">            com_link = data[<span class="string">'comlink'</span>]</span><br><span class="line">            com_data = getCOM(com_link)</span><br><span class="line">            data = dict(data.items(), **com_data)</span><br><span class="line"></span><br><span class="line">            rec_link = data[<span class="string">'link'</span>]</span><br><span class="line">            recruit_data = getREC(rec_link)</span><br><span class="line">            data = dict(data.items(), **recruit_data)</span><br><span class="line">            datalist.append(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> datalist</span><br></pre></td></tr></table></figure>
<p>爬取公司信息(getCOM)：获取公司链接内的信息，公司性质、公司规模、公司行业</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCOM</span><span class="params">(com_link)</span>:</span></span><br><span class="line">    com_html = askURL(com_link)</span><br><span class="line">    bs = BeautifulSoup(com_html, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="comment"># 公司信息</span></span><br><span class="line">    CP_TYPE = [<span class="string">'民营公司'</span>, <span class="string">'上市公司'</span>, <span class="string">'事业单位'</span>, <span class="string">'国企'</span>, <span class="string">'外资（欧美）'</span>, <span class="string">'外资（非欧美）'</span>,</span><br><span class="line">               <span class="string">'创业公司'</span>, <span class="string">'政府机关'</span>, <span class="string">'合资'</span>, <span class="string">'外资'</span>, <span class="string">'合资'</span>, <span class="string">'外企代表处'</span>, <span class="string">'非营利组织'</span>]</span><br><span class="line">    CP_SCALE = [<span class="string">'少于50人'</span>, <span class="string">'50-150人'</span>, <span class="string">'150-500人'</span>, <span class="string">'500-1000人'</span>,</span><br><span class="line">                <span class="string">'1000-5000人'</span>, <span class="string">'5000-10000人'</span>, <span class="string">'10000人以上'</span>]</span><br><span class="line"></span><br><span class="line">    cp_info = bs.select(<span class="string">'.in &gt; p.ltype'</span>)[<span class="number">0</span>].text.split(<span class="string">'\xa0\xa0|\xa0\xa0'</span>)</span><br><span class="line">    com_data = &#123;&#125;</span><br><span class="line">    com_data[<span class="string">'cp_type'</span>] = com_data[<span class="string">'cp_scale'</span>] = com_data[<span class="string">'industry'</span>] = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> CP_TYPE:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> cp_info:</span><br><span class="line">            com_data[<span class="string">'cp_type'</span>] = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> CP_SCALE:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> cp_info:</span><br><span class="line">            com_data[<span class="string">'cp_scale'</span>] = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> cp_info:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> CP_TYPE <span class="keyword">and</span> i <span class="keyword">not</span> <span class="keyword">in</span> CP_SCALE:</span><br><span class="line">            com_data[<span class="string">'industry'</span>] = i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> com_data</span><br></pre></td></tr></table></figure>
<p>爬取招聘信息(getREC)：获取招聘岗位链接内的信息，经验、学历、招聘人数、发布日期、工作描述</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getREC</span><span class="params">(rec_link)</span>:</span></span><br><span class="line">    jobHtml = askURL(rec_link)  <span class="comment">#获取详情页</span></span><br><span class="line">    bs = BeautifulSoup(jobHtml,<span class="string">"html.parser"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 经验、学历、招聘人数、发布日期</span></span><br><span class="line">    text = bs.select(<span class="string">".ltype"</span>)</span><br><span class="line">    job = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> len(text) != <span class="number">0</span>:</span><br><span class="line">        info = text[<span class="number">0</span>].text.split(<span class="string">'\xa0\xa0|\xa0\xa0'</span>)</span><br><span class="line">        EDU = [<span class="string">'博士'</span>, <span class="string">'硕士'</span>, <span class="string">'本科'</span>, <span class="string">'大专'</span>,</span><br><span class="line">               <span class="string">'中专'</span>, <span class="string">'中技'</span>, <span class="string">'高中'</span>, <span class="string">'初中及以下'</span>]</span><br><span class="line"></span><br><span class="line">        job[<span class="string">'exp'</span>] = job[<span class="string">'edu'</span>] = job[<span class="string">'other'</span>] = job[<span class="string">'demand'</span>] = job[<span class="string">'pubdate'</span>] = <span class="string">" "</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> info:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'经验'</span> <span class="keyword">in</span> i:</span><br><span class="line">                job[<span class="string">'exp'</span>] = i</span><br><span class="line">            <span class="keyword">elif</span> i <span class="keyword">in</span> EDU:</span><br><span class="line">                job[<span class="string">'edu'</span>] = i</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">'招'</span> <span class="keyword">in</span> i:</span><br><span class="line">                job[<span class="string">'demand'</span>] = i</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">'发布'</span> <span class="keyword">in</span> i:</span><br><span class="line">                job[<span class="string">'pubdate'</span>] = i</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                job[<span class="string">'other'</span>] = i</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        job[<span class="string">'exp'</span>] = job[<span class="string">'edu'</span>] = job[<span class="string">'other'</span>] = job[<span class="string">'demand'</span>] = job[<span class="string">'pubdate'</span>] = <span class="string">" "</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    job[<span class="string">'msg'</span>] = <span class="string">" "</span></span><br><span class="line">    jobMsgList = bs.select(<span class="string">".job_msg &gt; p"</span>)  <span class="comment">#工作描述</span></span><br><span class="line">    jobMsgStr = <span class="string">""</span></span><br><span class="line">    <span class="keyword">for</span> str <span class="keyword">in</span> jobMsgList:</span><br><span class="line">        jobMsgStr = jobMsgStr + str.text</span><br><span class="line">    job[<span class="string">"msg"</span>] = jobMsgStr</span><br><span class="line"></span><br><span class="line">    <span class="comment"># jobList.append(job)</span></span><br><span class="line">    <span class="keyword">return</span> job</span><br></pre></td></tr></table></figure>

<p>数据存储(saveData)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveDB</span><span class="params">(datalist, dbpath)</span>:</span></span><br><span class="line">    init_db(dbpath)</span><br><span class="line">    conn = sqlite3.connect(dbpath)</span><br><span class="line">    cur = conn.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> datalist:</span><br><span class="line">        print(data)</span><br><span class="line">        sql = <span class="string">'''</span></span><br><span class="line"><span class="string">                insert or ignore into job_quanguo(</span></span><br><span class="line"><span class="string">                link,title,comlink,com,area,salary,cp_type,cp_scale,industry,exp,edu,other,demand,pubdate,msg</span></span><br><span class="line"><span class="string">                 ) </span></span><br><span class="line"><span class="string">                 values(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)'''</span></span><br><span class="line">        <span class="comment"># print(sql)</span></span><br><span class="line">        cur.execute(sql,(data[<span class="string">'link'</span>],data[<span class="string">'title'</span>],data[<span class="string">'comlink'</span>],data[<span class="string">'com'</span>],data[<span class="string">'area'</span>],data[<span class="string">'salary'</span>],data[<span class="string">'cp_type'</span>],</span><br><span class="line">                         data[<span class="string">'cp_scale'</span>],data[<span class="string">'industry'</span>],data[<span class="string">'exp'</span>],data[<span class="string">'edu'</span>],data[<span class="string">'other'</span>],data[<span class="string">'demand'</span>],data[<span class="string">'pubdate'</span>],data[<span class="string">'msg'</span>]))</span><br><span class="line">        conn.commit()</span><br><span class="line">    cur.close()</span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure>
<p>爬取结果：<br><img src="https://img-blog.csdnimg.cn/2020053115105068.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>一共爬取了7277条数据，包括：公司名称、链接、岗位名称、地区、薪水、企业性质、企业规模、行业、招聘要求、招聘信息等等。</p>
<h1 id="三、数据处理"><a href="#三、数据处理" class="headerlink" title="三、数据处理"></a>三、数据处理</h1><p>薪水处理：由于薪水是以上下限显示的，故将薪水分成三列，分别为下限，上限以及平均薪水。同时删除一部分没有显示薪水的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSalary</span><span class="params">()</span>:</span></span><br><span class="line">    datalist = []</span><br><span class="line">    con = sqlite3.connect(<span class="string">"51job.db"</span>)</span><br><span class="line">    cur = con.cursor()</span><br><span class="line">    sql = <span class="string">"SELECT com,title,area,cp_type,cp_scale,industry,exp,edu,salary FROM job_quanguo"</span></span><br><span class="line">    data_quanguo = cur.execute(sql)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> data_quanguo:</span><br><span class="line">        string = <span class="string">""</span>.join(item[<span class="number">8</span>])</span><br><span class="line">        <span class="keyword">if</span> string.endswith(<span class="string">'千/月'</span>):</span><br><span class="line">            num = string.replace(<span class="string">"千/月"</span>,<span class="string">""</span>).split(<span class="string">"-"</span>)</span><br><span class="line">            sal = pd.to_numeric(num)*<span class="number">1000</span></span><br><span class="line">            <span class="comment"># datalist.append(pd.to_numeric(num)*1000)</span></span><br><span class="line">            data1 = append_other(item)</span><br><span class="line">            data2 = append_salary(sal)</span><br><span class="line">        <span class="keyword">elif</span> string.endswith(<span class="string">'万/月'</span>):</span><br><span class="line">            num = string.replace(<span class="string">"万/月"</span>,<span class="string">""</span>).split(<span class="string">"-"</span>)</span><br><span class="line">            sal = pd.to_numeric(num)*<span class="number">10000</span></span><br><span class="line">            <span class="comment"># datalist.append(pd.to_numeric(num)*10000)</span></span><br><span class="line">            data1 = append_other(item)</span><br><span class="line">            data2 = append_salary(sal)</span><br><span class="line">        <span class="keyword">elif</span> string.endswith(<span class="string">'万/年'</span>):</span><br><span class="line">            num = string.replace(<span class="string">"万/年"</span>,<span class="string">""</span>).split(<span class="string">"-"</span>)</span><br><span class="line">            sal = pd.to_numeric(num)*<span class="number">10000</span>/<span class="number">12</span></span><br><span class="line">            <span class="comment"># datalist.append(pd.to_numeric(num)*10000/12)</span></span><br><span class="line">            <span class="comment"># append_other(item)</span></span><br><span class="line">            data1 = append_other(item)</span><br><span class="line">            data2 = append_salary(sal)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        data = dict(data1.items(), **data2)</span><br><span class="line">        datalist.append(data)</span><br><span class="line">    cur.close()</span><br><span class="line">    con.close()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># df_salary = pd.DataFrame(columns=['low-salary','high-salary'])</span></span><br><span class="line">    dbpath = <span class="string">"./51job.db"</span></span><br><span class="line">    saveDB(datalist, dbpath)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_salary</span><span class="params">(sal)</span>:</span></span><br><span class="line">    data1 = &#123;&#125;</span><br><span class="line">    data1[<span class="string">'low-salary'</span>] = sal[<span class="number">0</span>].astype(np.int64)</span><br><span class="line">    data1[<span class="string">'high-salary'</span>] = sal[<span class="number">1</span>].astype(np.int64)</span><br><span class="line">    data1[<span class="string">'avg-salary'</span>] = (sal[<span class="number">0</span>].astype(np.int64)+sal[<span class="number">1</span>].astype(np.int64))/<span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data1</span><br></pre></td></tr></table></figure>

<h1 id="四、Flask与ECharts"><a href="#四、Flask与ECharts" class="headerlink" title="四、Flask与ECharts"></a>四、Flask与ECharts</h1><p>主要参考了ECharts官方文档，在此就不一一论述了。</p>
]]></content>
      <categories>
        <category>python</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>flask</tag>
        <tag>BeautifulSoup</tag>
      </tags>
  </entry>
</search>
