<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【Machine Learning】应用机器学习的建议(Advice for Applying Machine Learning)</title>
    <url>/2020/07/14/%5BMachine%20Learning%5D%20%E5%BA%94%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BB%BA%E8%AE%AE(Advice%20for%20Applying%20Machine%20Learning)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200714180442551.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="8-Advice-for-Applying-Machine-Learning-应用机器学习的建议"><a href="#8-Advice-for-Applying-Machine-Learning-应用机器学习的建议" class="headerlink" title="8 Advice for Applying Machine Learning(应用机器学习的建议)"></a>8 Advice for Applying Machine Learning(应用机器学习的建议)</h2><h3 id="8-1-Introduction"><a href="#8-1-Introduction" class="headerlink" title="8.1 Introduction"></a>8.1 Introduction</h3><p>获得更多的训练实例——通常是有效的，但代价较大，下面的方法也可能有效，可考虑先采用下面的几种方法。<br>1.尝试减少特征的数量<br>2.尝试获得更多的特征<br>3.尝试增加多项式特征<br>4.尝试减少正则化程度𝜆<br>5.尝试增加正则化程度𝜆<br>不应该随机选择上面的某种方法来改进算法，而是运用一些机器学习诊断法来确定上面哪些方法对算法是有效的。</p>
<p>接下来将介绍怎样评估机器学习算法的性能，然后再开始讨论这些方法，它们也被称为”机器学习诊断法”。“诊断法”的意思是：这是一种测试法，你通过执行这种测试，能够深入了解某种算法到底是否有用。这通常也能够告诉你，要想改进一种算法的效果，什么样的尝试，才是有意义的。这些诊断法的执行和实现，是需要花些时间的，有时候确实需要花很多时间来理解和实现，但这样做的确是把时间用在了刀刃上。</p>
<h3 id="8-2-Evaluating-a-Hypothesis"><a href="#8-2-Evaluating-a-Hypothesis" class="headerlink" title="8.2 Evaluating a Hypothesis"></a>8.2 Evaluating a Hypothesis</h3><p><img src="https://img-blog.csdnimg.cn/20200714153351469.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在确定学习算法参数的时候，需要考虑的是选择参量来使训练误差最小化。另外，仅仅是因为这个假设具有很小的训练误差，并不能说明它就一定是一个好的假设函数。例如，可能发生了过拟合问题。</p>
<p>那么，该如何判断一个假设函数是过拟合的呢？对于这个简单的例子，可以对假设函数ℎ(𝑥)进行画图，然后观察图形趋势，但对于特征变量不止一个的这种一般情况，还有像有很多特征变量的问题，想要通过画出假设函数来进行观察，就会变得很难甚至是不可能实现。因此，需要另一种方法来评估假设函数过拟合。</p>
<p>为了检验算法是否过拟合，将数据分成训练集和测试集，通常用 70%的数据作为<br>训练集，用剩下 30%的数据作为测试集。很重要的一点是训练集和测试集均要含有各种类型的数据，通常需要对数据进行“洗牌”，然后再分成训练集和测试集。<img src="https://img-blog.csdnimg.cn/20200714153540170.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt=" "><br>测试集评估在通过训练集让模型学习得出其参数后，对测试集运用该模型，有两种方式计算误差：<br>1.对于线性回归模型，利用测试集数据计算代价函数𝐽<br>2.对于逻辑回归模型，除了可以利用测试数据集来计算代价函数外：<br><img src="https://img-blog.csdnimg.cn/20200714163139716.png" alt="在这里插入图片描述"><br>误分类的比率，对于每一个测试集实例，计算：<br><img src="https://img-blog.csdnimg.cn/20200714163307224.PNG#pic_center" alt="在这里插入图片描述"><br>然后对计算结果求平均。</p>
<h3 id="8-3-Model-Selection-and-Train-Validation-Test-Sets"><a href="#8-3-Model-Selection-and-Train-Validation-Test-Sets" class="headerlink" title="8.3 Model Selection and Train_Validation_Test Sets"></a>8.3 Model Selection and Train_Validation_Test Sets</h3><p><img src="https://img-blog.csdnimg.cn/20200714163458637.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>假设要在 10 个不同次数的二项式模型之间进行选择，显然越高次数的多项式模型越能够适应训练数据集，但是适应训练数据集并不代表着能推广至一般情况，应该选择一个更能适应一般情况的模型。此时需要使用交叉验证集来帮助选择模型。</p>
<p>即：使用 60%的数据作为训练集，使用 20%的数据作为交叉验证集，使用 20%的数据作为测试集。<br><img src="https://img-blog.csdnimg.cn/20200714163712246.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>模型选择的方法为：</p>
<ol>
<li>使用训练集训练出 10 个模型</li>
<li>用 10 个模型分别对交叉验证集计算得出交叉验证误差（代价函数的值）</li>
<li>选取代价函数值最小的模型</li>
<li>用步骤 3 中选出的模型对测试集计算得出推广误差（代价函数的值）</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/20200714163835857.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="8-4-Diagnosing-Bias-vs-Variance"><a href="#8-4-Diagnosing-Bias-vs-Variance" class="headerlink" title="8.4 Diagnosing Bias vs. Variance"></a>8.4 Diagnosing Bias vs. Variance</h3><p>当运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况：要么是偏差比较大，要么是方差比较大。换句话说，出现的情况要么是欠拟合，要么是过拟合问题。那么这两种情况，哪个和偏差有关，哪个和方差有关，或者是不是和两个都有关？搞清楚这一点非常重要，因为能判断出现的情况是这两种情况中的哪一种。其实是一个很有效的指示器，指引着可以改进算法的最有效的方法和途径。<br><img src="https://img-blog.csdnimg.cn/202007141657370.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>通常会通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来帮助分析：<br><img src="https://img-blog.csdnimg.cn/20200714165636740.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200714170214653.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对于训练集，当 𝑑 较小时，模型拟合程度更低，误差较大；随着 𝑑 的增长，拟合程度提高，误差减小。<br>对于交叉验证集，当 𝑑 较小时，模型拟合程度低，误差较大；但是随着 𝑑 的增长，误差呈现先减小后增大的趋势，转折点是我们的模型开始过拟合训练数据集的时候。</p>
<p>如果交叉验证集误差较大，如何判断是方差还是偏差呢？根据上面的图表，得出:<br><img src="https://img-blog.csdnimg.cn/20200714170427983.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>训练集误差和交叉验证集误差近似时：偏差/欠拟合</li>
<li>交叉验证集误差远大于训练集误差时：方差/过拟合</li>
</ul>
<h3 id="8-5-Regularization-and-Bias-Variance"><a href="#8-5-Regularization-and-Bias-Variance" class="headerlink" title="8.5 Regularization and Bias/Variance"></a>8.5 Regularization and Bias/Variance</h3><p>在训练模型的过程中，一般会使用一些正则化方法来防止过拟合。但是可能会正则化的程度太高或太小了，即在选择 λ 的值时也需要思考与刚才选择多项式模型次数类似的问题。<br><img src="https://img-blog.csdnimg.cn/20200714170902750.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>选择一系列的想要测试的 𝜆 值，通常是 0-10 之间的呈现 2 倍关系的值（如：0,0.01,0.02,0.04,0.08,0.15,0.32,0.64,1.28,2.56,5.12,10共 12 个）。同样把数据分为训练集、交叉验证集和测试集。<br><img src="https://img-blog.csdnimg.cn/20200714172426323.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>选择𝜆的方法为：<br>1.使用训练集训练出 12 个不同程度正则化的模型<br>2.用 12 个模型分别对交叉验证集计算的出交叉验证误差<br>3.选择得出交叉验证误差最小的模型<br>4.运用步骤 3 中选出模型对测试集计算得出推广误差，也可以同时将训练集和交叉验证集模型的代价函数误差与 λ 的值绘制在一张图表上：<br><img src="https://img-blog.csdnimg.cn/20200714172535993.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>当 𝜆 较小时，训练集误差较小（过拟合）而交叉验证集误差较大</li>
<li>随着 𝜆 的增加，训练集误差不断增加（欠拟合），而交叉验证集误差则是先减小后增加</li>
</ul>
<h3 id="8-6-Learning-Curves"><a href="#8-6-Learning-Curves" class="headerlink" title="8.6 Learning Curves"></a>8.6 Learning Curves</h3><p>学习曲线可用于判断某一个学习算法是否处于偏差、方差问题。学习曲线是学习算法的一个很好的<label style="color:red">合理检验（sanity check）</label>。学习曲线是将训练集误差和交叉验证集误差作为训练集实例数量（𝑚）的函数绘制的图表。</p>
<p>即，如果有 100 行数据，从 1 行数据开始，逐渐学习更多行的数据。思想是：当训练较少行数据的时候，训练的模型将能够非常完美地适应较少的训练数据，但是训练出来的模型却不能很好地适应交叉验证集数据或测试集数据。<br><img src="https://img-blog.csdnimg.cn/20200714173125794.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如何利用学习曲线识别高偏差/欠拟合：作为例子，尝试用一条直线来适应下面的数据，可以看出，无论训练集有多么大误差都不会有太大改观：<br><img src="https://img-blog.csdnimg.cn/2020071417355684.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>也就是说在高偏差/欠拟合的情况下，增加数据到训练集不一定能有帮助。</p>
<p>如何利用学习曲线识别高方差/过拟合：假设使用一个非常高次的多项式模型，并且正则化非常小，可以看出，当交叉验证集误差远大于训练集误差时，往训练集增加更多数据可以提高模型的效果。<br><img src="https://img-blog.csdnimg.cn/20200714173709702.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>也就是说在高方差/过拟合的情况下，增加更多数据到训练集可能可以提高算法效果。</p>
<h3 id="8-7-Summary"><a href="#8-7-Summary" class="headerlink" title="8.7 Summary"></a>8.7 Summary</h3><ol>
<li>获得更多的训练实例——解决高方差</li>
<li>尝试减少特征的数量——解决高方差</li>
<li>尝试获得更多的特征——解决高偏差</li>
<li>尝试增加多项式特征——解决高偏差</li>
<li>尝试减少正则化程度 λ——解决高偏差</li>
<li>尝试增加正则化程度 λ——解决高方差</li>
</ol>
<p><strong>神经网络的方差和偏差：</strong><br><img src="https://img-blog.csdnimg.cn/20200714180238125.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。</p>
<p>对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Learning Curves</tag>
        <tag>Bias/Variance</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】神经网络的学习(Neural Networks_Learning)</title>
    <url>/2020/07/12/%5BMachine%20Learning%5D%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%AD%A6%E4%B9%A0(Neural%20Networks_%20Learning)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200712143509812.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="7-Neural-Networks-Learning-神经网络的学习"><a href="#7-Neural-Networks-Learning-神经网络的学习" class="headerlink" title="7 Neural Networks-Learning(神经网络的学习)"></a>7 Neural Networks-Learning(神经网络的学习)</h2><h3 id="7-1-Cost-Function"><a href="#7-1-Cost-Function" class="headerlink" title="7.1 Cost Function"></a>7.1 Cost Function</h3><p>假设神经网络的训练样本有𝑚个，每个包含一组输入𝑥和一组输出信号𝑦，𝐿表示神经网络层数，𝑆<sub>𝐼</sub>表示每层的 neuron 个数(𝑆<sub>l</sub>表示输出层神经元个数)，𝑆<sub>L</sub>代表最后一层中处理单元的个数。</p>
<p>将神经网络的分类定义为两种情况：二类分类和多类分类，</p>
<ul>
<li>二类分类：𝑆<sub>L</sub> = 0, 𝑦 = 0 𝑜𝑟 1表示哪一类；</li>
<li>𝐾类分类：𝑆<sub>L</sub> = 𝑘, 𝑦<sub>i</sub> = 1表示分到第 i 类(𝑘 &gt; 2)；</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200711140907505.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>逻辑回归问题中的代价函数为：<br><img src="https://img-blog.csdnimg.cn/20200711141004490.PNG#pic_center" alt="在这里插入图片描述"><br>在逻辑回归中，只有一个输出变量，又称标量（scalar），也只有一个因变量𝑦，但是在神经网络中，可以有很多输出变量，ℎ𝜃(𝑥)是一个维度为𝐾的向量，并且训练集中的因变量也是同样维度的一个向量，因此代价函数会比逻辑回归更加复杂一些，为：<br><img src="https://img-blog.csdnimg.cn/2020071114131862.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这个看起来复杂很多的代价函数背后的思想还是一样的，希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，都会给出𝐾个预测，基本上可以利用循环，对每一行特征都预测𝐾个不同结果，然后在利用循环在𝐾个预测中选择可能性最高的一个，将其与𝑦中的实际数据进行比较。</p>
<p>正则化的那一项只是排除了每一层𝜃0后，每一层的𝜃 矩阵的和。最里层的循环𝑗循环所有的行（由𝑠𝑙 +1 层的激活单元数决定），循环𝑖则循环所有的列，由该层（𝑠𝑙层）的激活单元数所决定。即：ℎ𝜃(𝑥)与真实值之间的距离为每个样本-每个类输出的加和，对参数进行regularization 的 bias 项处理所有参数的平方和。</p>
<h3 id="7-2-Backpropagation-Algorithm-反向传播算法"><a href="#7-2-Backpropagation-Algorithm-反向传播算法" class="headerlink" title="7.2 Backpropagation Algorithm(反向传播算法)"></a>7.2 Backpropagation Algorithm(反向传播算法)</h3><p>在计算神经网络预测结果的时候采用了一种正向传播方法，从第一层开始正向一层一层进行计算，直到最后一层的ℎ𝜃(𝑥)。</p>
<p>现在，为了计算代价函数的偏导数 <img src="https://img-blog.csdnimg.cn/20200711145159753.png" alt="在这里插入图片描述">，需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。 以一个例子来说明反向传播算法。</p>
<p>假设训练集只有一个实例(𝑥(1), 𝑦(1))，神经网络是一个四层的神经网络，其中𝐾 = 4，𝑆𝐿 = 4，𝐿 = 4：</p>
<p><strong>前向传播算法：</strong><br><img src="https://img-blog.csdnimg.cn/20200711145443278.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>反向传播算法</strong><br><img src="https://img-blog.csdnimg.cn/20200712131502934.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>从最后一层的误差开始计算，误差是激活单元的预测（a<sub>k</sub><sup>(4)</sup>）与实际值（𝑦<sup>𝑘</sup>）之间的误差，（𝑘 = 1: 𝑘），用𝛿来表示误差，则：𝛿<sup>(4)</sup> = 𝑎<sup>(4)</sup> − y 。</p>
<p>利用这个误差值来计算前一层的误差：𝛿<sup>(3)</sup> = (𝛩<sup>(3)</sup>)<sup>𝑇</sup>𝛿<sup>(4)</sup>∗ 𝑔′(𝑧<sup>(3)</sup>) 其中 𝑔′(𝑧<sup>(3)</sup>) 是 𝑆 形函数的导数，𝑔′(𝑧<sup>(3)</sup>)  = 𝑎<sup>(3)</sup>∗ (1 − 𝑎<sup>(3)</sup>)。而(𝛩<sup>(3)</sup>)<sup>𝑇</sup>𝛿<sup>(4)</sup>则是权重导致的误差的和。</p>
<p>下一步是继续计算第二层的误差：𝛿<sup>(2)</sup> = (𝛩<sup>(2)</sup>)<sup>𝑇</sup>𝛿<sup>(3)</sup>∗ 𝑔′(𝑧<sup>(2)</sup>) 。</p>
<p>因为第一层是输入变量，不存在误差。有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设𝜆 = 0，即不做任何正则化处理时有： 𝜕/𝜕𝛩<sub>𝑖𝑗</sub><sup>(𝑙)</sup>𝐽(𝛩) = 𝑎<sub>𝑗</sub><sup>(𝑙)</sup>𝛿<sub>𝑖</sub><sup>(𝑙+1)</sup> 。</p>
<p>上面式子中上下标的含义：</p>
<ul>
<li>𝑙 代表目前所计算的是第几层。</li>
<li>𝑗 代表目前计算层中的激活单元的下标，也将是下一层的第𝑗个输入变量的下标。</li>
<li>𝑖 代表下一层中误差单元的下标，是受到权重矩阵中第𝑖行影响的下一层中的误差单元的下标。</li>
</ul>
<p>如果考虑正则化处理，并且训练集是一个特征矩阵而非向量。在上面的特殊情况中，需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，同样需要计算每一层的误差单元，但是需要为整个训练集计算误差单元，此时的误差单元也是一个矩阵，我们用𝛥<sub>𝑖𝑗</sub><sup>(𝑙)</sup>来表示这个误差矩阵。第 𝑙 层的第 𝑖 个激活单元受到第 𝑗个参数影响而导致的误差。</p>
<p>反向传播算法为：<br><img src="https://img-blog.csdnimg.cn/20200712132926516.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。</p>
<p>在求出了𝛥<sub>𝑖𝑗</sub><sup>(𝑙)</sup>之后，便可以计算代价函数的偏导数了，计算方法如下：<br><img src="https://img-blog.csdnimg.cn/20200712133115751.PNG#pic_center" alt="在这里插入图片描述"><br>进一步理解：<br><img src="https://img-blog.csdnimg.cn/20200712135205765.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200712135416318.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2020071213542917.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="7-3-Gradient-Checking-梯度检测"><a href="#7-3-Gradient-Checking-梯度检测" class="headerlink" title="7.3 Gradient Checking(梯度检测)"></a>7.3 Gradient Checking(梯度检测)</h3><p>当对一个较为复杂的模型（例如神经网络）使用梯度下降算法时，可能会存在一些不容易察觉的错误，意味着，虽然代价看上去在不断减小，但最终的结果可能并不是最优解。为了避免这样的问题，我们采取一种叫做==梯度的数值检验（Numerical Gradient Checking）==方法。这种方法的思想是通过估计梯度值来检验计算的导数值是否真的是所要求的。</p>
<p>对梯度的估计采用的方法是在代价函数上沿着切线的方向选择两个非常近的点然后计算两个点的平均值用以估计梯度。即对于某个特定的 𝜃，计算出在 𝜃-𝜀 处和 𝜃+𝜀 的代价值（𝜀是一个非常小的值，通常选取 0.001），然后求两个代价的平均，用以估计在 𝜃处的代价值。<br><img src="https://img-blog.csdnimg.cn/20200712140624589.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>当𝜃是一个向量时，则需要对偏导数进行检验。因为代价函数的偏导数检验只针对一个参数的改变进行检验。<br><img src="https://img-blog.csdnimg.cn/20200712140921217.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>最后还需要对通过反向传播方法计算出的偏导数进行检验。</p>
<p>根据上面的算法，计算出的偏导数存储在矩阵 𝐷<sub>𝑖𝑗</sub><sup>(𝑙)</sup> 中。检验时，要将该矩阵展开成为向量，同时也将 𝜃 矩阵展开为向量，针对每一个 𝜃 都计算一个近似的梯度值，将这些值存储于一个近似梯度矩阵中，最终将得出的这个矩阵同𝐷<sub>𝑖𝑗</sub><sup>(𝑙)</sup> 进行比较。</p>
<p><img src="https://img-blog.csdnimg.cn/20200712141514334.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="7-4-Random-Initialization-随机初始化"><a href="#7-4-Random-Initialization-随机初始化" class="headerlink" title="7.4 Random Initialization(随机初始化)"></a>7.4 Random Initialization(随机初始化)</h3><p>任何优化算法都需要一些初始的参数。到目前为止都是初始所有参数为 0，这样的初始方法对于逻辑回归来说是可行的，但是对于神经网络来说是不可行的。如果令所有的初始参数都为 0，这将意味着第二层的所有激活单元都会有相同的值。同理，如果初始所有的参数都为一个非 0 的数，结果也是一样的。</p>
<p>通常初始参数为正负𝜀之间的随机值，假设要随机初始一个尺寸为 10×11 的参数矩阵，代码如下：<br>Theta1 = np.random.randn(10, 11) * (2*eps) – eps</p>
<h3 id="7-5-Putting-it-together"><a href="#7-5-Putting-it-together" class="headerlink" title="7.5 Putting it together"></a>7.5 Putting it together</h3><p><strong>神经网络结构：</strong></p>
<ul>
<li>第一层——特征数量</li>
<li>最后一层——类的数量（K分类就是K个）</li>
<li>隐藏层——每个隐藏层的单元个数相同，且单元的个数越多越好</li>
<li>需要设计的结构——隐藏层的层数and单元个数</li>
</ul>
<p><strong>训练神经网络步骤：</strong></p>
<ul>
<li>(a)参数的随机初始化</li>
<li>(b)利用正向传播方法计算所有的h_θ (x)</li>
<li>(c)编写计算代价函数 J 的代码</li>
<li>(d)利用反向传播方法计算所有偏导数</li>
<li>(e)利用数值检验方法检验这些偏导数</li>
<li>(f)使用优化算法来最小化代价函数</li>
</ul>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Networks</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】多变量线性回归(Linear Regression with Multiple Variables)</title>
    <url>/2020/07/07/%5BMachine%20Learning%5D%20%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92(Linear%20Regression%20with%20Multiple%20Variables)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200707131529483.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="3-Linear-Regression-with-Multiple-Variables-多变量线性回归"><a href="#3-Linear-Regression-with-Multiple-Variables-多变量线性回归" class="headerlink" title="3 Linear Regression with Multiple Variables(多变量线性回归)"></a>3 Linear Regression with Multiple Variables(多变量线性回归)</h2><h3 id="3-1-Multiple-Features-多维特征"><a href="#3-1-Multiple-Features-多维特征" class="headerlink" title="3.1 Multiple Features(多维特征)"></a>3.1 Multiple Features(多维特征)</h3><p><img src="https://img-blog.csdnimg.cn/20200707100825934.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200707100922690.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>注：实际上不一定是线性的，仅本例中使用线性。非线性也是此思想。</p>
<h3 id="3-2-Gradient-Descent-for-Multiple-Variables-多变量梯度下降"><a href="#3-2-Gradient-Descent-for-Multiple-Variables-多变量梯度下降" class="headerlink" title="3.2 Gradient Descent for Multiple Variables(多变量梯度下降)"></a>3.2 Gradient Descent for Multiple Variables(多变量梯度下降)</h3><p>与单变量线性回归类似，在多变量线性回归中，同样也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：<br><img src="https://img-blog.csdnimg.cn/20200707102308696.PNG#pic_center" alt="在这里插入图片描述"><br>目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。<img src="https://img-blog.csdnimg.cn/20200707101806364.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200707101739874.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>上图右边显示了多变量线性回归的批量梯度下降算法，其开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。</p>
<p><strong>python代码：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">computeCost</span><span class="params">(X, y, theta)</span>:</span></span><br><span class="line">	inner = np.power(((X * theta.T) - y), <span class="number">2</span>)</span><br><span class="line">	<span class="keyword">return</span> np.sum(inner) / (<span class="number">2</span> * len(X))</span><br></pre></td></tr></table></figure>

<h4 id="3-2-1-Gradient-Descent-in-Practice-I-Feature-Scaling-特征缩放"><a href="#3-2-1-Gradient-Descent-in-Practice-I-Feature-Scaling-特征缩放" class="headerlink" title="3.2.1 Gradient Descent in Practice I - Feature Scaling (特征缩放)"></a>3.2.1 Gradient Descent in Practice I - Feature Scaling (特征缩放)</h4><p><strong>在解决多维特征问题时，应该保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。</strong></p>
<p>以房价问题为例，假设有两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000 平方英尺，而房间数量的值则是 0-5，以两个参数分别为横纵坐标，绘制代价函数等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。<br><img src="https://img-blog.csdnimg.cn/20200707104230484.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>解决方法是尝试将所有特征的尺度都尽量缩放到-1 到 1 之间，即==特征归一化==。如图：<br><img src="https://img-blog.csdnimg.cn/20200707104328954.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<blockquote>
<p>数据的标准化（normalization）是将数据按比例缩放，使之落入一个小的特定区间。在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权，可以大大提高分类器的准确性。<br>其中最典型的就是数据的归一化处理，即将数据统一映射到[0,1]区间上。</p>
</blockquote>
<p>归一化公式：<br><img src="https://img-blog.csdnimg.cn/20200707105004270.PNG#pic_center" alt="在这里插入图片描述"></p>
<h4 id="3-2-2-Gradient-Descent-in-Practice-II-Learning-Rate-学习率"><a href="#3-2-2-Gradient-Descent-in-Practice-II-Learning-Rate-学习率" class="headerlink" title="3.2.2 Gradient Descent in Practice II - Learning Rate (学习率)"></a>3.2.2 Gradient Descent in Practice II - Learning Rate (学习率)</h4><p>梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，无法提前预知，但可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。<br><img src="https://img-blog.csdnimg.cn/20200707105546868.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>图像300~400已经相当平坦了，可推测到达400左右时梯度下降法差不多已经收敛了。</p>
<p>梯度下降算法的每次迭代受到学习率的影响，如果学习率𝑎过小，则达到收敛所需的迭代次数会非常多；如果学习率𝑎过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。</p>
<p>通常可以考虑尝试些学习率：<br>𝛼 =…，0.001，0.003，0.01，0.03，0.1，0.3，1，…</p>
<h3 id="3-3-Features-and-Polynomial-Regression-特征和多项式回归"><a href="#3-3-Features-and-Polynomial-Regression-特征和多项式回归" class="headerlink" title="3.3 Features and Polynomial Regression(特征和多项式回归)"></a>3.3 Features and Polynomial Regression(特征和多项式回归)</h3><p><img src="https://img-blog.csdnimg.cn/20200707121141207.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>线性回归并不适用于所有数据，有时需要曲线来适应数据，比如，<br>一个二次方模型：<img src="https://img-blog.csdnimg.cn/20200707121921446.PNG#pic_center" alt="在这里插入图片描述"><br>或者三次方模型：<img src="https://img-blog.csdnimg.cn/20200707121933949.PNG#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200707122024153.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>根据函数图形特性，我们还可以使：<br><img src="https://img-blog.csdnimg.cn/20200707122340253.PNG#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200707122358694.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>注：如果采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。</p>
<h3 id="3-4-Normal-Equation-正规方程"><a href="#3-4-Normal-Equation-正规方程" class="headerlink" title="3.4 Normal Equation(正规方程)"></a>3.4 Normal Equation(正规方程)</h3><p>正规方程是区别于迭代方法的直接计算解法，即直接求导数等于0的点。<br><img src="https://img-blog.csdnimg.cn/20200707123106110.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>假设训练集特征矩阵为 𝑋（包含了 𝑥0 = 1）并且训练集结果为向量 𝑦，则利用正规方程解出向量：<img src="https://img-blog.csdnimg.cn/202007071243148.PNG#pic_center" alt="在这里插入图片描述"><br>例子：<br><img src="https://img-blog.csdnimg.cn/20200707124545251.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>注：对于不可逆的矩阵（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。</p>
<p><strong>梯度下降与正规方程的比较</strong><br><img src="https://img-blog.csdnimg.cn/20200707125601290.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>注：只要特征变量的数目并不大，标准方程是一个很好的计算参数𝜃的替代方法。具体地说，只要特征变量数量小于一万，通常使用标准方程法，而不使用梯度下降法。</p>
<p><strong>Normal Equation Noninvertibility(正规方程及不可逆性)</strong><br><img src="https://img-blog.csdnimg.cn/20200707130156670.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>python实现正规方程：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalEqn</span><span class="params">(X, y)</span>:</span></span><br><span class="line">	theta = np.linalg.inv(X.T@X)@X.T@y <span class="comment">#X.T@X 等价于 X.T.dot(X)</span></span><br><span class="line">	<span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200707130732297.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200707130731881.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>《增长黑客实战》（第1-3章）</title>
    <url>/2020/07/14/%E3%80%8A%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%88%E7%AC%AC1-3%E7%AB%A0%EF%BC%89/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/2020071414384626.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="1-检验商业计划"><a href="#1-检验商业计划" class="headerlink" title="1 检验商业计划"></a>1 检验商业计划</h2><h3 id="1-1-伪需求"><a href="#1-1-伪需求" class="headerlink" title="1.1 伪需求"></a>1.1 伪需求</h3><p>对于初创公司能否存活的关键：如何快速地迭代、如何在现金流耗尽之前验证商业模式。常见的两种失败：</p>
<ul>
<li>市场占有失败</li>
<li>产品研发失败</li>
</ul>
<p>其中，前者的比例远远高于后者。</p>
<p>失败的项目中有超过七成错在满足的是伪需求。伪需求产品的诞生，主要可归结为五种原因。</p>
<ul>
<li>1.创始人的个人梦想情怀<br>“弱小和无知不是生存的障碍，傲慢才是”</li>
<li>2.寻求技术的商业化路径时结合生硬<br>“手里拿着锤子，看什么都是钉子”</li>
<li>3.误将自身需求放大为整个市场需求</li>
<li>4.以感性体验代替理性思考</li>
<li>5.盲目抄袭市场热点，缺乏对商业本质的深度认识</li>
</ul>
<h3 id="1-2-快速验证商业计划"><a href="#1-2-快速验证商业计划" class="headerlink" title="1.2 快速验证商业计划"></a>1.2 快速验证商业计划</h3><p>商业计划书（BP，business plan）<label style="color:red">P/MF，Product/Market Fit</label>，产品与市场相契合。用户级产品和企业级SaaS产品的业界参考标准如下。</p>
<p><strong>用户级产品标准</strong></p>
<ul>
<li>每周使用天数超过3天</li>
<li>初始日新增用户DAU超过100</li>
<li>30%新用户次日留存率</li>
<li>达到10万用户量</li>
</ul>
<p><strong>SaaS产品标准</strong></p>
<ul>
<li>5%付费转化率</li>
<li>LTV/CAC 大于 3，即用户生命周期价值/获取成本 大于3</li>
<li>月流失率 小于 2%</li>
<li>月销售流水达到10万元</li>
</ul>
<p><strong>快速寻找到P/MF的方法</strong></p>
<ul>
<li>精益画布</li>
<li>最小化可行产品（MVP）</li>
<li>设计冲刺（Sprint）</li>
</ul>
<h3 id="1-3-产品价值和建立付费增长框架"><a href="#1-3-产品价值和建立付费增长框架" class="headerlink" title="1.3 产品价值和建立付费增长框架"></a>1.3 产品价值和建立付费增长框架</h3><p>百度贴吧之父俞军提出过一个产品价值公式：<br>产品价值 = （新体验-旧体验）-换用成本</p>
<p>建立系统性的付费增长（Paid Growth）框架，每多花一元钱都能明确地讲出这一元的付出究竟是降低了整体获客成本、圈占到更大市场份额，抑或是让竞争对手不得不为此多花费两天的额外成本。</p>
<p><strong>互联网产品增值的“不可能三角”</strong></p>
<ul>
<li>新增用户规模</li>
<li>用户留存率</li>
<li>营收变现</li>
</ul>
<ol>
<li>追求新增、留存，牺牲营收<br>—— “烧钱补贴”</li>
<li>追求留存、营收，暂缓新增<br>—— 在同质化竞争之下，产品只能从加强专业性、提升用户体验等角度寻求溢价。</li>
<li>追求新增、营收，放弃留存<br>—— 如同设赌场一样，本着捞一笔是一笔的态度，只要有足够的用户流量支撑，最终都能收割韭菜，保证赚钱。</li>
</ol>
<p><strong>如何付费购买增长，保证产品获取长久稳健的流量？</strong></p>
<ul>
<li>购买用户数量<br>—— 适用于完全竞争市场，采用该方式的前提是CAC（用户获取成本）必须小于LTV（用户生命周期总价值）。即，花5美元买来的用户，最后会让你赚10美元。</li>
<li>购买增长速度<br>—— 牺牲短期营收，快速跑马圈地。目的是垄断市场。垄断利润给了企业规划长远未来的资本，但前提可能是牺牲短期营收，CAC大于LTV。</li>
<li>购买流动性<br>—— 促成更多的交易。如果项目是建立一个双边市场，那么相比供求双方的数量，更直接与估值挂钩的是流动性。只有产生流动性才算得出客单价、复购率、生命周期中价值等数据。 </li>
</ul>
<h3 id="1-4-增长的三个阶段：选择最恰当时机和目标"><a href="#1-4-增长的三个阶段：选择最恰当时机和目标" class="headerlink" title="1.4 增长的三个阶段：选择最恰当时机和目标"></a>1.4 增长的三个阶段：选择最恰当时机和目标</h3><p><img src="https://img-blog.csdnimg.cn/20200714133027404.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<table>
<thead>
<tr>
<th></th>
<th>种子期</th>
<th>成型期</th>
<th>增长期</th>
</tr>
</thead>
<tbody><tr>
<td>目标</td>
<td>验证产品，达到P/FM状态</td>
<td>理解用户的使用行为如何让各项指标产生波动，比如DAU波动的原因及改进方法</td>
<td>增长、增长、高速增长</td>
</tr>
<tr>
<td>指标</td>
<td>紧盯留存率</td>
<td>开始关注每周或每月的用户增长，并设法降低CPA （Cost Per Action）、提高LTV</td>
<td>增长率是主要目标，但仍需留意投资回报期，也就是多久能把之前亏损的钱赚回来</td>
</tr>
<tr>
<td>用户规模</td>
<td>在保证平稳持续的前提下，缓慢导入一些种子用户，用于进行各种试验，最终服务于达成P/FM的目的</td>
<td>允许更多的真实用户加入使用，但仍要注意留存率</td>
<td>已找到性价比在接受范围的推广渠道，就开闸泄洪让用户鱼贯而入吧</td>
</tr>
<tr>
<td>推广渠道</td>
<td>在多种不同类型的推广渠道上小规模地测试投入产出比，找到值得重点投入的主力渠道</td>
<td>一边尝试新的渠道，一边在已验证过的渠道中选择投入产出比最高的一个继续加码投入</td>
<td>花费80%的精力在主要推广渠道上</td>
</tr>
<tr>
<td>产品优化</td>
<td>在产品方向令人满意前，着眼于大的优化点，比如更换目标人群、改善行为路径、推翻核心流程</td>
<td>既着眼于大的优化点，也开始着手解决小问题</td>
<td>打磨细节</td>
</tr>
<tr>
<td>团队成员</td>
<td>不需要专门的增长黑客角色，但至少保证团队里有一个人在工作中将80%的时间用于思考如何获取增长</td>
<td>开始尝试建立专门的增长团队，或选拨有经验的产品经理专职负责聚焦增长</td>
<td>增长团队扩增</td>
</tr>
</tbody></table>
<h3 id="1-5-对产品增进认知"><a href="#1-5-对产品增进认知" class="headerlink" title="1.5 对产品增进认知"></a>1.5 对产品增进认知</h3><p>产品：<br>    * 用户为什么使用产品？他们期待的核心价值是什么？<br>    * 用户在产品中一步步的使用路径是怎样的？<br>    * 哪些特性或功能，更容易让新增用户转化成长期活跃的忠诚用户？<br>    * 是什么问题直接导致了一部分用户的离开？</p>
<p>用户：<br>    * 他们年龄多大，住在哪里，大多数从事什么职业？（建立你的用户画像。）<br>    * 他们如何描述我们试图解决的问题，以及看待我们提供的解决方案？<br>    * 在实际使用过程中，他们有哪些疑虑或恐慌？<br>    * 他们会将我们的产品与哪些品牌或事物关联在一起？</p>
<p>推广渠道：<br>    * 我们现行的推广渠道是如何运作的？<br>    * 哪些渠道的性价比最高，哪些渠道的用户质量最高，哪些渠道更便宜？<br>    * 如何让我们的网页在搜索引擎里取得更高的排名？<br>    * 怎样群发广告邮件能较好地避免被系统屏蔽或引发用户反感？</p>
<p>认知过程：<br>    * 我们是否以系统化的思维，正确地收集并分析了所有试验数据？<br>    * 我们挑选试验的标准，是基于手头的资源限制，还是预期产生的影响？<br>    * 我们是否在每一次的试验之前，清晰地提出了某种假设，并有意识地去验证它？<br>    * 对我们用户新增渠道影响最深远的一次近期变化是什么？我们花了多久发现并做出调整？</p>
<p>获得试验结论：<br>    * 我们是否有及时记录试验结论并交流分享的机制，还是它们只停留在参与者各自脑袋里？<br>    * 认知结论是否以一种便于分享的形式，对团队内的所有成员开放？<br>    * 我们是否坦然地交流了所有的认知结论，包括那些让人不快的负面结论？（记得 交流时邀请黑帽思考者参与。）<br>    * 是否有人刻意绕过某些障碍或掩盖错误，对影响认知结论的因素避而不谈？</p>
<h2 id="2-组建增长团队"><a href="#2-组建增长团队" class="headerlink" title="2 组建增长团队"></a>2 组建增长团队</h2><p><strong>增长黑客的工作</strong><br>    * 关注整个用户生命周期，而不仅仅是获客阶段<br>    * 通过数据驱动的方法，不断试验迭代<br>    * 将增长进制产品化，把增长做到产品里面去</p>
<p><strong>团队成员角色</strong><br>增长负责人、增长产品经理、增长工程师、设计师/交互设计师、增长营销经理、数据分析师等。</p>
<p><strong>增长团队日常工作</strong><br>主要围绕制定策略、实施方案、招聘人才、打造文化四项内容展开。</p>
<ul>
<li>制定策略<br>——  制定策略就是在采取下一步具体行动之前，对整体框架和路线图进行梳理，找出影响增长的方法、建立增长模型。<br>举个例子，你可以将增长策略分解为以下这些基本问题： 1）我应当如何提升下载/注册转化率？ 2）我能在用户初次使用的前N天内做些什么来激发活跃度？ 3）影响用户参与度和留存率的手段都有哪些？ 4）如何召回即将或已经流失的用户，让他们重新对产品发生兴趣？<br>接着，寻求解决上述问题的新渠道，或是对既有渠道进行优化改进，例如尝试病毒邀请机制、购买搜索引擎关键词、导入通讯录联系人、优化注册确认邮件送达率等。</li>
<li>实施方案<br>——  增长策略落实到执行阶段，就产生了待办列表上的一堆具体的计划任务。要做的是将这些点子，通过技术手段实现出来，并且不断打磨优化，提升方案的最终转化率。<br>值得注意的潜在细节包括但不限于： • 用按钮取代文字链接 • 测试按钮的位置、尺寸、用语和配色 • 提升页面和服务器的响应速度，降低延迟 • 优化网页标题、副标题、关键词、描述 • 应用适当的配图尺寸和文件格式 • 在页面加入客户证言来加强可信度 • 加入直观的宣传视频降低使用门槛 • 优化付费关键词对应的着陆页 • 简化注册表单，去除或延后非必要字段 • 用第三方账号授权登录代替注册独立账号 • 给用户施加社交压力，如写上“你的N个朋友正在使用” • 测试电子邮件的标题、内容、发送者地址、发送频率</li>
</ul>
<h2 id="3-提升协作效率"><a href="#3-提升协作效率" class="headerlink" title="3 提升协作效率"></a>3 提升协作效率</h2><h3 id="3-1-AARRR流量漏斗模型"><a href="#3-1-AARRR流量漏斗模型" class="headerlink" title="3.1 AARRR流量漏斗模型"></a>3.1 AARRR流量漏斗模型</h3><p><img src="https://img-blog.csdnimg.cn/20200714134346384.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>Acquisition（获取用户）</strong></p>
<p>互联网产品获取用户流量的常见手段繁多。<br>诸如： • 在目标人群集中的网站平台购买广告位 • 搜索引擎优化（SEO）及搜索引擎营销（SEM） • 内容营销、社群营销、病毒营销 • 撰写软文或公关稿 • 预装、刷机 当你成功吸引到网站的新房客，或是让应用被下载安装一次，AARRR流量漏斗就此启动运行。</p>
<p><strong>Activation（激发活跃）</strong></p>
<p>互联网产品可以通过交互界面和机制策略的设计，激发用户使用的活跃度，让他们尽快完成某些“指定动作”，从而产生商业价值。<br>例如： • 简化填写步骤，促使用户尽快填写并提交调查表 • 提供注册奖励，新用户绑定手机或信用卡即赠送5元代金券 • 加强被动引导，用排行榜、热门搜索等帮用户发现更多内容 • 预测购物偏好，将用户可能感兴趣的商品直接推荐到购物车 • 设置积分等级，用户发布一条微博或上传一张照片就能增加积分</p>
<p><strong>Retention（提高留存）</strong></p>
<p>留住一个老用户的成本要远远低于获取一个新用户的成本。为了再次赢回他们的注意力，提高留存率。<br>可以采取： • 增加高频刚需的功能，例如网盘自动为用户上传备份手机相册照片 • 优化产品性能，如判断用户的网络环境下载对应大小的数据包 • 定期发送产品升级优化的通知邮件，维持品牌曝光 • 用好友的私信提醒、陌生人添加好友的邀请等社交关系来召回 • 根据用户生命周期模型，在预测到用户可能流失时主动发送优惠折扣券</p>
<p><strong>Revenue（增加收入）</strong></p>
<p>以免费大行其道的互联网行业，除了直接向用户收费以外，还可以通过广告展示、业务分成、技术支持等方式向其他利益方收取费用。<br>常见的增加收入策略有： • 让电商顾客买更多东西，如捆绑推荐关联商品 • 让免费用户为增值服务买单，如层出不穷的QQ秀及网络游戏里的皮肤套装 • 为犹豫不决的潜在用户提供一个月免费试用，到期若不主动取消则自动续订 • 让已经付费者升级付费套餐，如视频网站的白银会员升级到黄金会员后，每月可享受更多独播大片 • 涨价，如付费社群可采用阶梯性定价，让晚加入者支付更高成本</p>
<p><strong>Referral（传播推荐）</strong></p>
<p>有关传播推荐的典型案例如下： • 以Dropbox为代表的云存储产品，若邀请到一名好友注册，双方就都能获赠额外250MB网络免费空间 • 互联网金融产品，邀请好友注册并绑定信用卡就能获赠10元礼金 • 打车应用订单完成后，向用户提供代金红包并鼓励分享给好友 • 图片社交产品，只有先分享到朋友圈才能解锁某款独特的滤镜或贴纸 • 在微信里开展的母婴电商、时尚潮品销售，可通过加盟代理和三级分销的方式获得订单优惠和返利</p>
<p>从获取用户到传播推荐，整个AARRR流量漏斗构成了一道产品使用周期的闭环。增长团队正是通过不断优化这五个关键步骤，减少每个环节中不必要的损耗，提高转化效率，从而不断扩大用户群体的数量和质量，为增长保驾护航。</p>
<h3 id="3-2-如何套用流量漏斗模型，提高转化率"><a href="#3-2-如何套用流量漏斗模型，提高转化率" class="headerlink" title="3.2 如何套用流量漏斗模型，提高转化率"></a>3.2 如何套用流量漏斗模型，提高转化率</h3><p>案例：信用卡优惠应用如何提升转化率</p>
<p>我的一客户朋友开发了一款展示信用卡优惠的手机应用。用户手动输入卡号或拍摄扫描，将信用卡绑定到个人账号后，就能定期收到这张卡的专属优惠信息，例如周二刷卡冰淇淋半价、周六电影票八折兑换等。</p>
<p>这款产品在早期推广时陷入了困境。用户并没有如预想的那样蜂拥而至，借助有限的免费推广渠道发布的营销广告和软文阅读曝光量寥寥。即使是注册用户，也在匆匆扫了几眼过后，就急不可耐地卸载了。这究竟是怎么一回事呢？</p>
<p>套用AARRR流量漏斗模型，分析了这款应用的流量转化路径。<br>• 获取用户：利用微信公众号做内容营销聚拢粉丝，提醒粉丝下载应用<br>• 激发活跃：引导用户绑定信用卡信息，作为推送内容的基础<br>• 提高留存：通过推送通知（Push Notification）等形式定期推送商家优惠券<br>• 增加收入：根据用户广告内容的点击和转化，向合作商家收取分成<br>• 传播推荐：邀请用户将有价值的内容分享出去</p>
<p>厘清上述转化脉络后，我们就可以针对每个环节加以优化。</p>
<p>• 在微信公众号里，原先每日推送的文章聚焦在信用卡使用知识上，受众狭窄，传播受限。既然我们的目标是以此聚集潜在用户，就不必苛求人群精准，而应当扩大基数，发布内容从“垂直人群的强需求”向“宽泛人群的普遍需求”转变，为下一步转化提供充足的“分母”。所以，调整后的策略是：增加优惠活动、美食旅行、品质生活等泛目标人群中喜闻乐见且有传播力的内容，提高攒粉速率。</p>
<p>• 提醒粉丝下载安装阶段，用小恩小惠增加说服的筹码：注册即送 10 元专享代金券，或是指定餐厅优惠体验资格（注意要与前面通过公众号文章吸引来的目标人群兴趣点吻合）。</p>
<p>• 不要在用户首次启动时，就立即催促他绑定信用卡，此时大部分人会有抵触心理。正确的做法是先让他自由地浏览，体验到产品的价值感，然后再试图诱导转化。例如在呈现的高质量优惠信息详情底部设置“立即领取”按钮，未绑卡用户一旦点击，就提醒他需要先绑卡才可享用。诉诸利益，而非恳请或强迫。</p>
<p>• 用户绑卡后，更聪明地向其推送优惠信息。比如，工作日侧重推送金融证券、商旅服务、正餐餐厅，周末则提供娱乐休闲聚会相关资讯。如果结合用户画像，效果更佳。</p>
<p>• 在尝到甜头时，才提醒分享，例如在成功兑换优惠之时提醒。</p>
<h3 id="3-3-从增长模型中挖掘机会"><a href="#3-3-从增长模型中挖掘机会" class="headerlink" title="3.3 从增长模型中挖掘机会"></a>3.3 从增长模型中挖掘机会</h3><p>创建增长模型的三个核心原则<br>    * 覆盖全面<br>    * 逻辑精简<br>    * 全员贯彻</p>
<p>增长模型应当形如：<br><img src="https://img-blog.csdnimg.cn/20200714135257832.PNG#pic_center" alt="在这里插入图片描述"><br>以美国最大的电商网站亚马逊为例，它的增长模型是：<br><img src="https://img-blog.csdnimg.cn/20200714135315661.PNG#pic_center" alt="在这里插入图片描述"><br>A=垂直品类拓展（Vertical Expansion）<br>B=单个垂直品类商品库存（Product Inventory Per Vertical）<br>C=单个商品页面浏览量（Traffic Per Product Page）<br>D=购买转化率（Coversion to Purchase）<br>E=客单价（Average Purchase Value）<br>F=重复购买行为（Repeat Purchase Behavior）</p>
<p>据此归纳出的亚马逊增长模型，可指导管理层关注三个增长方向：<br>    * 组织市场研究团队，探索新的商品品类和服务领域。<br>    * 调配采购团队，加强商品采购和货物流通。<br>    * 建立线上优化团队，运用SEO、付费广告、A/B测试等途径优化页面浏览到下单购买的整个流程。</p>
<p>增长模型左边的增长目标以具体的数字指标体现，是你的核心指标，又被称作“North Star Metric”（北极星指标），或“OMTM”（One Metric That Matters，即唯一重要的指标）。</p>
<p>设定核心指标时，必须避免 <label style="color:red">“虚荣指标”（Vanity Metric）</label>，也就是让团队误以为自己好像在进步，但实际上却没有取得什么进展的浮夸指标。如：点击量、页面浏览量（PV）、访问量、独立访客数、粉丝/好友/赞的数量、网站提留时间/浏览页数、收集到的用户邮件地址数量、下载量。</p>
<p>以下是一组不同公司核心指标的范例：<br>• 亚马逊，做的是电商购物的生意，核心指标是“商品销量额”。<br>• Medium，一家作者与读者交换故事想法的在线创作社区，核心指标是“总阅读时长”。<br>• Quora，允许专家以问答形式将知识技能分享给全世界，核心指标是“有多少问题被回答”。<br>• Airbnb，作为双边市场服务，作用是连接房东和住客，核心指标是“有多高比例的整晚房间被租赁出去”。<br>• Uber，同样是一家双边市场服务，赋予司机和乘客随时匹配的权利，Uber 的核心指标并非“有多少辆车成功搭载乘客”，而是“乘客从叫车到上车之间的平均候车时长”——这更能体现某一地区驾乘双方的用户密度、匹配算法的智能性。</p>
<p>核心指标通常是复合因素作用下的衡量标准。为了提升核心指标，你必须将它分解成若干个彼此关联且共同产生影响的关键指标（可能包含二级指标、三级指标甚至更多），然后分别去优化各自的影响因素，从而自下而上地影响核心指标。如：<br><img src="https://img-blog.csdnimg.cn/20200714135545864.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>例： 早在2007年4月前，Google的广告展示中使用了大面积的矩形区域作为背景，只要用户点击整个矩形区域，就视作产生广告点击，广告主需为此付费。看起来，更大的点击面积的确让人点击时移动鼠标更省眼力，促进点击率剧增，Google能因此获得更多收入。 但出乎意料的是，Google创始人自断一指，突然宣布将广告可点击区域限制在标题和链接区域，这对营收产生了负面影响。广告点击模式改变后数月间，Google的股票价格从2007年11月的740多美元，一路倾泻到了2008年年中的350多美元，引发了资本市场和科技评论圈的轩然大波。自此，很多媒体和出版商的点击转化率和收入都大幅下降。</p>
<p>果不其然，坚持带来了最终的胜利。Google的收入随后开始快速增长，估价也水涨船高，之前的变动被证明是有远见的，Google广告系统的收入日渐提升，成为Google公司的支柱性收入之一。</p>
<p>这里的奥妙可以用下面的增长模型解释：<br><img src="https://img-blog.csdnimg.cn/20200714135707102.PNG#pic_center" alt="在这里插入图片描述"><br>其中，每个指标对应的含义分别是：<br>• CPM：每千次展示给Google带来的收入。CPM越高代表Google赚钱越多。<br>• Coverage：广告覆盖率。广告覆盖率=出现广告的页面/所有页面。使用Google搜索时，浏览了10个页面，其中5个页面出现广告，则Coverage为50%。Google的Coverage大约是1/3。<br>• Depth：平均每页广告数。页面上广告数越多，整体展示量越高，但同时每个广告的点击率也可能更低。Google的Depth是每个页面1-3条广告。<br>• CTR：点击转化率。上面已经提到过。<br>• CPC：单次点击费用。上面也已提到过。 </p>
<p>绝大多数广告平台倾向于提升Coverage和Depth，因为CTR取决于用户，CPC则取决于广告主。为了确保用户体验，Google严格遵守广告少而精的策略，决定放弃Coverage和Depth，着力于CTR和CPC。 塞翁失马，焉知非福。虽然刚开始限制点击区域的改动，短期内降低了CTR，但正是由于成功减少了大量的意外点击，随着用户真实点击百分比的提高，广告主看到了每个点击更真实的价值，满意度也随之提高。广告主更愿意去买点击广告，触发了更高的单次点击费用。加之 Google 采用机器学习等技术帮助广告主增强展示的精准性，因此整体收入不降反升。</p>
<h3 id="3-3-建立团队内部协作流程"><a href="#3-3-建立团队内部协作流程" class="headerlink" title="3.3 建立团队内部协作流程"></a>3.3 建立团队内部协作流程</h3><p>打造自增长产品的创意始于增长模型， 这套流程主要由以下五个核心环节组成：<label style="color:red">头脑风暴&gt;确定优先级&gt;小规模测试&gt;动手研发&gt;持续优化</label></p>
<p><strong>第一步：头脑风暴，提出假设</strong><br>增长团队协作流程的原点，就是提出假设。假设是有根据的猜测，这些猜测在日后 能被证实或证伪，最终服务于产品迭代。<br>可证伪的假设=[具体并且可重复的动作]可以导致[预期中可评估的目标或结果]</p>
<p>头脑风暴是激发团队提出假设的常规方式。请试着怀揣开放心态，让所有人都参与进来，鼓励每个人都提出自己的意见。如 • 改变按钮文字 • 尝试不同平台 • 修改定价策略 • 将某个流程前置或后置 • 针对不同人群投放广告 • 发起一场营销活动 • 推翻重构产品界面头脑风暴的前提是：确立了明确的指标，并对产品增长模型有清晰认识。否则，很容易陷入一群人在会议室天马行空、乱枪打鸟的窘境，那绝对是你不愿看到的。</p>
<p>头脑风暴的基本原则是： • 推迟判断 • 鼓励大胆的创意 • 基于他人的创意延伸 • 不要偏题 • 一次只有一个人说话 • 借助视觉语言 • 追求数量</p>
<p>提出头脑风暴创意的方式： • 观察法：用户是如何使用的？竞争对手都做了些什么（从竞争对手那里偷师，先模仿再超越，切忌为了不同而不同）？行业内有什么新知创想？你的数据给了你哪些启发？ • 关联法：将产品流程与生活中的事物建立连接。例如，现实中的实体店铺经营有哪些值得借鉴的经验，可以用到我们的电商服务中？ • 社群法：创建或加入增长黑客们的圈子，在交流碰撞中迸发更多创意火花。 • 提问法：不妨自己设问，为什么会这样？如果我们XX，会怎样？还有哪些因素与XX有关？</p>
<p>一张好的备选创意列表（Backlog），应当包含如下项目： • 名称：为头脑风暴提出的创意取个名字。 •状态：创意尚处在想法阶段，还是正在设计试验中，或者试验已经设计完成。 • 分类：帮助团队成员明确这一试验服务的产品阶段。 • 指标：用哪项（些）指标判断试验是否成功。 • 预期结果：无论是拍脑袋还是基于以往数据经验，都要对试验结果有一定的预 期，通过将实际结果与预期结果的比较，增强对产品和市场的理解。 • 评估工时：涉及试验的各部门需要耗费的人员和天数。<br><img src="https://img-blog.csdnimg.cn/20200714140014179.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><strong>第二步：确定优先级</strong><br>当资源有限时，面对长长的备选创意列表，分析每个创意值不值得优先做、花多少精力去做时，可以从以下三个维度评估：<br>• 收益值，即在当下或长期将为增长带来多大贡献。<br>• 消耗量，即需要花费的资源数量，包括资金、人力、时间、心智。<br>• 半衰期，即这项收益随时间衰减的速度，半衰期越长，影响维持越久。</p>
<p>如果我们从这三个维度划分不同的增长策略，由此便可得到由其组合成的八类策略：<br>• 高收益值、低消耗量、长半衰期策略：Hotmail 的签名档病毒推广、Dropbox邀请好友送空间。<br>• 高收益值、低消耗量、短半衰期策略：Airbnb借Craiglist邮件系统群发广告（很快被封）。<br>• 高收益值、高消耗量、长半衰期策略：Facebook 每天同时进行的数百项 A/B测试。<br>• 高收益值、高消耗量、短半衰期策略：绞尽脑汁做出红极一时的爆款病毒推广方案。<br>• 低收益值、高消耗量、长半衰期策略：彻底重构产品，优化整体架构。<br>• 低收益值、低消耗量、长半衰期策略：发布软文，使用有趣的产品文案。<br>• 低收益值、高消耗量、短半衰期策略：挨个手动发广告私信骚扰陌生网民。<br>• 低收益值、低消耗量、短半衰期策略：发布一条微博（假定你不是百万粉丝大V）。</p>
<p>据此对你收集到的方案做出筛选，更加着眼于高收益、低消耗、长半衰期的策略，而不是纠结于无关痛痒的细节，比如争论页面使用圆角还是直角、更换测试不同深度的40种蓝色，这对于初创公司来说完全没有任何意义。</p>
<p>另一种便于量化的优先级评估方式，是我们在咨询工作中总结出的 <label style="color:red">T.W.I.C.E 原则</label>。具体说来，它包括以下五项评定指标：</p>
<p>1.流量Traffic（1分最低，5分最优）<br>多少人能看到这项变化？你的改动是深埋在设置选项中，还是挂在网站首页？一项改动所触及的用户量是它能否产生作用的前提条件。<br>2.口碑Word of Mouth（1分最低，5分最优）<br>你的创意是否能促成显著的口碑传播效应？正面口碑，还是负面口碑？大多数改动在用户眼中无关痛痒，他们只是默默地接受；有些改动则让人眼前一亮，具备利于营销的话题点；还有些则可能引发特定人群的抵触情绪，你必须准备好危机公关预案。<br>3.影响力Impact（1分最低，5分最优）<br>你对于方案能产生多少影响力的预期如何？如果你的注册转化率只有10%，那么将它改善到20%就已经是100%的提升。如果80%的用户顺利走完注册转化漏斗，那么将这一数字改善为90%也不过是12.5%的提升。<br>4.自信心Confidence（1分最低，5分最优）<br>你的想法是通过借鉴别人既有的成功案例而升华归纳产生或者从信源靠谱的实践者那里汲取灵感，还是仅限于上班路上的灵光一现，缺乏数据支持和参考坐标？<br>5.实现难易度Ease（1分最低，5分最优）<br>新方案是否能在几个小时内就完成MVP并被测试？抑或需要数天乃至数周的努力？尽可能优先考虑最简单易行的解决方案，而不是邀功式地追求工作量和加班时长。</p>
<p>优先考虑最简单易行的解决方案。 需要为上述五项评估指标分别打分，最终筛选出得分最高的备选创意，列为最优之选。</p>
<p><strong>第三步：不断测试</strong><br>真正可持续的增长是通过小规模测试的不断迭代，验证试验假设，并将成功结果不断累加的过程。</p>
<p>• 首先，你要确认某个标准，用这个标准来判定每次改动或迭代是否成功。标准本身既可以是量化指标（比如有多少人点击注册按钮、有多少乘客叫车），也可以是定性指标（比如易用性），又或者是两者兼有。<br>• 一旦大家对成功的定义有了共识，那么接下来就是不断尝试各种方法，提出不同的假设，围绕假设去做试验。<br>• 当试验完成后，展开一次数据调研。如果达到了理想的预期目标，则之前的假设成立，可以全方位启用这项设计，然后马不停蹄地继续寻找下一个增长点；如果没有达到理想状态，则必须从难以立足的伪命题上吸取经验，反思总结，然后在解决 方案上迭代更新。</p>
<p><strong>第四步：动手研发</strong><br>在小规模测试有所成效的前提下，动手将你的增长创意开发成实际功能。</p>
<p>需遵循以下三个原则：</p>
<ul>
<li>不要重复发明轮子<br>——  在如今这个 SaaS 横行、随手可用的时代，大多数初创公司不会有技术风险。过度关注技术是一种浪费。你应该将注意力更多放在研发过程的科学性、结论导出的准确性和对指标的影响上。如果市场上有现成的工具，那么就尽量挪为己用。</li>
<li>内容动态化<br>——  增长黑客们总在思考如何用最少的代价来实现一件事情。如果研发阶段采取的方案缺乏灵活性，将可能造成后续维护时成本过高——最直接的体现，就是必须等待下一个版本的发布上线，才能修复问题或测试一个全新的创意，这有可能延误宝贵时机。为此，必须考虑在实现阶段尽可能将业务模块动态化。</li>
<li>让机器替你自动化执行<br>——  交给机器自动执行，从而将宝贵的智力资源节省出来，投入到创造新的增长策略中。如将手动发送邮件变成自动回复、让人工处理数据变为脚本抓取。</li>
</ul>
<p><strong>第五步：持续优化</strong><br>善于学习的团队能够从过往成功经验中总结出经验，提高下一次临门一脚的胜算。为此你应当将每次试验过程和数据记录下来，并且公开与全体成员分享。</p>
]]></content>
      <categories>
        <category>产品/运营</category>
      </categories>
      <tags>
        <tag>用户增长</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】单变量线性回归(Linear Regression with One Variable)</title>
    <url>/2020/07/06/%5BMachine%20Learning%5D%20%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92(Linear%20Regression%20with%20One%20Variable)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200706191025292.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="2-Linear-Regression-with-One-Variable-单变量线性回归"><a href="#2-Linear-Regression-with-One-Variable-单变量线性回归" class="headerlink" title="2 Linear Regression with One Variable(单变量线性回归)"></a>2 Linear Regression with One Variable(单变量线性回归)</h2><h3 id="2-1-Case-Housing-Prices"><a href="#2-1-Case-Housing-Prices" class="headerlink" title="2.1 Case: Housing Prices"></a>2.1 Case: Housing Prices</h3><p>使用数据集预测住房价格，数据集包含某市的不同房屋尺寸所售出的价格。<br><img src="https://img-blog.csdnimg.cn/20200706132157519.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">)<img src="https://img-blog.csdnimg.cn/20200706131824876.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>其中，ℎ 代表学习算法的解决方案或函数也称为==假设（hypothesis）==。</p>
<p>这就是一个监督学习算法的工作方式，在学习算法下，输入训练集里的房屋价格，然后输出一个函数，通常表示为小写 ℎ表示。ℎ 代表 hypothesis(假设)，ℎ表示一个函数，输入是房屋尺寸大小，因此 ℎ 根据输入的 𝑥值来得出 𝑦 值，𝑦 值对应房子的价格。因此，ℎ 是一个从𝑥到 𝑦 的函数映射。</p>
<p>那么，对于房价预测问题，该如何表达 ℎ？</p>
<p>一种可能的表达方式为：ℎ𝜃(𝑥) = 𝜃0 + 𝜃1𝑥，因为只含有一个特征/输入变量，因此这样的问题叫作==单变量线性回归问题(Linear Regression with One Variable)==。</p>
<h3 id="2-2-Cost-Function-代价函数"><a href="#2-2-Cost-Function-代价函数" class="headerlink" title="2.2 Cost Function(代价函数)"></a>2.2 Cost Function(代价函数)</h3><p><img src="https://img-blog.csdnimg.cn/2020070613382955.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在线性回归中有一个训练集，其预测的函数形式是：ℎ𝜃(𝑥) = 𝜃0 + 𝜃1𝑥。接下来要做的便是为模型选择合适的参数（parameters）𝜃0 和 𝜃1，在房价问题这个例子中便是直线的斜率和在𝑦 轴上的截距。</p>
<p>选择的参数决定了所得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是==建模误差（modeling error）==。</p>
<p><img src="https://img-blog.csdnimg.cn/20200706135220962.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>目标便是选择出可以使得建模误差的平方和能够最小的模型参数， 即让代价函数：<img src="https://img-blog.csdnimg.cn/20200706135354668.PNG#pic_center" alt="在这里插入图片描述">最小。</p>
<p>如图一个等高线图，三个坐标分别为𝜃0和𝜃1 和𝐽(𝜃0, 𝜃1)：<br><img src="https://img-blog.csdnimg.cn/20200706135500768.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>则可以看出在三维空间中存在一个使得𝐽(𝜃0, 𝜃1)最小的点。</p>
<p>在实际问题上，我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们需要的是编写程序来找出这些最小化代价函数的𝜃0和𝜃1的值。</p>
<p>==代价函数  (Cost Function)== 也被称作平方误差函数，有时也被称为平方误差代价函数。之所以要求出误差的平方和，是因为对于大多数问题，特别是回归问题，误差平方代价函数都是一个合理的选择。虽然还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回归问题最常用的手段了。<br><img src="https://img-blog.csdnimg.cn/20200706141519668.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述">)<img src="https://img-blog.csdnimg.cn/20200706141307651.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="2-3-Gradient-Decent-梯度下降"><a href="#2-3-Gradient-Decent-梯度下降" class="headerlink" title="2.3 Gradient Decent(梯度下降)"></a>2.3 Gradient Decent(梯度下降)</h3><p>==梯度下降(Gradient Decent)== 是一个用来求函数最小值的算法，可使用梯度下降算法来求出代价函数𝐽(𝜃0, 𝜃1) 的最小值。</p>
<p>梯度下降含义是：开始时随机选择一个参数的组合(𝜃0, 𝜃1, . . . . . . , 𝜃𝑛)，计算代价函数，然后寻找下一个能让代价函数值下降最多的参数组合。持续这么做直到到到一个局部最小值（local minimum），因为并没有尝试完所有的参数组合，所以不能确定所得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。<br><img src="https://img-blog.csdnimg.cn/20200706144357901.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>例如，你站立在这座红色山上，寻找最快下山的方向。在梯度下降算法中，我们要做的就是旋转 360 度，发现最佳的下山方向，然后按照判断迈出一步，再在新的一个点重复上面的步骤，决定从什么方向将会最快下山，并依此类推，直到接近局部最低点的位置。</p>
<p>==批量梯度下降（batch gradient descent）== 算法的公式为：<br><img src="https://img-blog.csdnimg.cn/202007061443109.PNG#pic_center" alt="在这里插入图片描述"><br>其中𝑎是学习率（learning rate），它决定了沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，每一次都同时让所有的参数减去学习速率乘以代价函数的导数。</p>
<p><img src="https://img-blog.csdnimg.cn/2020070614584344.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在梯度下降算法中，左边是正确实现<strong>同时</strong>更新的方法。</p>
<p>梯度下降算法如下：<br><img src="https://img-blog.csdnimg.cn/20200706154630872.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>描述：对𝜃赋值，使得𝐽(𝜃)按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。<br><img src="https://img-blog.csdnimg.cn/20200706161527701.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>图中上方红色切线的斜率是正，也就是说它有正导数，因此可得到的新的𝜃1，𝜃1更新后等于𝜃1减去一个正数乘以𝑎。相反，图中下方红色切线的斜率是负。</p>
<p><strong>如果𝑎太小或𝑎太大会出现什么情况：</strong></p>
<ul>
<li>如果𝑎太小了，即我的学习速率太小，结果就是像蜗牛一样一点点地挪动，不断接近最低点，这样就需要很多步才能到达最低点，所以如果𝑎太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。</li>
<li>如果𝑎太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果𝑎太大，它会导致无法收敛，甚至发散。</li>
</ul>
<p><strong>如果预先把𝜃1放在一个局部的最低点，下一步梯度下降法会怎样工作？</strong></p>
<ul>
<li>假设将𝜃1初始化在局部最低点，那么它已经在一个局部的最优处或局部最低点，导数将等于零。这意味着该点已经在局部最优点，它使得𝜃1不再改变，也就是新的𝜃1等于原来的𝜃1，因此，如果参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率𝑎保持不变时，梯度下降也可以收敛到局部最低点。</li>
</ul>
<h4 id="2-3-1-Case-Cost-Function-of-Gradient-Descent"><a href="#2-3-1-Case-Cost-Function-of-Gradient-Descent" class="headerlink" title="2.3.1 Case: Cost Function of Gradient Descent"></a>2.3.1 Case: Cost Function of Gradient Descent</h4><p>例子：<br><img src="https://img-blog.csdnimg.cn/20200706161618177.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>为了找到最小值，首先初始化梯度下降算法，在那个粉红色的点初始化，如果更新一步梯度下降，到了绿色的点。不断更新，越来越接近最低点，导数也越来越接近零。所以随着梯度下降法的运行，移动的幅度会自动变得越来越小，直到最终移动幅度非常小，收敛到局部极小值。</p>
<p>总结一下，在梯度下降法中，当接近局部最低点时，梯度下降法会自动采取更小的幅度，实际上没有必要再另外减小𝑎。这是因为在局部最低点时导数等于零，当接近局部最低时，导数值会自动变得越来越小。</p>
<h4 id="2-3-2-Gradient-Descent-For-Linear-Regression-梯度下降的线性回归"><a href="#2-3-2-Gradient-Descent-For-Linear-Regression-梯度下降的线性回归" class="headerlink" title="2.3.2 Gradient Descent For Linear Regression(梯度下降的线性回归)"></a>2.3.2 Gradient Descent For Linear Regression(梯度下降的线性回归)</h4><p>梯度下降算法和线性回归算法比较如图：<br><img src="https://img-blog.csdnimg.cn/20200706162727647.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200706163111965.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>则算法可改写为：<br><img src="https://img-blog.csdnimg.cn/20200706163141859.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>上面的算法有时也称为==批量梯度下降(“Batch” Gradient Descent，简称：BGD)== ，指的是在梯度下降的每一步中，都会用到所有的训练样本，在计算微分求导项时，需要进行求和运算，所以，在每一个单独的梯度下降中，最终都要计算这样一个东西，这个项需要对所有𝑚个训练样本求和。因此，批量梯度下降法这个名字说明了需要考虑所有这一”批”训练样本，而事实上，也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】正则化(Regularization)</title>
    <url>/2020/07/08/%5BMachine%20Learning%5D%20%E6%AD%A3%E5%88%99%E5%8C%96(Regularization)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200708161032267.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="5-Regularization-正则化"><a href="#5-Regularization-正则化" class="headerlink" title="5 Regularization(正则化)"></a>5 Regularization(正则化)</h2><h3 id="5-1-The-problem-of-overfitting"><a href="#5-1-The-problem-of-overfitting" class="headerlink" title="5.1 The problem of overfitting"></a>5.1 The problem of overfitting</h3><p><strong>case1：</strong><br><img src="https://img-blog.csdnimg.cn/20200708133431983.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>第一个模型是一个线性模型，欠拟合，不能很好地适应训练集；</li>
<li>第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。即，若给出一个新的值使之预测，它将表现的很差；</li>
<li>而中间的模型似乎最合适。</li>
</ul>
<p><strong>case2：</strong><br><img src="https://img-blog.csdnimg.cn/20200708134042138.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>同上。</p>
<p><strong>过拟合的解决方法</strong><br><img src="https://img-blog.csdnimg.cn/20200708134338840.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="5-2-Cost-Function"><a href="#5-2-Cost-Function" class="headerlink" title="5.2 Cost Function"></a>5.2 Cost Function</h3><p>上面的回归问题中模型是：<br><img src="https://img-blog.csdnimg.cn/20200708135115992.PNG#pic_center" alt="在这里插入图片描述"><br>一般而言，正是那些高次项导致了过拟合的产生，所以如果能让这些高次项的系数接近于 0 的话，就能很好的拟合了，所以可以在一定程度上减小这些参数𝜃 的值，这正是正则化的基本方法。当要减少𝜃3和𝜃4的大小，需要做的便是修改代价函数，在其中𝜃3和𝜃4 设置一点惩罚。在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的𝜃3和𝜃4。</p>
<p>修改后的代价函数：<br><img src="https://img-blog.csdnimg.cn/2020070813555675.PNG#pic_center" alt="在这里插入图片描述"><br>通过这样的代价函数选择出的𝜃3和𝜃4 对预测结果的影响就比之前要小许多。假如有非常多的特征，并不知道其中哪些特征需要惩罚，可以将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：<br><img src="https://img-blog.csdnimg.cn/20200708135853580.PNG#pic_center" alt="在这里插入图片描述"><br>其中𝜆又称为==正则化参数（Regularization Parameter）==。 注：根据惯例，我们不对𝜃0 进行惩罚。经过正则化处理的模型（粉色）与原模型（蓝色）的可能对比如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020070814004971.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如果选择的正则化参数 λ 过大，则会把所有的参数都最小化了，那么𝜃（不包括𝜃0）都会趋近于 0，这样我们所得到的只能是一条平行于𝑥轴的直线，模型变成 ℎ<sub>𝜃</sub>(𝑥) =𝜃<sub>0</sub>，造成欠拟合。</p>
<h3 id="5-3-Regularizede-linear-regression-正则化线性回归"><a href="#5-3-Regularizede-linear-regression-正则化线性回归" class="headerlink" title="5.3 Regularizede linear regression(正则化线性回归)"></a>5.3 Regularizede linear regression(正则化线性回归)</h3><p>对于线性回归的求解，之前推导了两种学习算法：一种基于梯度下降，一种基于正规方程。</p>
<p>正则化线性回归的代价函数为：<br><img src="https://img-blog.csdnimg.cn/20200708142309532.PNG#pic_center" alt="在这里插入图片描述"><br>如果要使用梯度下降法令这个代价函数最小化，因为未进行正则化，所以梯度下降算法将分两种情形：<br><img src="https://img-blog.csdnimg.cn/20200708142428802.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对上面的算法中𝑗 = 1,2, . . . , 𝑛 时的更新式子进行调整可得：<br><img src="https://img-blog.csdnimg.cn/2020070814252032.PNG#pic_center" alt="在这里插入图片描述"><br>可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令𝜃值减少了一个额外的值。</p>
<p>注：在梯度下降时，对任意的θ<sub>j</sub>的处理可以分为两部分，J(θ)的偏导数 + 单独针对该θ<sub>j</sub>的正则化项。</p>
<p>同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示：<br><img src="https://img-blog.csdnimg.cn/20200708155229540.PNG#pic_center" alt="在这里插入图片描述"><br>图中的矩阵尺寸为 (𝑛 + 1) ∗ (𝑛 + 1)。</p>
<h3 id="5-4-Regularized-Logistic-Regression-正则化的逻辑回归模型"><a href="#5-4-Regularized-Logistic-Regression-正则化的逻辑回归模型" class="headerlink" title="5.4 Regularized Logistic Regression(正则化的逻辑回归模型)"></a>5.4 Regularized Logistic Regression(正则化的逻辑回归模型)</h3><p>针对逻辑回归问题，之前已学习过两种优化算法：首先学习了使用梯度下降法来优化代价函数𝐽(𝜃)，接下来学习了更高级的优化算法，这些高级优化算法需要自己设计代价函数𝐽(𝜃)。<br><img src="https://img-blog.csdnimg.cn/20200708160007681.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对于逻辑回归，代价函数正则化的表达式：<br><img src="https://img-blog.csdnimg.cn/20200708160155875.PNG#pic_center" alt="在这里插入图片描述"><br>要最小化该代价函数，通过求导，得出梯度下降算法为：<br><img src="https://img-blog.csdnimg.cn/20200708160313567.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>注：看上去同线性回归一样，但是知道 ℎ<sub>𝜃</sub>(𝑥) = 𝑔(𝜃<sup>𝑇</sup>𝑋)，所以与线性回归不同。𝜃<sub>0</sub>不参与其中的任何一个正则化。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>《增长黑客实战》（第4-6章）</title>
    <url>/2020/07/16/%E3%80%8A%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2%E5%AE%9E%E6%88%98%E3%80%8B%EF%BC%88%E7%AC%AC4-6%E7%AB%A0%EF%BC%89/</url>
    <content><![CDATA[<p>![在这里插入图片描述](<a href="https://img-blog.csdnimg.cn/2020071414080124.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" target="_blank" rel="noopener">https://img-blog.csdnimg.cn/2020071414080124.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center</a> =242x320)</p>
<a id="more"></a>

<h2 id="4-秉持数据为王"><a href="#4-秉持数据为王" class="headerlink" title="4 秉持数据为王"></a>4 秉持数据为王</h2><h3 id="4-1-数据能够解决什么"><a href="#4-1-数据能够解决什么" class="headerlink" title="4.1 数据能够解决什么"></a>4.1 数据能够解决什么</h3><h4 id="4-1-1-是否一切皆可数据化衡量"><a href="#4-1-1-是否一切皆可数据化衡量" class="headerlink" title="4.1.1 是否一切皆可数据化衡量"></a>4.1.1 是否一切皆可数据化衡量</h4><p><strong>如何估算芝加哥有多少钢琴调音师？</strong><br>解答：芝加哥人口大约300万人，假设平均10-30个家庭中有一部钢琴，每部钢琴大约一年需要调音一次，每个调音师每天大约调音4-5家，每个调音师每年工作250天。那么，上述问题答案可由以下公式求得：<br><img src="https://img-blog.csdnimg.cn/20200715151232307.PNG#pic_center" alt="在这里插入图片描述"></p>
<p><strong>婚姻幸福相当于收入增加多少带来的快乐？</strong><br>英国伦敦大学的研究人员对1万名英国人的快乐程度、财富、健康和社会关系进行了调查，他们把受调查者的“生活满意度”从高到低划分为7个级别，计算出人们每提升一个“生活满意度”级别，每年需要多挣多少钱。<br>通过对比这两类数据，研究人员计算出了每个社会因素和生活方式因素所对应的“价格”。比如，婚姻幸福和每年多赚5.4万英镑所带来的欢乐相当，两个人同居所带来的快乐等同于每年多赚8.25万英镑，经常和邻居聊天所感受到的快乐则相当于每年多赚4万英镑。</p>
<p>真正的量化过程不需要无限精确。尽管公共事业及各类投资、商业管理决策中所需要量化的数据往往看起来异常复杂，难以获取。但只要先明确待量化的内容，找出核心问题，或是将一个笼统问题层层分解、剥离，对含糊的概念做出清晰的定义，就能为数据驱动的决策提供良好解决办法。换而言之，如果你提不出任何数据化衡量的思路，说明你对问题理解得还不够深刻。</p>
<h4 id="4-1-2-数据不能解决什么"><a href="#4-1-2-数据不能解决什么" class="headerlink" title="4.1.2 数据不能解决什么"></a>4.1.2 数据不能解决什么</h4><p><strong>1.数据不懂社交情绪</strong><br>计算机擅长为社交产品定量，而非定性。数据分析师能够获悉你在过去一周内47%的使用时长用于跟新认识的好友聊天，但却无法捕捉到你心底对一年仅能见2次面的儿时玩伴的牵挂。</p>
<p>例：Facebook通过数据掌握了用户对发布和查看照片功能的喜爱，于是着力于让平台产生更多照片。平台价值也随着用户数据资产的沉淀而不断增值。但反其道而行之的产品Snapchat一经推出，让不少青少年用户纷纷改旗易帜。因为Snapchat开创的“阅后即焚”社交产品模式，允许用户在发送照片后的几秒钟内，立即自动清除。这转瞬即逝的互动形式，反倒刺激了用户的紧迫感和创造力，人们得以毫无顾忌地肆意使用。Snapchat每天产生的照片及视频上传量，甚至一度击败了Facebook，让后者不得不考虑收购或模仿。</p>
<p><strong>2.数据无法理解业务背景</strong><br>人类的决策并不都是独立离散的事件，而是镶嵌在时间序列和背景之中。数据本身不懂得如何叙事，也无法理解思维的浮现过程。我们掌握的数据越多，统计上显著相关的变量也愈发繁杂，而变量之间如何作用、权重高低如何设置，以及如何排除没有实际意义的干扰变量，则需要结合背景考虑。</p>
<p>例：一款异性交友产品，出现大量优质女用户流失的现象。通过数据分析，原来是因为她们动辄每天收到数十条陌生人的聊天骚扰。在简单地与女性用户沟通后，我们产生了做一个“一键清除未读信息”的功能。满怀信心地将功能发布上线，却意外发现用户并不买账，留存曲线并没有因此更好看。直到参与一场线下的圆桌访谈，才找到了个中症结：她们之所以并不打算使用“一键清除未读消息”，是故意想留着未读消息数量的数字，在各种场合假装不经意地晒出截图，彰显自己的人气——被骚扰越多，反而显得越有魅力。如果不去理解用户使用的背景和微妙的心态，光靠观察数据仪表盘，我们是不可能领悟到这一重要需求的。</p>
<p><strong>3.数据抹杀创新精神</strong><br>曾经借力Facebook平台大热的社交游戏公司星佳（Zynga）强调常态化地检测用户身份和他们的行为。通过分析用户一段时间内在游戏中与其他玩家的交互行为、前N天内建造的房子数目、前 M 个小时内杀死的怪物个数等，他们便可以知道用户达成参与的关键点，并设计出符合玩家需要的游戏。但也正是这样投其所好亦步亦趋的刻板设计，抹杀了游戏作为一款感性产品的创新精神。在固有测试模板下生成的流水线游戏，绝不可能产生让人耳目一新、大放异彩的特性，新的模式、特性、剧情必须仰赖游戏创造者灵光一闪的创造力。最终，玩家在厌烦了社交游戏的惯常套路后纷纷流失，星佳游戏黯然衰落。</p>
<h3 id="4-2-数据分析常见方法及指标"><a href="#4-2-数据分析常见方法及指标" class="headerlink" title="4.2 数据分析常见方法及指标"></a>4.2 数据分析常见方法及指标</h3><h4 id="4-2-1-数据分析的一般步骤"><a href="#4-2-1-数据分析的一般步骤" class="headerlink" title="4.2.1 数据分析的一般步骤"></a>4.2.1 数据分析的一般步骤</h4><p>培养数据分析能力，可以从两方面着手：一是数据分析方法论的建立，二是以入门到精通的方式掌握数据分析的技能。</p>
<p>数据分析的一般步骤及其需要掌握的技能点，如下所述。</p>
<p><strong>第一步：数据准备（这很可能花费你70%的时间）</strong><br>• 获取数据（爬虫抓取、基于自有数据仓库）<br>• 验证数据<br>• 数据清洗（包括对缺失值、孤立点、垃圾信息、规范化、重复记录、特殊值、合并数据集的处理）<br>• 使用Python进行文件读取，导出为csv或者txt格式便于操作加工<br>• 数据抽样（数据量大时常用随机抽样提取子数据集）<br>• 存储和归档</p>
<p><strong>第二步：数据观察（发现规律和隐藏的关联）</strong><br>• 单一变量：点图、抖动图、直方图、核密度估计等<br>• 两个变量：散点图、LOESS平滑、残差分析、对数图、斜率等<br>• 多个变量：假色图、马赛克图、平行坐标图等</p>
<p><strong>第三步：数据建模</strong><br>• 推算和估算（均衡可行性和成本消耗）<br>• 缩放参数模型（缩放维度优化问题）<br>• 建立概率模型（二项、高斯、幂律、几何、泊松分布与已知模型对比）</p>
<p><strong>第四步：数据挖掘</strong><br>• 选择合适的机器学习算法（如蒙特卡洛模拟、相似度计算、主成分分析）<br>• 大数据考虑用Map/Reduce<br>• 得出结论，最后绘制图表展示</p>
<h4 id="4-2-2-留存率——产品早期“最重要的唯一指标”"><a href="#4-2-2-留存率——产品早期“最重要的唯一指标”" class="headerlink" title="4.2.2 留存率——产品早期“最重要的唯一指标”"></a>4.2.2 留存率——产品早期“最重要的唯一指标”</h4><p>在用户获取和留存之间，增长团队主要负责的是用户获取，而留存率则主要取决于产品。当产品还没有达到真正的P/MF阶段前，增长对于公司来说都是徒劳的。如果留存率很低，那么先把重点放在产品的改进、市场方向的调整上，而不是继续加速扩张宣传。</p>
<p>为了找出影响留存率的关键因素，可以尝试向用户询问下面4个问题：<br>• 最初是什么因素驱动你注册账号试用我们的产品？<br>• 产品哪些地方没有达到你的预期，或是觉得很难使用？<br>• 停用一阵后，你为什么愿意再次回来使用？<br>• 哪些因素会让你倾向于今后更频繁地使用？</p>
<p>此外，如果统计代码部署得当，足以观测每一个单体用户的使用行为，那么去“死亡现场”勘探一下——也就是观测那些流失用户的最后一次使用行为，看看他们走过哪些路径、干了哪些事情、有哪些痛点还未解决，借此模拟用户流失的场景，寻求维护优化策略。</p>
<h4 id="4-2-3-NPS净推荐值：衡量产品早期用户忠诚度"><a href="#4-2-3-NPS净推荐值：衡量产品早期用户忠诚度" class="headerlink" title="4.2.3 NPS净推荐值：衡量产品早期用户忠诚度"></a>4.2.3 NPS净推荐值：衡量产品早期用户忠诚度</h4><p>在创业型团队早期研发中，缺乏海量的数据反馈，面对数量有限的种子用户，NPS净推荐值系统是一种结合了定量研究手段和定性分析的有效方法。</p>
<p><label style="color:red">NPS（Net Promoter Score），净推荐值系统</label>，是一种计量某个客户将会向其他人推荐公司产品或服务可能性的指数。</p>
<p>计算NPS的方法很简单：<br><img src="https://img-blog.csdnimg.cn/20200715164222229.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>1.通过问卷或面对面访问，请用户回答“你在多大程度上愿意向朋友（亲人、同事）推荐某服务或产品？”用户以10分制数字作答，10分表示非常愿意，0分表示非常不愿意。<br>2.根据用户回答，将用户分成三类：评分在6分及以下的归为“贬损者”（Detractors），即用户不满意、无忠诚度；7-8分的归为“被动者”（Passives），即用户总体满意但没到狂热的程度，会考虑其他竞争对手的产品；9-10分的归为“推荐者”（Promoter），即用户是忠实狂热的，会考虑继续购买或推荐给其他人。<br>3.推荐者与贬损者在用户总数中所占百分比之差，就是净推荐值。<br><img src="https://img-blog.csdnimg.cn/2020071516405996.PNG#pic_center" alt="在这里插入图片描述"><br>• 优点：与长期利润增长正相关，可操作性强，易理解和接受，能直接与竞品比较，帮助企业明确业务优先级，弥补了用户满意度调查（ACSI）所得信息太多又缺乏重点的问题。<br>• 缺点：需要结合用户的具体信息去考虑，如“生命周期”等；净推荐值≠用户满意度，它只能为企业提供“预警装置”；最后，它不能给你解释，需要结合其他定性定量的方法来分析原因。</p>
<p>建议：<br>1.请先衡量它是否适用于你的产品或服务。人们愿意推荐餐馆，却不见得会推荐墓地。你的产品或服务本身应当具有被推荐的价值，最好也能给推荐者带来某些好处（显得见多识广、塑造前沿形象）。如果用户选择你的产品或服务，是为了解决难以启齿的痛点，那么面向大众公开推荐的可能性会显著降低。<br>2.NPS可以结合其他指标体系共同作用。比如Airbnb的增长团队将顾客入住后的综合评分，以及清洁度、位置、性价比等6个子维度的数据与NPS（他们称之为LTR）结合，建立了一系列嵌套逻辑回归模型。<br>3.可以根据实际情况对NPS进行修改简化。例如取消10分制，改为7分制或5分制（“非常厌恶”、“勉强接受”、“中规中矩”、“超过预期”、“非常喜爱”）。</p>
<h4 id="4-2-4-魔法数字：发现用户的惊喜时刻"><a href="#4-2-4-魔法数字：发现用户的惊喜时刻" class="headerlink" title="4.2.4 魔法数字：发现用户的惊喜时刻"></a>4.2.4 魔法数字：发现用户的惊喜时刻</h4><p>用户流失的一般情形：<br>• 30%的人因“没有感受到产品价值”而离开<br>• 30%的人因“不知道怎么操作”而离开<br>• 10%的人因“使用中有失败体验”而离开<br>• 剩下不到30%的人出于兼容性差、投奔竞品等理由离开</p>
<p>新用户直至亲身体验到你的产品为他们带来的价值与愉悦之际才有可能转化成忠诚的常客。这个最终让用户成功驻留的关键点，就是 <label style="color:red">“惊喜时刻”（＂Aha！”Moment）</label>。它代表用户在使用产品到达特定阶段后所产生的对产品价值的肯定。而奠定惊喜时刻的数据指标，则被称为 <label style="color:red">“魔法数字”（Magic Number）</label>。</p>
<p>以下是一组“惊喜时刻”及其对应“魔法数字”的例子：<br>• Twitter的增长负责人Josh Elman透露，如果一个新用户关注了至少30人，他才更倾向于转化成活跃用户，而不是随便看看就离开。<br>• Facebook的Chamath Palihapitiya说，他们定义的惊喜时刻是让新用户在注册的前10天里添加至少7个好友。为此Facebook开发了“你可能感兴趣的人”（People You May Know）功能来引导用户互加好友。<br>• Zynga的Nabell Hyatt意识到，如果他们游戏的玩家在注册后的第二天重新登录，则这批人变为活跃用户和付费用户的可能性更高，所以将“第一天的次日留存率”（Day 1 Retention）视作核心指标之一。<br>• Dropbox的增长负责人ChenLi Wang观测获知，惊喜时刻在于让用户上传至少一个文件到自己的网盘空间。</p>
<p>通过对常见产品魔法数字的归纳总结，不难得出以下三种衡量标准。<br>• 用户关系网络密度：在X天内添加/关注了Y名好友。<br>• 产生内容：添加（上传/发布/撰写）了X单位的内容。<br>• 访问频度：在X天之内发生重复访问行为。</p>
<p><strong>掌握用户的惊喜时刻的方法</strong></p>
<ul>
<li>询问用户</li>
<li>借助数据分析工具精确地探寻产品的惊喜时刻，将它们作为增长团队行动的参照。国外的Mixpanel、国内的GrowingIO等。</li>
</ul>
<p><strong>分析移动端订单数量下降情况</strong><br>假设你是百度外卖App的增长团队负责人，某天移动端的订单数量比前一日下跌了5%。你的老板要求你对这一数据变动做出合理解释，你将如何应答呢？</p>
<p>为了分析订单下跌情况，可以从以下三个方面展开论述：<br>• 明确指标变动的异常程度、预期影响面<br>• 寻求数据分析的角度，排查异常原因<br>• 根据结论寻求优化或止损方案</p>
<p>第一步：订单量比前一日下跌5%，影响是否大到必须加以重视？<br>以2015年百度外卖B轮融资计划书展示的数据看，其拥有3 000万注册用户，日订单数量超过110万，客单价可达50元左右。以此数据估算，假设2016年底注册用户数达到6 000万，日订单数量突破200万，客单价基本不变，那么5%的订单量下滑意味着当日损失500万元营收。<br>天然的单一突发事件几乎不可能造成这么大的损失，因此这足以引起产品团队的高度重视。</p>
<p>第二步：影响数据异常变动的原因可能有哪些？<br>1）全局指标：包括一定时间内新增用户量、用户活跃度、总转化率、搜索功能使用率、翻页率、Bug率等。全局指标用于分析对全体用户产生影响的共性原因。<br>2）分渠道指标：可按不同下载渠道、用户所在地域、移动平台、运营商、网络接入方式等维度观察不同渠道数据是否存在异常。<br>3）用户行为数据：在上述两项指标基础上，重点观测用户在不同时间段、不同需求类型下的行为，从而定位到由于某一细分人群的定向变化产生的数据异常。<br>4）时间因素：外界环境的影响也可能对产品数据造成影响，因此观测同比和环比数据都很重要。典型代表如“月末效应”，即一定规模的用户群体会因月底手机流量用尽而减少上网行为，造成整体流量的下滑。另外，对于一款外卖产品而言，天气变化也会造成数据波动，通常阴雨天的订单量会走高。<br>5）其他产品线监控：百度集团旗下的其他产品线变动也可能成为造成订单量下滑的原因，例如91应用市场改变了App广告的展示位置，或是搜索引擎的算法调整降低了网民常用关键词的权重等。<br>6）舆情监控：包括但不限于通过人工或机器方式，从内部反馈通道、论坛、贴吧、微博、朋友圈等处采集大众对产品的实时意见。极有可能因此发现导致产品数据骤然降低或飙升的特殊舆情，如新发布的当季财报引发投资者关注、母公司运作纰漏招致大众抵制，或是竞争对手做出了哪些新动作。</p>
<p>第三步：提出应对方案。<br>排查完成后，通过定位到具体原因，给出对应的方案。比如修复某个版本新上线引发的严重Bug、联系合作部门提高曝光量、针对竞争对手的营销策略做出同等力度的折扣反击等。</p>
<h4 id="4-2-5-同期群分析"><a href="#4-2-5-同期群分析" class="headerlink" title="4.2.5 同期群分析"></a>4.2.5 同期群分析</h4><p><label style="color:red">同期群分析（Cohort Analysis）</label> 亦称群组分析，是按照用户初始行为的发生时间进行群组划分，继而分析相似群体随时间变化情况的数据分析方法。<br><img src="https://img-blog.csdnimg.cn/20200715170724530.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在产品研发中，同一项产品改进，对不同同期群中的用户而言，产生的影响是不同的，分开衡量才能反应最真实的情况。如果你为产品增加了新手引导，那么就要将新手和老用户区隔开验证；如果你准备发放折扣券，那么已长期使用的忠实用户会比刚注册的新用户更乐于响应。</p>
<p>同期群分析的作用主要体现在：<br>• 衡量产品业务的整体进展。<br>• 评估产品改版的效果。<br>• 优化产品的用户体验。<br>• 寻找产品改进关键点。<br>• 提升用户参与度。</p>
<h3 id="4-3-案例：如何通过大数据分析提升电销利润"><a href="#4-3-案例：如何通过大数据分析提升电销利润" class="headerlink" title="4.3 案例：如何通过大数据分析提升电销利润"></a>4.3 案例：如何通过大数据分析提升电销利润</h3><h4 id="4-3-1-如何获取并维护客户销售线索"><a href="#4-3-1-如何获取并维护客户销售线索" class="headerlink" title="4.3.1 如何获取并维护客户销售线索"></a>4.3.1 如何获取并维护客户销售线索</h4><p>销售线索（Leads）是指有成单可能性的客户名单，是电销行业中非常重要的资源。传统的做法是从各种渠道获取销售线索名单，直接海量拨打。某网则通过数据挖掘，创建出周密的分析模型，继而搭建出两套自动化系统：1.商机自动识别和分配系统；2.客户策略性维护系统。</p>
<p>1.商机自动识别和分配系统：针对海量客户数据进行挖掘，决定触达客户群</p>
<p>首先通过数据分析，归纳出100多个影响成交率的不同维度数据（包括行为数据、订单数据、行业地域数据等），再结合机器学习，教会机器模型如何通过上述特征判别出有成功可能的通话记录。经过训练，机器模型成功将需要拨打的电话数量从2万5千条降到了5千条，节约了近五分之四的成本，成功率提升到80%。模型上线后的一段时间内，团队继续通过报表监控预测值和实际结果的区别，每周对模型更新和维护，收集销售端反馈，持续优化模型参数和商机分配规则。</p>
<p>2.客户策略性维护系统</p>
<p>只有客户留存率足够高的时候，追求客户数增长才是有意义的，否则即使利用高额成本获取了大量客户，也只能制造短暂的市场繁荣假象，无法带来持久增长。某网采用了RFM模型进行客户状态跟踪和维护。</p>
<p><img src="https://img-blog.csdnimg.cn/20200715172632473.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><label style="color:red">RFM</label>代表：<br>• Recency：最近一次消费距今时间。<br>• Frenquency：消费频率。<br>• Monetary：消费金额。</p>
<p>依据上述三个核心指标，用户被划分成八种类型。从消费金额角度，花钱多的用户定义为重要客户，花钱少的用户定义为一般客户。将重要用户继续拆分：<br>• 重要价值客户。最受欢迎的是这类消费频率高、最近一次消费距今时间短的“重要价值客户”。他们价值高、行为活跃、维护成本低。通过观察重要价值客户的占比，可以衡量公司重点客户的风险性和维护效果。<br>• 重要发展客户。这类客户最近一次消费时间较近，单消费频率偏低，说明其消费潜力没有被充分发掘，因此需要重点发展该类客户。<br>• 重要保持客户。客户历史上消费过多次，而最近一次消费距今较远，有可能体现了客户对产品的兴趣减弱。对这类客户要积极跟进，以防流失。<br>• 重要挽留客户。客户历史消费金额较高，但是消费频次低、最近一次消费时间距今较远。这类客户很有可能已经流失了。该类型客户的占比反映了重要客户的流失情况，如果占比较高，需要引起警惕，可以通过对该类客户的回访找出流失原因，制定补救方案。</p>
<h4 id="4-3-2-如何控制成本实现收益最大化"><a href="#4-3-2-如何控制成本实现收益最大化" class="headerlink" title="4.3.2 如何控制成本实现收益最大化"></a>4.3.2 如何控制成本实现收益最大化</h4><p>相对于邮件或短信营销渠道，电话销售渠道的成本非常高。因此在进行业绩目标规划时，也需要考虑到成本因素，让电销的收益最大化。</p>
<p>1.营收管理：如何实现收益最大化<br>首先将各个维度的成本分摊到每通电话上，并且将电销渠道获取的消费总金额分摊到每通成功转化的电话上。例如，假设折算出一通电话的成本为5元，而一通成功转化的电话可以带来100元的消费，那么只要一个销售线索的转化率高于5%（5元/100元），那么拨打是盈利的。<br>于是借助上文提到的数据挖掘模型，可以预测出每个销售线索的转化率，并依据转化率倒序排列，制作出 ROC（接受者操作特征）曲线。曲线可以反映出拨打决策和相应的预测结果。在这套模型下，如果决策者计划削减外呼量以控制成本，电销人员就可以选择拨打模型预测出的转化率最高的20%客户。</p>
<p>2.系统管理：减少无效拨打，增加工作条理性<br>某网将客户名单池划分为：个人池、公共池和无效池。<br>• 个人池：属于单个销售人员的名单池，为了避免抢单，其他销售不可触达。个人池可进一步细分为。<br>a）熟客维护池：属于该销售维护的已成单的客户。<br>b）新分配商机：属于系统自动分配或销售从公共池领取的商机。<br>• 公共池：当个人池的销售线索无法满足业绩指标时，销售人员可从公共池领取替补销售线索。<br>• 无效池：当所触达的客户明确表示无需求时，销售会在客户商机标注无效，该商机从个人池流转至无效。</p>
<h4 id="4-3-3-如何抓住转瞬即逝的商机"><a href="#4-3-3-如何抓住转瞬即逝的商机" class="headerlink" title="4.3.3 如何抓住转瞬即逝的商机"></a>4.3.3 如何抓住转瞬即逝的商机</h4><p>和传统线下商店不同，困扰很多电商平台的一个大问题是：用户来访转化率大多只有5%左右。也就是说，每100位来访者，仅有5位客户会真的付费。另外，互联网访问的低成本也加剧了市场竞争：客户可以毫不费力地去访问多家网站，对比产品和价格之后再做出购买决定。</p>
<p>某网借鉴沃顿商学院市场营销系知名教授彼得·菲德尔（Peter Fader）关于路径数据（Path Data）的理论体系，对客户行为进行拆分和建模，观测到了用户从出现购买意向到被销售人员触达的时间间隔和用户转化率之间的关系。<br><img src="https://img-blog.csdnimg.cn/20200715174530960.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>研究发现，在客户出现购买意向之后越快得到销售的服务，其成单可能性就越高。这里面有两个原因：</p>
<ul>
<li>第一，市场竞争激烈。客户同时有3家以上分类网站可供选择，稍有延迟，客户就流失。</li>
<li>第二，“被服务”VS“被推销”：不同时机带来截然不同的客户体验。越及时地触达客户，就越能更好地帮助客户，节约客户的时间，从而让客户对你的服务满意并乐意购买你的产品。基于这一点，某网确定了服务营销的关键时刻，研发了一套实时用户需求挖掘和响应系统，从用户在某网的点击流数据中挖掘其出现付费需求的可能性和强烈程度，并及时将信息利用CRM系统传达给电销团队。</li>
</ul>
<h4 id="4-3-4-如何利用用户需求提炼系统找出业务增长点"><a href="#4-3-4-如何利用用户需求提炼系统找出业务增长点" class="headerlink" title="4.3.4 如何利用用户需求提炼系统找出业务增长点"></a>4.3.4 如何利用用户需求提炼系统找出业务增长点</h4><p>电销团队就某网来说，不是一个赚钱工具，而是最能理解客户需求的渠道。因此<br>某网研发了一套需求提炼系统，通过评估、跟踪用户的需求满足情况找出产品缺点，推动产品的革新和业务发展。用户的需求识别系统可以分为两个部分：显著需求和潜在需求。<br>• 显著需求是指那些信号明确，流程清晰的常见需求，包括验证失败、支付失败、发布失败、发布超限等。<br>• 潜在需求则是指较为模糊的、有待发掘的需求，包括流量需求（用户发布信息之后感觉来联系的人少）、编辑需求（用户对如何优化信息的内容比较在意）、信息需求（用户并没有找到想要的信息）等。</p>
<p>对于某网这个服务提供方来说，显著需求的整理主要是为了降低理解成本，简化沟通流程；而潜在需求则是某网在销售服务上的核心竞争力。对潜在需求的精确解读可以为用户提供更与众不同的服务，推荐个性化的付费产品。</p>
<p>那么某网是如何分析和提炼出用户的潜在需求的呢？<br>第一，对潜在需求进行定义和分级。<br>第二，对定义好的潜在需求进行数据整理和建模。<br>第三，对单个用户进行需求提取，方便销售人员了解用户痛点。<br>第四，对客户需求进行宏观总结，制定针对性的政策。<br><img src="https://img-blog.csdnimg.cn/20200715182307915.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>通过宏观总结客户需求的处理率，某网就可以发现产品和服务上面的改进点，从而推动服务运营能力和产品完善性。</p>
<p>综上所述，某网利用其大数据技术优势，结合营收管理和市场营销理论，全方位地改造了电话销售团队，使其成为一支能够实时捕捉商机、高效服务于客户的精英团队。</p>
<h2 id="5-洞悉用户心理"><a href="#5-洞悉用户心理" class="headerlink" title="5 洞悉用户心理"></a>5 洞悉用户心理</h2><h3 id="5-1-用户画像：理解你的目标用户"><a href="#5-1-用户画像：理解你的目标用户" class="headerlink" title="5.1 用户画像：理解你的目标用户"></a>5.1 用户画像：理解你的目标用户</h3><p><label style="color:red">用户画像（Persona）</label> 可以给用户体验建模，从而帮助团队更加清晰地理解目标用户的工作方法。“Persona”在拉丁语中的原意是“面具”。在产品研发中，Persona 是真实用户的虚拟代表，是建立在一系列真实数据之上的目标用户模型。通过用户调研去了解用户，根据他们的目标、行为和观点的差异，将他们区分为不同类型以进行用户信息标签化，然后从每种类型中抽取出典型特征，赋予名字、照片、一些人口统计学要素、场景等描述，形成了一个Persona。</p>
<p>用户体验专家大卫·特拉维斯（David Travis）认为，一个令人信服的Persona要满足七个条件，即<label style="color:red">P.E.R.S.O.N.A</label>——<br>• P代表基本性（Primary research）指该Persona是否基于对真实用户的情景访谈。<br>• E 代表移情性（Empathy）指 Persona 中包含姓名、照片和产品相关的描述，是否能引起同理心。<br>• R代表真实性（Realistic）指对那些每天与顾客打交道的人来说，Persona是否看起来像真实人物。<br>• S代表独特性（Singular）每个Persona是否是独特的，彼此很少有相似性。<br>• O代表目标性（Objectives）该Persona是否包含与产品相关的高层次目标，是<br>否包含关键词来描述该目标。<br>• N代表数量（Number）Persona的数量是否足够少，以便设计团队能够记住每个用户角色的姓名，以及其中的一个主要用户角色。<br>• A代表应用性（Applicable）是否能使用Persona作为一种实用工具进行设计决策。</p>
<p><strong>完整有价值的Persona，应当包括以下内容：</strong><br>• 赋予每一个角色姓名、年龄和性别。让他更像是有血有肉的真实存在，并且方便迅速沟通。<br>• 寻找一张代表这个角色的真人照片。<br>• 确定所在的地理位置。<br>• 职业、收入范围。<br>• 喜好、人生态度、对于外部特定刺激的固定反应。<br>• 用户使用产品的场景和外部因素。<br>• 致使他们使用产品的主要原因。<br>• 他们的根本需求、痛点及核心目标是什么。<br>• 与产品使用相关的其他补充信息。</p>
<p><strong>构建Persona的一般步骤</strong><br>第1步：根据角色对访谈对象进行分组。根据研究结果和理解对用户进行大致的角色划分，并根据角色对要访谈的用户进行分组。<br>第2步：找出行为变量。把每种角色的显著行为列成几组行为变量。一般包括用户的活动（行为及频率），以及对产品及相关技术的态度、能力、动机、技能等几个方面。<br>第3步：将访谈主体和行为变量对应起来。实际上就是为每个访谈用户标注各项行为的情况。<br>第4步：找出重要的行为模型。发现访谈用户中的显著行为模式组合。<br>第5步：综合各种特征，阐明目标。从用户模型的行为细节中综合挖掘出用户的目标和其他特性。<br>第6步：检查完整性和冗余。为每种用户模型弥补行为特征中重要的缺漏，将行为模式相同而仅仅是人口统计数据有差异的用户模型合并为一个。<br>第7步：指定用户模型的类型。对用户模型进行优先级排序，确定主要、次要、补充、增加负面的用户模型。主要用户模型是界面设计的主要对象，一个产品的一个界面，只能有一个主要用户模型。<br>第8步：进一步描述特征和行为。通过第三人称叙述的方式描述用户模型，并为不同用户模型选择恰当的照片。至此，用户模型构建完成。</p>
<p>例如，某产品构建的Persona文字部分示例如下。<br>用户画像：互联网公司产品经理Jason<br>基础信息<br>• 姓名：Jason<br>• 性别：男<br>• 年龄：出生于1993年，金牛座<br>• 籍贯：江西南昌<br>• 性格：腼腆内敛，富于好奇心<br>• 职业：产品经理<br>• 工作单位：北京某互联网公司X，月薪6千元<br>• 常用软件：Visio、Axure、Office、MindManager<br>• 经常关注网站：增长黑客网、知乎、36氪、馒头商学院<br>用户特性<br>• 出入产品经理行业1年，对产品工作经验不足<br>• 面对部分工作力不从心，急需快速提升产品相关专业能力<br>• 希望可以通过行业内前辈的指导以及同行交流帮助自己高效完成工作<br>用户故事<br>• Jason 刚进入一家互联网公司做产品经理，由于缺乏实战经验，有时对于团队负责人分配的工作显得力不从心。<br>• 他希望通过使用本产品，能跟行业内的大牛互动，逐步形成自己的思维方式和产品方法论，掌握一套趁手工具的高效使用流程，提升自己对于产品的把控能力，尽早担负起独当一面的责任，计划两到三年内从产品经理上升到高级产品经理。<br>• Jason 可能会在入行五年后考虑自行创业，因此与创业有关的技能和行业八卦也是他所热衷的话题之一。</p>
<p><strong>怎样才能让Person发挥最大作用呢？</strong><br>• 首先，应当确保获得公司各部门的支持。良好的跨团队协作交流，既有利于获取生成 Persona 需要的信息和资源，又可以让大家都有参与感、了解 Persona的产生过程，最后的结果会更让人信服。<br>• 其次，每个产品界面只对应一个主要的Persona。不要试图满足所有的Persona，这很可能导致众口难调，最终谁的需求都无法充分满足。<br>• 最后，针对不同的项目、功能及时调整 Persona，不要指望一劳永逸。时代在前进，产品在更迭，Persona迟早是会过时的。</p>
<h3 id="5-2-新手引导：加速惊喜时刻的到来"><a href="#5-2-新手引导：加速惊喜时刻的到来" class="headerlink" title="5.2 新手引导：加速惊喜时刻的到来"></a>5.2 新手引导：加速惊喜时刻的到来</h3><p>新手引导流程（User Onboarding）是加速惊喜时刻到来的重要环节。成功的新手引导流程不仅便于用户快速上手，还能让他尽快感受到产品的价值，从而形成长期使用的习惯。</p>
<p>Robbie Kellman Baxter在其著作《成员经济学》（The Membership Economy）<br>中提出了新手引导流程的三大法则和八个步骤。</p>
<p><strong>法则一：消除用户疑虑，降低挫败感</strong><br>➢ 步骤1：注册环节<br>你应该设法让注册环节变得更简单，减少用户的疑虑困惑，让他们毫无负担地尽快开始使用。例如：<br>• 将注册时的必填项缩减到最少，其他选填项允许在之后填补。<br>• 采用第三方账号（如Facebook、微博）一键授权登录。<br>• 如果是收费服务，记得提供免费试用期或者演示账号。</p>
<p>➢ 步骤2：欢迎信息<br>在注册完成后，马上提出感谢并告诉用户他们应该干些什么。常用的做法有：<br>• 给用户发送一封欢迎邮件，展示产品的主要功能。<br>• 用浮层页面指示用户常见操作的入口。<br>• 或是像Slack那样，模拟机器人小助手的输入，与用户轻松对话。</p>
<p><strong>法则二：为用户提供立竿见影的好处</strong><br>➢ 步骤3：让用户马上体验主要功能<br>在新用户热情尚未消散之前，尽快引导他们用上产品的主要功能。为此你可以：<br>• 让用户注册完毕后，立即跳转到主要功能的所在页面。<br>• 将执行“标准动作”作为必经步骤，无法直接跳过。<br>• 安排另一名用户主动发起交互（如聊天、私信、漂流瓶），主要适用于社交类产品。</p>
<p>➢ 步骤4：询问反馈<br>通过提前部署数据分析工具，你可以明确追踪到每一名用户的使用行为，并在适当时机与其建立沟通。如果用户卡在某一任务流程中，始终未能走完，那么不妨询问他阻力来自哪里并予以适当协助。</p>
<p>➢ 步骤5：提供建议<br>如果用户已经逐渐从新手阶段过渡到进阶阶段，那么不妨给出一些使用中的小技巧、高级玩法，提升他们的使用效率和愉悦感。例如，可以向使用Dropbox网页版的用户建议：<br>• 下载手机版App，体验手机照片同步备份到云端的功能。<br>• 开启浏览器插件，一键拖动自动上传。<br>• 更换Webkit内核的现代浏览器，让使用过程更顺畅。<br>• 体验一次版本控制、文件标注等高级功能。</p>
<p><strong>法则三：根据用户行为施予小恩小惠</strong><br>➢ 步骤6：鼓励用户邀请好友使用<br>如果你的产品自带推荐用户（Referral Program）模块，记得找机会鼓励那些活跃度高的用户，号召他们邀请亲朋好友一起使用你的产品。常用策略有：<br>• 邀请好友注册，你跟他都获赠一个月会员、500MB空间及100元礼金券。<br>• 你获得受邀好友日后实际消费金额20%的销售提成。<br>• 分享到社交网络，解锁某个高级付费功能的3个月使用权限。<br>• 推出人气榜单，公开展示邀请好友数量最多的活跃用户名单。</p>
<p>➢ 步骤7：向用户提供定制的个性体验<br>在用户使用一定程度后，你应该能通过数据对他描摹出画像，由此提供独特的专属服务。包括但不限于：<br>• 内容预测类，如“你可能感兴趣的人”、“猜你喜欢的内容”、“你的音乐口味”。<br>• 身份特质类，如向个人用户发放指定品类的消费代金券，给企业用户一定额度的垂直人群免费曝光机会。<br>• 个性彰显类，达到特定等级的用户，可以自己选择主题背景、图片配饰、签名小尾巴等。</p>
<p>➢ 步骤8：提供有营养的长期价值<br>无论是智慧的与日俱增、财富的水涨船高，还是友情的持续升温，你的用户应当在每一次使用产品的过程中，明确感觉到长期价值的提升。你的整套产品都应当毫不吝惜于彰显自己的价值，不必藏着掖着。</p>
<h3 id="5-3-病毒基因：让产品像病毒一样疯传"><a href="#5-3-病毒基因：让产品像病毒一样疯传" class="headerlink" title="5.3 病毒基因：让产品像病毒一样疯传"></a>5.3 病毒基因：让产品像病毒一样疯传</h3><p>乔纳·伯杰（Jonah Berger）在其著作《疯传——让你的产品、思想、行为像病毒一样入侵》一书中，归结出以下六个关键因素：社交货币、诱因、情绪、公共性、实用价值和故事。它们构成了广泛传播的深层次原因。<br><img src="https://img-blog.csdnimg.cn/20200715191902758.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200715191944913.PNG#pic_center" alt="在这里插入图片描述"><br>➢ 因素一：社交货币（Social Currency）<br>每个人都希望自己在他人眼中更加灵巧、更加富有、更加时尚。人们对产品或思想的评论，就像服装和轿车一样，成为别人对其评判的重要因素。我们需要洞悉人们的内心深处，让他们感觉到自己进入了他们渴望的世界之中。我们需要调整游戏规则，去迎合人们向身边朋友炫耀身份的需要，构建出他们渴望的形象。这就是社交货币。</p>
<p>铸造社交货币的方式：<br>1）发掘标志性的内心世界。<br>2）撬动游戏杠杆。<br>3）使人们有自然天成、身临其境的归属感。</p>
<p>➢ 因素二：诱因（Triggers）<br>怎样能提醒用户想到我们的产品呢？巧妙地利用心理学的“锚点”，把你的产品和用户司空见惯的事物建立关联，一旦产生刺激，瞬间激发人们的记忆，就能让人们想到你的产品。这就是诱因的作用。许多产品之所以缺乏传播，是源于“空对空”的单纯吹嘘工具性能，而不是放到用户实实在在的业务需求场景中展开讨论。</p>
<p>➢ 因素三：情绪（Emotion）<br>有感染力的内容通常能够激发人们的即时情绪。只有选择高唤醒的情绪才容易带来更多转发。</p>
<p>➢ 因素四：公共性（Public）<br>当人们看见别人使用我们的产品时，他们会不会考虑这种产品是否符合自己的需要呢？有样学样的“羊群效应”很能反映人们的跟风趋势。所以从反面来讲，人们只要没有看到相关的事物，是不会轻易模仿的，更不可能让这些事物变得流行。所以我们需要设计一些具备公共性的产品，主动制造一种在公众中广泛渗透的影响力。</p>
<p>➢ 因素五：实用价值（Practical Value）<br>人与人之间本来就有互利的倾向，只要我们向用户证明我们的产品能够为他们节省时间或者金钱，他们就会大力宣传我们的产品。不过当我们绞尽脑汁想以产品信息将用户的视野淹没时，应该更清醒地意识到，应当让自己的信息能够优先凸显。为此，我们应该弄清什么东西会让用户觉得更优质、更加值得信赖，从而尽可能地向用户提供更具性价比的商品。</p>
<p>➢ 因素六：故事（Stories）<br>人们不仅会分享信息，更可能会讲述其中的相关故事。特洛伊木马之所以经久流<br>传，是因为故事本身就是传播道德和启示的血液。信息会经过闲散的聊天包装后逐渐传播。所以我们需要建立像特洛伊木马这样的传奇故事，用来注入我们的产品和思想。这也是为什么越来越多中高端产品开始重视对品牌故事的包装叙述。</p>
<h2 id="6-技术驱动营销"><a href="#6-技术驱动营销" class="headerlink" title="6 技术驱动营销"></a>6 技术驱动营销</h2><h3 id="6-1-营销是如何逐渐被技术接管的"><a href="#6-1-营销是如何逐渐被技术接管的" class="headerlink" title="6.1 营销是如何逐渐被技术接管的"></a>6.1 营销是如何逐渐被技术接管的</h3><p><strong>传统以营销为驱动力的增长是如何被技术颠覆的？</strong><br>1.营销和产品的边界正在变得模糊。过去的产品和营销是割裂的，互联网的兴起为软件产品的推广和交付带来全新可能。以云端同步工具 Dropbox 为例，每一位用户可以将它推介给自己的好友，双方都将因此获赠额外的500MB免费存储空间。这算是营销吗？当然，但它是技术团队开发出来的产物。这算是产品吗？的确，但其初衷是完成与营销密切挂钩的用户增长指标。</p>
<p>2.获得用户数据越来越容易。一个对普通用户而言有点难以接受的事实是：如果你获得的商品是免费的，那么你自己就是商品。</p>
<p>3.平台和开放接口（API）的涌现提供了更多机会。如今，你既可以花钱购买平台提供的广告展示机会，也可以借助第三方提供的接口（许多是免费的）从零开始搭建自己的产品、服务或营销工具，利用网络上现成的基础设施为你节省下一大笔费用。</p>
<p>4.营销者眼界逐渐放宽。周遭环境的变化让敏锐的营销者重新开始审视自身权责的边界。一种新技术或渠道的出现让他们眼前一亮，而当流量红利逐渐殆尽，他们不得不伺机待发，随时扑向另一个潜在机会。</p>
<h3 id="6-2-爬虫抓取：对网络公开资源的巧取豪夺"><a href="#6-2-爬虫抓取：对网络公开资源的巧取豪夺" class="headerlink" title="6.2 爬虫抓取：对网络公开资源的巧取豪夺"></a>6.2 爬虫抓取：对网络公开资源的巧取豪夺</h3><p>互联网是一座资源未被充分结构化的数据仓库，利用技术手段批量从已知网页或其他数据源下载资源的方法，就是爬虫抓取。执行这项任务的程序被称为网络爬虫（Web Crawler），它的职责在于采集、处理和储存。</p>
<p><strong>利用抓取技术解决产品增长的案例，包括：</strong><br>• 锁定早期用户。<br>• 调研竞争对手。<br>• 立项市场调查。<br>• 年底业绩交差。</p>
<p><strong>编写爬虫脚本抓取数据的基本步骤：</strong><br>1）选定目标。首先确定被抓取方提供了哪些服务，比如网站、移动应用、开放平台等。如果所有服务是等价的，不存在某一服务缺失功能，那么就优先从移动应用开始抓取。因为应用一般是通过API来获取数据，透过API抓取的数据方便后期的结构化整理。<br>2）技术方案。依实际情况而定。<br>3）性能优化。如果是单次抓取需求，并不需要持续稳定地一直跟踪抓取。复杂一些可以考虑用付费的第三方云服务。<br>4）资源结构。抓取网页，一般先研究页面上是否有统一的资源ID命名方式（分类、排行、导航、搜索通常能提供良好的组织结构和命名规则），然后递增、遍历或借助能批量处理特定结构的第三方库。<br>5）见招拆招。对于采取防抓取措施的对象，也有应对方法：如果对方要求注册，网页服务可以在request请求中把浏览器的cookie带上，移动应用抓包看看Auth Key然后在请求中带上；如果对方有 IP 限制，可以用代理池解决；如果有随机数时间校验，就用random命令生成一个对应长度的随机数来延时。<br>6）数据处理。脏数据要用正则表达式或者 beautifulsoup 这样的第三方包把想要的内容取出来，然后存放到数据库。<br>7）数据分析。</p>
<p><strong>如何反抓取，保护自己的数据资产</strong><br>封锁IP、封锁设备、限制单位时间内的访问频度、混淆代码增大识别难度等。将单一策略组合起来，能更有效地避免误判，以免将普通用户识别为爬虫。</p>
<h3 id="6-3-A-B测试：如何用数据定夺最终决策"><a href="#6-3-A-B测试：如何用数据定夺最终决策" class="headerlink" title="6.3 A/B测试：如何用数据定夺最终决策"></a>6.3 A/B测试：如何用数据定夺最终决策</h3><p>所谓<label style="color:red">A/B测试</label>，就是针对想调研的问题提供多种解决方案（比如两个页面），然后让一部分用户使用方案A，另一部分用户使用方案B，通过数据观察对比确定较优的方案，从而确定最终结果。世界上最好的产品经理也只能跑赢一半的A/B测试。</p>
<p>A/B测试的基本思想：<br>• 提供多个方案并行测试。<br>• 不同方案之间只存在一个变量。<br>• 以某种标准判定结果，筛出最优方案。</p>
<p>利用A/B测试优化产品，分为后验和试验两种策略。</p>
<ul>
<li>后验是通过统计分析目前用户的行为指标，以判断产品在哪些地方可以做改进，比如将白底黑字改为黑底白字是否影响页面停留时长、将按钮体积增大20%能否提升被点击的概率。</li>
<li>试验则是根据项目目标提出方案的假想，再经过A/B测试的结果对假想结果加以检验，从而推断是否应当上线某项改动。</li>
</ul>
<p>A/B测试中抽取的测试流量应当来源于该功能的真实使用者，核心在于无感知分流和对不同流量群准确观测。在产品初期，随意的改动都可能引发寥寥数个用户的测试曲线波动，造成数百上千倍的增长或下滑，这样的测试结果并不能落在有效的置信区间内。一般来说，产品的UV超过数千时的测试结果才有意义。</p>
<p>为了得出足以具有说服力的测试结论，你应当考虑以下两个要素。<br>• 转化率基准线（Baseline Conversion Rate），用于参考的控制组数据。<br>• 最少可检测效果（Minimum Detectable Effect），相较于控制组数据，产生多<br>少变化被视作试验产生了效果。</p>
<p>为了确保A/B测试工具本身的科学合理性，你可以试着跑一次“A/A测试”——实验组和控制组没有任何产品特性的差别，仅存在样本量上的变化。</p>
<h3 id="6-4-深度链接：如何合纵连横提升转化率"><a href="#6-4-深度链接：如何合纵连横提升转化率" class="headerlink" title="6.4 深度链接：如何合纵连横提升转化率"></a>6.4 深度链接：如何合纵连横提升转化率</h3><p>当今，一个个应用如同一座座老死不相往来的信息孤岛，彼此暗自较劲，争相将用户锁定在自己的平台上。例如，微信中只能通过内嵌浏览器查看有限的外部网页，某些竞争对手的产品受到严格的封锁与限制。这种巨头互掐之下的做法虽然确保了应用的活跃度与使用时长的增长，却剥夺了用户自由选择和高效获取信息的权利。</p>
<p>用户的真实需求是，在朋友圈看到时尚的服装单品推荐，能够直接点击文章里的链接，打开手机淘宝，直达购买页面。在这种转化流程中，用户主动操作步骤少、跳转方便灵活，因此能产生更高转化率。但在实际操作中，用户不得不先记住商品名称，再主动打开手机淘宝，从首页中搜索并找到对应商品，一个简单的需求经过多个步骤多次跳转才能实现。由此，一种打破移动应用彼此割据封闭状态的技术—— <label style="color:red">深度链接（Deeplink）</label> 应运而生。</p>
<p>深度链接的基本原理是：为移动应用的每一个子页面分配一个特定的链接，该链接能够被其他应用识别，经调用后打开应用并直达相应的子页面，从而彻底打破彼此间的壁垒。<br><img src="https://img-blog.csdnimg.cn/20200716172432665.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>深度链接技术涵盖的优势如下：<br>• 解决了跨域信息损耗的困境。<br>• 打破了入口垄断。<br>• 实现了入口的多样化和切片化。</p>
]]></content>
      <categories>
        <category>产品/运营</category>
      </categories>
      <tags>
        <tag>用户增长</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】逻辑回归(Logistic Regression)</title>
    <url>/2020/07/08/%5BMachine%20Learning%5D%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92(Logistic%20Regression)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200708114415292.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="4-Logistic-Regression-逻辑回归"><a href="#4-Logistic-Regression-逻辑回归" class="headerlink" title="4 Logistic Regression(逻辑回归)"></a>4 Logistic Regression(逻辑回归)</h2><h3 id="4-1-Classification"><a href="#4-1-Classification" class="headerlink" title="4.1 Classification"></a>4.1 Classification</h3><p>在分类问题中，需要预测的变量 𝑦 是离散的值，这种学习算法称为逻辑回归 (Logistic Regression) 的算法，这也是目前最流行的一种学习算法。</p>
<p>分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；区别一个肿瘤是恶性的还是良性的。</p>
<p><strong>以二元的分类问题为例</strong><br>将因变量(dependent variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量y∈0,1，其中 0 表示负向类，1 表示正向类。<br><img src="https://img-blog.csdnimg.cn/20200707142758328.PNG#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200707142910758.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2020070714301992.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>使用线性回归算法解决分类问题</strong></p>
<ul>
<li><p>对于分类， 𝑦 取值为 0 或者 1。</p>
</li>
<li><p>对于线性回归，那么假设函数的输出值可能远大于 1，或者远小于 0，即使所有训练样本的标签 𝑦 都等于 0 或1。尽管标签应该取值 0 或者 1，但是算法得到的值可能远大于 1 或者远小于 0的话。</p>
</li>
<li><p>所以需要研究一种新的算法——==逻辑回归算法==，这个算法的性质是：它的输出值永远在 0 到 1 之间。逻辑回归算法是分类算法，它是作为分类算法使用。</p>
<h3 id="4-2-Hypothesis-Representation-假设陈述"><a href="#4-2-Hypothesis-Representation-假设陈述" class="headerlink" title="4.2 Hypothesis Representation(假设陈述)"></a>4.2 Hypothesis Representation(假设陈述)</h3><p><img src="https://img-blog.csdnimg.cn/20200707144925873.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>sigmoid函数也叫做logistic函数，用于隐层神经元输出，取值范围为（0,1），它可以将一个实数映射到（0,1）的区间，可用作二分类。</p>
<h3 id="4-3-Decision-Boundary-决策边界"><a href="#4-3-Decision-Boundary-决策边界" class="headerlink" title="4.3 Decision Boundary(决策边界)"></a>4.3 Decision Boundary(决策边界)</h3><p>==决策边界(decision boundary)==的概念能更好地理解逻辑回归的假设函数在计算什么。</p>
<blockquote>
<p>在具有两个类的统计分类问题中，决策边界或决策表面是超曲面，其将基础向量空间划分为两个集合，一个集合。 分类器将决策边界一侧的所有点分类为属于一个类，而将另一侧的所有点分类为属于另一个类。<br>决策界限并不总是明确的。 也就是说，从特征空间中的一个类到另一个类的过渡不是不连续的，而是渐进的。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20200707151748236.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200707152202723.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>case1 线性决策边界:</strong><br><img src="https://img-blog.csdnimg.cn/20200707152629993.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>参数𝜃 是向量[-3 1 1]，则当−3 + 𝑥1 + 𝑥2 ≥ 0，即𝑥1 + 𝑥2 ≥ 3时，模型将预测 𝑦 =1。 我们可以绘制直线𝑥1 + 𝑥2 = 3，这条线便是我们模型的分界线，将预测为 1 的区域和预测为 0的区域分隔开。</p>
</li>
</ul>
<p><strong>case2 非线性决策边界：</strong><br><img src="https://img-blog.csdnimg.cn/20200707153019116.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>𝑦 = 0 的区域和 𝑦 = 1 的区域需要曲线才能分隔，二次方特征：ℎ𝜃(𝑥) = 𝑔(𝜃0 + 𝜃1𝑥1 + 𝜃2𝑥2 + 𝜃3𝑥12 + 𝜃4𝑥22)，其参数𝜃 是向量[-1 0 0 1 1]，则得到的决策边界恰好是圆点在原点且半径为 1 的圆形。</p>
<h3 id="4-4-Cost-Function-代价函数"><a href="#4-4-Cost-Function-代价函数" class="headerlink" title="4.4 Cost Function(代价函数)"></a>4.4 Cost Function(代价函数)</h3><p>监督学习问题中的逻辑回归模型的拟合问题，即是要定义用来拟合参数的优化目标/代价函数。<br><img src="https://img-blog.csdnimg.cn/20200707155159582.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对于线性回归模型，定义的代价函数是所有模型误差的平方和。理论上来说，逻辑回归模型可以沿用这个定义，但是问题在于，当将<img src="https://img-blog.csdnimg.cn/20200707155737548.PNG#pic_center" alt="在这里插入图片描述"><br>代入到这样定义的代价函数中时，得到的代价函数将是一个非凸函数（non-convexfunction）。这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。<br><img src="https://img-blog.csdnimg.cn/202007071559442.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200707160127498.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这样构建的𝐶𝑜𝑠𝑡(ℎ𝜃(𝑥), 𝑦)函数的特点是：当实际的 𝑦 = 1 且ℎ𝜃(𝑥)也为 1 时误差为 0，当 𝑦 = 1 但ℎ𝜃(𝑥)不为 1 时误差随着ℎ𝜃(𝑥)变小而变大；当实际的 𝑦 = 0 且ℎ𝜃(𝑥)也为 0 时代价为 0，当𝑦 = 0 但ℎ𝜃(𝑥)不为 0 时误差随着 ℎ𝜃(𝑥)的变大而变大。<br><img src="https://img-blog.csdnimg.cn/20200707162318105.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>python代码实现：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(theta, X, y)</span>:</span></span><br><span class="line">	 theta = np.matrix(theta)</span><br><span class="line">	 X = np.matrix(X)</span><br><span class="line">	 y = np.matrix(y)</span><br><span class="line">	 first = np.multiply(-y, np.log(sigmoid(X* theta.T)))</span><br><span class="line">	 second = np.multiply((<span class="number">1</span> - y), np.log(<span class="number">1</span> - sigmoid(X* theta.T)))</span><br><span class="line">	 <span class="keyword">return</span> np.sum(first - second) / (len(X))</span><br></pre></td></tr></table></figure>

<p>在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为：<br><img src="https://img-blog.csdnimg.cn/20200707162938538.PNG#pic_center" alt="在这里插入图片描述"><br>求导后，得：<br><img src="https://img-blog.csdnimg.cn/20200707163047181.PNG#pic_center" alt="在这里插入图片描述"><br>推导过程：<br><img src="https://img-blog.csdnimg.cn/20200707163827673.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的ℎ<sub>𝜃</sub>(𝑥) = 𝑔(𝜃<sup>T</sup>𝑋)与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。</p>
<p><strong>线性回归和逻辑回归是同一个算法吗？</strong><br>线性回归的假设函数：<img src="https://img-blog.csdnimg.cn/20200707192633258.PNG#pic_center" alt="在这里插入图片描述"><br>逻辑函数假设函数：<img src="https://img-blog.csdnimg.cn/20200707192654840.PNG#pic_center" alt="在这里插入图片描述"><br>因此，即使更新参数的规则看起来基本相同，但由于假设的定义发生了变化，所以逻辑函数的梯度下降，跟线性回归的梯度下降实际上是两个完全不同的东西。</p>
<p>当使用线性回归的梯度下降法时，监控梯度下降法以确保其收敛，同样的方法用在逻辑回归中，来监测梯度下降，以确保它正常收敛。</p>
<p>当使用梯度下降法来实现逻辑回归时，有不同的参数𝜃，就是𝜃0 𝜃1 𝜃2 一直到𝜃𝑛，需要用表达式来更新这些参数。我们还可以使用 for 循环来更新这些参数值，用 for i=1 to n，或者 for i=1 to n+1。当然，不用 for 循环也是可以的，理想情况下，更提倡使用向量化的实现，可以把所有这些 n 个参数同时更新。</p>
<p>另外，线性回归的特征缩放的方法也适用于逻辑回归。如果特征范围差距很大的话，那么应用特征缩放的方法，同样也可以让逻辑回归中，梯度下降收敛更快。</p>
<h3 id="4-5-Advanced-Optimization-高级优化"><a href="#4-5-Advanced-Optimization-高级优化" class="headerlink" title="4.5 Advanced Optimization(高级优化)"></a>4.5 Advanced Optimization(高级优化)</h3><p>高级优化的思路是通过梯度下降，进行逻辑回归的速度大大提高，而这也将使算法更加适合解决大型的机器学习问题，比如，我们有数目庞大的特征量。 另外，想要使代价函数𝐽(𝜃)最小化，那么需要做的是编写代码，当输入参数 𝜃 时，程序会计算出两样东西：𝐽(𝜃) 以及𝐽 等于 0、1 直到 𝑛 时的偏导数项。<br><img src="https://img-blog.csdnimg.cn/20200707194238293.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>假设已经完成了可以实现这两件事的代码，那么梯度下降所做的就是反复执行这些更新。</p>
<p>另一种考虑梯度下降的思路是：需要写出代码来计算𝐽(𝜃) 和这些偏导数，然后把这些插入到梯度下降中，然后它就可以最小化这个函数。</p>
<p>对于梯度下降来说，从技术上讲，实际并不需要编写代码来计算代价函数𝐽(𝜃)。只需要编写代码来计算导数项，但是，如果希望代码还要能够监控这些𝐽(𝜃) 的收敛性，那么就需要编写代码来计算代价函数𝐽(𝜃)和偏导数项 𝜕/𝜕𝜃<sub>𝑗</sub> 𝐽(𝜃)。所以，在写完能够计算这两者的代码之后，就可以使用梯度下降。</p>
<p>然而梯度下降并不是唯一可使用的算法，还有其他一些算法，更高级、更复杂。如果能用这些方法来计算代价函数𝐽(𝜃)和偏导数项𝜕/𝜕𝜃<sub>𝑗</sub> 𝐽(𝜃)两个项的话，那么这些算法就是为优化代价函数的不同方法，<strong>Conjugate gradient(共轭梯度法)</strong> 、<strong>BFGS (变尺度法)</strong> 和 <strong>L-BFGS (限制变尺度法)</strong> 就是其中一些更高级的优化算法，它们需要有一种方法来计算𝐽(𝜃)，以及需要一种方法计算导数项，然后使用比梯度下降更复杂的算法来最小化代价函数。</p>
<p><strong>三种算法的优缺点</strong></p>
<ul>
<li>优点是：一、<strong>通常不需要手动选择学习率𝛼</strong>，对于这些算法的一种思路是，给出计算导数项和代价函数的方法，可以认为算法有一个智能的内部循环，称为==线性搜索(line search)算法==，它可以自动尝试不同的学习速率 𝛼，并自动选择一个好的学习速率𝑎，因此它甚至可以为每次迭代选择不同的学习速率，那么就不需要手动选择。二、这些算法实际上不仅仅是选择一个好的学习率，它们最终<strong>收敛的速度一般快于梯度下降</strong>。</li>
<li>缺点是：它们比梯度下降法复杂多了。</li>
</ul>
<h3 id="4-6-Multiclass-Classification-One-vs-all-多类别分类：一对多"><a href="#4-6-Multiclass-Classification-One-vs-all-多类别分类：一对多" class="headerlink" title="4.6 Multiclass Classification: One-vs-all(多类别分类：一对多)"></a>4.6 Multiclass Classification: One-vs-all(多类别分类：一对多)</h3><p><img src="https://img-blog.csdnimg.cn/20200708111918112.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>对于二元分类可以使用逻辑回归，对于直线可以将数据集一分为二为正类和负类，对于一对多的分类思想可以将其用在多类分类问题上，有时这个方法也被称为 ==”一对余”方法== 。</p>
<p>将多个类中的一个类标记为正向类（𝑦 = 1），然后将其他所有类都标记为负向类，这个模型记作ℎ𝜃(1)(𝑥)。接着，类似地选择另一个类标记为正向类（𝑦 = 2），再将其它类都标记为负向类，将这个模型记作 ℎ𝜃(2)(𝑥),依此类推，得到一系列的模型简记为： ℎ𝜃(𝑖)(𝑥) = 𝑝(𝑦 = 𝑖|𝑥; 𝜃)其中：𝑖 = (1,2,3. . . . 𝑘)。 最后，在预测时，将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。<br><img src="https://img-blog.csdnimg.cn/20200708112953805.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】神经网络-表述(Neural Networks-Representation)</title>
    <url>/2020/07/11/%5BMachine%20Learning%5D%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%A1%A8%E8%BF%B0(Neural%20Networks_%20Representation)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200711130358651.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="6-Neural-Networks-Representation-神经网络：表述"><a href="#6-Neural-Networks-Representation-神经网络：表述" class="headerlink" title="6 Neural Networks: Representation(神经网络：表述)"></a>6 Neural Networks: Representation(神经网络：表述)</h2><h3 id="6-1-Non-linear-hypotheses-非线性假设"><a href="#6-1-Non-linear-hypotheses-非线性假设" class="headerlink" title="6.1 Non-linear hypotheses(非线性假设)"></a>6.1 Non-linear hypotheses(非线性假设)</h3><p>无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。</p>
<p>假设希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车），应该怎么做呢？一种方法是利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。<br><img src="https://img-blog.csdnimg.cn/20200710163445193.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>假如只选用灰度图片，每个像素则只有一个值（而非 RGB 值），可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：<br><img src="https://img-blog.csdnimg.cn/20200710163602179.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>假使采用的都是 50x50 像素的小图片，并且将所有的像素视为特征，则会有2500 个特征，如果要进一步将两两特征组合构成一个多项式模型，则会有约2500<sup>2</sup>/2个（接近 3 百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候需要神经网络。</p>
<h3 id="6-2-Model-Representation-模型表示"><a href="#6-2-Model-Representation-模型表示" class="headerlink" title="6.2 Model Representation(模型表示)"></a>6.2 Model Representation(模型表示)</h3><p>神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。</p>
<p>为了构建神经网络模型，首先需要思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（processing unit/Nucleus），它含有许多输入/树突（input/Dendrite），并且有一个输出/轴突（output/Axon）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。<br><img src="https://img-blog.csdnimg.cn/20200710180319605.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元。</p>
<p>下图是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是感觉和肌肉运转的原理。如果想活动一块肌肉，就会触发一个神经元给肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。<br><img src="https://img-blog.csdnimg.cn/20200710183458169.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，activation unit）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被成为权重（weight）。<br><img src="https://img-blog.csdnimg.cn/20200710183840825.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>设计出了类似于神经元的神经网络，效果如下：<br><img src="https://img-blog.csdnimg.cn/20200710184011764.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>其中𝑥1, 𝑥2, 𝑥3是输入单元（input units），我们将原始数据输入给它们。𝑎1, 𝑎2, 𝑎3是中间单元，它们负责将数据进行处理，然后呈递到下一层。最后是输出单元，它负责计算ℎ𝜃<br>(𝑥)。</p>
<p>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个 3 层的神经网络，第一层成为输入层（Input Layer），最后一层称为输出层（Output Layer），中间一层成为隐藏层（Hidden Layers）。为每一层都增加一个偏差单位（bias unit）：<br><img src="https://img-blog.csdnimg.cn/2020071018415966.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>注：𝑎<sub>𝑖</sub><sup>(𝑗)</sup> 代表第𝑗 层的第 𝑖 个激活单元。𝜃<sup>(𝑗)</sup>代表从第 𝑗 层映射到第𝑗 + 1 层时的权重的矩阵，例如𝜃<sup>(1)</sup>代表从第一层映射到第二层的权重的矩阵。其尺寸为：以第 𝑗 + 1层的激活单元数量为行数，以第 𝑗 层的激活单元数加一为列数的矩阵。例如：上图所示的神经网络中𝜃<sup>(1)</sup>的尺寸为 3*4。</p>
<p>对于上图所示的模型，激活单元和输出分别表达为：<br><img src="https://img-blog.csdnimg.cn/20200710185328930.PNG#pic_center" alt="在这里插入图片描述"><br>上面进行的讨论中只是将特征矩阵中的一行（一个训练实例）喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。</p>
<p>我们可以知道：每一个𝑎都是由上一层所有的𝑥和每一个𝑥所对应的决定的。<br>（我们把这样从左到右的算法称为前向传播算法( FORWARD PROPAGATION )）</p>
<p>把𝑥, 𝜃, 𝑎 分别用矩阵表示，我们可以得到𝜃 ⋅ 𝑋 = a :<br><img src="https://img-blog.csdnimg.cn/20200710190032240.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>相对于使用循环来编码，利用向量化的方法会使得计算更为简便。以上面的神经网络为例，试着计算第二层的值：<br><img src="https://img-blog.csdnimg.cn/20200710194213751.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200710194334438.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>为了更好了了解 Neuron Networks 的工作原理，先把左半部分遮住：<br><img src="https://img-blog.csdnimg.cn/20200710195253281.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>右半部分其实就是以𝑎0, 𝑎1, 𝑎2, 𝑎3, 按照 Logistic Regression 的方式输出ℎ𝜃(𝑥)：</p>
<p><img src="https://img-blog.csdnimg.cn/20200710195332905.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>其实神经网络就像是 logistic regression，只不过把 logistic regression 中的输入向量[𝑥<sub>1</sub> ∼ 𝑥<sub>3</sub>] 变成了中间层的[𝑎<sub>1</sub><sup>(2)</sup>∼ 𝑎<sub>3</sub><sup>(2)</sup>], 即:<br><img src="https://img-blog.csdnimg.cn/20200710195730589.PNG#pic_center" alt="在这里插入图片描述"><br>可以把𝑎0, 𝑎1, 𝑎2, 𝑎3看成更为高级的特征值，也就是𝑥0, 𝑥1, 𝑥2, 𝑥3的进化体，并且它们是由 𝑥与决定的，因为是梯度下降的，所以𝑎是变化的，并且变得越来越厉害，所以这些更高级的特征值远比仅仅将 𝑥次方厉害，也能更好的预测新数据。这就是神经网络相比于逻辑回归和线性回归的优势。</p>
<p>从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，被限制为使用数据中的原始特征𝑥1, 𝑥2, . . . , 𝑥𝑛，虽然可以使用一些二项式项来组合这些特征，但是仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。</p>
<p>神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(AND)、逻辑或(OR)。</p>
<p>举例说明：逻辑与(AND)；下图中左半部分是神经网络的设计与 output 层表达式，右边上部分是 sigmod 函数，下半部分是真值表。</p>
<p>可以用这样的一个神经网络表示 <strong>AND 函数：</strong><br><img src="https://img-blog.csdnimg.cn/20200711123825308.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><strong>OR 函数：</strong><br><img src="https://img-blog.csdnimg.cn/20200711123956883.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>OR 与 AND 整体一样，区别只在于的取值不同。</p>
<p>利用神经元来组合成更为复杂的神经网络可以实现更复杂的运算。例如要实现 XNOR 功能（输入的两个值必须一样，均为 1 或均为 0），即：<br>XNOR = (x1 ANDx2) OR((NOT x1)AND(NOT x2))</p>
<p>首先构造能表达(x1 ANDx2)和(NOT x1)AND(NOT x2)部分的神经元：<br><img src="https://img-blog.csdnimg.cn/20200711125641473.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200711125006673.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>然后将表示 AND 的神经元和表示(NOT x1)AND(NOT x2)的神经元以及表示 OR 的神经元进行组合：<br><img src="https://img-blog.csdnimg.cn/20200711125423807.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>这样就得到了一个能实现 XNOR 运算符功能的神经网络。</p>
<p>按这种方法可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征值。这就是神经网络的厉害之处。</p>
<h3 id="6-3-Multi-class-Classification-多元分类"><a href="#6-3-Multi-class-Classification-多元分类" class="headerlink" title="6.3 Multi-class Classification(多元分类)"></a>6.3 Multi-class Classification(多元分类)</h3><p>当有不止两种分类时（也就是𝑦 = 1,2,3 ….）<br><img src="https://img-blog.csdnimg.cn/2020071112595442.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Networks</tag>
      </tags>
  </entry>
  <entry>
    <title>关于SQL易忘的知识点</title>
    <url>/2020/06/19/%E5%85%B3%E4%BA%8ESQL%E6%98%93%E5%BF%98%E7%9A%84%E5%8D%81%E4%BA%94%E4%B8%AA%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200619102150246.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<p>主要记录SQL尤其是MySQL中，一些看了就忘，需要经常查的小知识点~</p>
<h2 id="1-下划线-通配符与百分号-通配符的区别"><a href="#1-下划线-通配符与百分号-通配符的区别" class="headerlink" title="1. 下划线_通配符与百分号%通配符的区别"></a>1. 下划线_通配符与百分号%通配符的区别</h2><p>下划线的用途与%一样，但是%能匹配0个字符不一样，_总是匹配一个字符，不能多也不能少。<br><img src="https://img-blog.csdnimg.cn/20200502213747941.png" alt="在这里插入图片描述"></p>
<h2 id="2-匹配不区分大小写"><a href="#2-匹配不区分大小写" class="headerlink" title="2. 匹配不区分大小写"></a>2. 匹配不区分大小写</h2><p>通过使用BINARY可以区分，如：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">WHERE prod_name REGEXP BINARY 'JetPack .000'</span><br></pre></td></tr></table></figure>

<h2 id="3-MySQL正则表达式"><a href="#3-MySQL正则表达式" class="headerlink" title="3. MySQL正则表达式"></a>3. MySQL正则表达式</h2><p>正则表达式的作用是匹配文本，将一个模式（正则表达式）与一个文本串进行比较。MySQL<br>用WHERE子句对正则表达式提供了初步的支持，允许你指定正则表达式，过滤SELECT检索出的数据。</p>
<h2 id="4-LIKE和REGEXP的区别"><a href="#4-LIKE和REGEXP的区别" class="headerlink" title="4. LIKE和REGEXP的区别"></a>4. LIKE和REGEXP的区别</h2><p>LIKE匹配整个列。如果被匹配的文本在列值中出现，LIKE将不会找到它，相应的行也不被返回（除非使用通配符）。而REGEXP在列值内进行匹配，如果被匹配的文本在列值中出现，REGEXP将会找到它，相应的行将被返回。这是一个非常重要的差别。</p>
<h2 id="5-匹配"><a href="#5-匹配" class="headerlink" title="5. 匹配"></a>5. 匹配</h2><p><strong>匹配字符</strong><br><img src="https://img-blog.csdnimg.cn/20200502215248363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>匹配特殊字符</strong><br>为了匹配特殊字符，必须用\为前导。\-表示查找-，\.表示查找.。这种处理就是所谓的转义（escaping），正则表达式内具有特殊意义的所有字符都必须以这种方式转义。这包括.、|、[]以及迄今为止使用过的其他特殊字符。<br>\也用来引用元字符（具有特殊含义的字符）。<br><img src="https://img-blog.csdnimg.cn/20200502220002901.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>例：<br><img src="https://img-blog.csdnimg.cn/20200502220945880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><strong>定位符</strong><br><img src="https://img-blog.csdnimg.cn/20200502221139784.png" alt="在这里插入图片描述"><br>例：<br><img src="https://img-blog.csdnimg.cn/2020050222152389.png" alt="在这里插入图片描述"><br><strong>注：^的双重用途</strong><br>^有两种用法。在集合中（用[和]定义），用它来否定该集合，否则，用来指串的开始处。</p>
<h2 id="6-文本处理函数"><a href="#6-文本处理函数" class="headerlink" title="6. 文本处理函数"></a>6. 文本处理函数</h2><p><img src="https://img-blog.csdnimg.cn/20200502224543982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>SOUNDEX是一个将任何文本串转换为描述其语音表示的字母数字模式的算法。使用Soundex()函数进行搜索，它匹配所有发音类似于Y.Lie的联系名：<br><img src="https://img-blog.csdnimg.cn/2020050222515799.png" alt="在这里插入图片描述"><br>拼接：将值联结到一起构成单个值。<br>解决办法是把两个列拼接起来。在MySQL的SELECT语句中，可使用Concat()函数来拼接两个列。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">Concat</span>(ven_name, <span class="string">'('</span>, vend_country, <span class="string">')'</span>)</span><br></pre></td></tr></table></figure>

<h2 id="7-日期和时间处理函数"><a href="#7-日期和时间处理函数" class="headerlink" title="7. 日期和时间处理函数"></a>7. 日期和时间处理函数</h2><p><img src="https://img-blog.csdnimg.cn/20200502225707163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200502231413483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="8-数值处理函数"><a href="#8-数值处理函数" class="headerlink" title="8. 数值处理函数"></a>8. 数值处理函数</h2><p><img src="https://img-blog.csdnimg.cn/20200502231547428.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="9-聚集函数"><a href="#9-聚集函数" class="headerlink" title="9. 聚集函数"></a>9. 聚集函数</h2><p><img src="https://img-blog.csdnimg.cn/20200503104310481.png" alt="在这里插入图片描述"><br>其中，在用于文本数据时，如果数据按相应的列排序，则MAX()返回最后一行，MIN()返回第一行。<br>COUNT()函数有两种使用方式。使用COUNT(*)对表中行的数目进行计数，不管表列中包含的是空值（NULL）还是非空值。使用COUNT(column)对特定列中具有值的行进行计数，忽略NULL值。</p>
<h2 id="10-HAVING和WHERE的区别"><a href="#10-HAVING和WHERE的区别" class="headerlink" title="10. HAVING和WHERE的区别"></a>10. HAVING和WHERE的区别</h2><p>“Where” 是一个约束声明，使用Where来约束来之数据库的数据，Where是在结果返回之前起作用的，且Where中不能使用聚合函数。<br>“Having”是一个过滤声明，是在查询返回结果集以后对查询结果进行的过滤操作，在Having中可以使用聚合函数。<br><img src="https://img-blog.csdnimg.cn/2020050310553535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="11-组合查询UNION"><a href="#11-组合查询UNION" class="headerlink" title="11. 组合查询UNION"></a>11. 组合查询UNION</h2><p>UNION 返回匹配行，不保留重复行<br>UNION ALL 返回匹配行，包括重复行</p>
<p>UNION中的每个查询必须包含相同的列、表达式或聚集函数（不过各个列不需要以相同的次序列出）。<br>在用UNION组合查询时，只能使用一条ORDER BY子句，它必须出现在最后一条SELECT语句之后。对于结果集，不存在用一种方式排序一部分，而又用另一种方式排序另一部分的情况，因此不允许使用多条ORDER BY子句。</p>
<h2 id="12-全文本搜索"><a href="#12-全文本搜索" class="headerlink" title="12. 全文本搜索"></a>12. 全文本搜索</h2><p><img src="https://img-blog.csdnimg.cn/2020050311335215.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>查询扩展<br><img src="https://img-blog.csdnimg.cn/20200503113851840.png" alt="在这里插入图片描述"><br>表中的行越多（这些行中的文本就越多），使用查询扩展返回的结果越好。</p>
<p>布尔文本搜索<br><img src="https://img-blog.csdnimg.cn/20200503114745745.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200503115115309.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在布尔方式中，不按等级值降序排序返回的行。</p>
<h2 id="13-数据插入"><a href="#13-数据插入" class="headerlink" title="13. 数据插入"></a>13. 数据插入</h2><p>插入一行<br><img src="https://img-blog.csdnimg.cn/20200503152023293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>插入多行<br><img src="https://img-blog.csdnimg.cn/20200503152023113.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>插入检索出的数据<br><img src="https://img-blog.csdnimg.cn/20200503152215262.png" alt="在这里插入图片描述"></p>
<h2 id="14-更新数据、删除数据"><a href="#14-更新数据、删除数据" class="headerlink" title="14. 更新数据、删除数据"></a>14. 更新数据、删除数据</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新多个列</span></span><br><span class="line"><span class="keyword">UPDATE</span> customers</span><br><span class="line"><span class="keyword">SET</span> cust_name = <span class="string">'The Fudds'</span>,</span><br><span class="line">	cust_email = <span class="string">'elmer@fudd.com'</span></span><br><span class="line"><span class="keyword">WHERE</span> cust_id = <span class="number">10005</span> ;     <span class="comment">#不要省略WHERE子句</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#删除某个列的值</span></span><br><span class="line"><span class="keyword">UPDATE</span> customers</span><br><span class="line"><span class="keyword">SET</span> cust_email = <span class="literal">NULL</span>    <span class="comment">#其中NULL用来去除cust_email列中的值。</span></span><br><span class="line"><span class="keyword">WHERE</span> cust_id = <span class="number">10005</span> ; </span><br><span class="line"></span><br><span class="line"><span class="comment">#删除数据</span></span><br><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> customers</span><br><span class="line"><span class="keyword">WHERE</span> cust_id = <span class="number">10005</span> ;</span><br><span class="line"><span class="comment">#DELETE不需要列名或通配符。DELETE删除整行而不是删除列,但DELETE不删除表本身。为了删除指定的列，请使用UPDATE语句。</span></span><br></pre></td></tr></table></figure>

<h2 id="15-主键、索引和外键"><a href="#15-主键、索引和外键" class="headerlink" title="15. 主键、索引和外键"></a>15. 主键、索引和外键</h2><p>主键的作用：</p>
<ul>
<li>惟一地标识一行。 </li>
<li>作为一个可以被外键有效引用的对象。</li>
</ul>
<p>索引：索引分为主键索引、唯一索引、普通索引、全文索引、组合索引等</p>
<ul>
<li>主键索引（PRIMARY KEY）：<strong>不可以为空</strong>，<strong>可以做外键</strong>，一张表中只能有一个主键索引。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> PRIMARY <span class="keyword">KEY</span> ( <span class="string">`column`</span> )</span><br></pre></td></tr></table></figure>

<ul>
<li>唯一索引（UNIQUE）：被索引的数据列不允许包含重复的值，但<strong>允许有空值。</strong></li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> <span class="keyword">UNIQUE</span> (<span class="string">`column`</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>普通索引（INDEX）：用来加速数据访问速度而建立的索引。多建立在经常出现在查询条件的字段和经常用于排序的字段。被索引的数据列允许包含重复的值。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> <span class="keyword">INDEX</span> index_name ( <span class="string">`column`</span> )</span><br></pre></td></tr></table></figure>

<ul>
<li>全文索引（FULLTEXT）：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时好空间。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> FULLTEXT ( <span class="string">`column`</span> )</span><br></pre></td></tr></table></figure>

<ul>
<li>组合索引：为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> <span class="string">`table_name`</span> <span class="keyword">ADD</span> <span class="keyword">INDEX</span> index_name ( <span class="string">`column1`</span>, <span class="string">`column2`</span>, <span class="string">`column3`</span> )</span><br></pre></td></tr></table></figure>


<p>主键和索引：主键是为了标识数据库记录唯一性，不允许记录重复，且键值不能为空，主也是一个特殊索引。数据表中只允许有一个主键，但是可以有多个索引。</p>
<p>外键：<br><img src="https://img-blog.csdnimg.cn/20200524190007537.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>《MySQL必知必会》Ben Forta 著，刘晓霞 钟鸣 译<br><a href="https://www.liaoxuefeng.com/wiki/1177760294764384/1218728424164736" target="_blank" rel="noopener">SQL教程 廖雪峰。</a></p>
]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>SQL</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Python对淘宝用户行为进行数据分析</title>
    <url>/2020/06/18/%E4%BD%BF%E7%94%A8Python%E5%AF%B9%E6%B7%98%E5%AE%9D%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200429154952128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>


<h1 id="1-分析背景与意义"><a href="#1-分析背景与意义" class="headerlink" title="1  分析背景与意义"></a>1  分析背景与意义</h1><p>淘宝网是中国深受欢迎的网购零售平台，拥有近5亿的注册用户数，每天有超过6000万的固定访客，同时每天的在线商品数已经超过了8亿件，平均每分钟售出4.8万件商品。<br>用户行为分析则是电商平台的重要事务，通过对用户行为的分析，有助于企业根据用户的行为习惯，找出网站、推广渠道等企业营销环境存在的问题，从而让企业的营销更加精准、有效，提升企业的广告收益。</p>
<h1 id="2-分析思路"><a href="#2-分析思路" class="headerlink" title="2  分析思路"></a>2  分析思路</h1><p>针对数据集中的用户、商品、商品种类、用户行为、时间等信息，使用Python对数据进行切片分类汇总等多种数据分析手段，从不同角度挖掘蕴含的价值。本次通过以下四个方向探索淘宝用户行为：<br><img src="https://img-blog.csdnimg.cn/20200428165245175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="3-分析内容"><a href="#3-分析内容" class="headerlink" title="3  分析内容"></a>3  分析内容</h1><h2 id="3-1-提出问题"><a href="#3-1-提出问题" class="headerlink" title="3.1  提出问题"></a>3.1  提出问题</h2><p>本次通过对淘宝用户行为数据分析，期望解决以下业务问题：</p>
<p> 1） 用户从浏览到最终购买整个过程的流失情况，确定夹点位置。<br> 2） 找出用户最活跃的日期以及活跃时间段，了解用户的行为时间模式。<br> 3） 找出最具价值的核心付费用户群。<br> 4） 找出最受用户青睐的产品。</p>
<h2 id="3-2-理解数据"><a href="#3-2-理解数据" class="headerlink" title="3.2  理解数据"></a>3.2  理解数据</h2><p>数据集：UserBehavior.csv。本次报告随机采集了在2017年11月25日至2017年12月3日之间，淘宝用户的行为，其中行为包括浏览、加购物车、收藏、购买等。数据集主要包含：用户数量约3万（37,376），商品数量约9万（930,607），商品类目数量7106以及总的淘宝用户行为记录数量为3百万（3,835,329）。<br>数据来源：<a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=649&amp;userId=1" target="_blank" rel="noopener">https://tianchi.aliyun.com/dataset/dataDetail?dataId=649&amp;userId=1</a><br>字段含义：<br>| 列名称 | 说明 |<br>|–|–|<br>|User ID  | 整数类型，序列化后的用户ID |<br>|Item ID| 整数类型，序列化后的商品ID |<br>|Category ID | 整数类型，序列化后的商品所属类目ID |<br>|Behavior type  | 字符串，枚举类型，包括(‘pv’, ‘buy’, ‘cart’, ‘fav’) |<br>|Timestamp | 行为发生的时间戳 |</p>
<p>用户行为类型共有四种，它们分别是：</p>
<table>
<thead>
<tr>
<th>行为类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>pv</td>
<td>商品详情页pv，等价于点击</td>
</tr>
<tr>
<td>buy</td>
<td>商品购买</td>
</tr>
<tr>
<td>cart</td>
<td>将商品加入购物车</td>
</tr>
<tr>
<td>fav</td>
<td>收藏商品</td>
</tr>
</tbody></table>
<h2 id="3-3-数据清洗"><a href="#3-3-数据清洗" class="headerlink" title="3.3  数据清洗"></a>3.3  数据清洗</h2><h3 id="3-3-1-数据导入"><a href="#3-3-1-数据导入" class="headerlink" title="3.3.1 数据导入"></a>3.3.1 数据导入</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]</span><br><span class="line">plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">path = <span class="string">'./data/UserBehavior.csv'</span></span><br><span class="line">data_user = pd.read_csv(path)</span><br><span class="line">cols = [<span class="string">'UserID'</span>, <span class="string">'ItemID'</span>, <span class="string">'CatogoryID'</span>, <span class="string">'BehaviorType'</span>, <span class="string">'TimeStamps'</span>]</span><br><span class="line">data_user.columns = cols</span><br><span class="line">data_user.head()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200428182653709.PNG" alt="UserID    ItemID    CatogoryID    BehaviorType    TimeStamps
0    1    2333346    2520771    pv    1.511562e+09
1    1    2576651    149192    pv    1.511573e+09
2    1    3830808    4181361    pv    1.511593e+09
3    1    4365585    2520377    pv    1.511596e+09
4    1    4606018    2735466    pv    1.511616e+09"></p>
<h3 id="3-3-2-缺失值分析"><a href="#3-3-2-缺失值分析" class="headerlink" title="3.3.2 缺失值分析"></a>3.3.2 缺失值分析</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_user.apply(<span class="keyword">lambda</span> x: sum(x.isnull()))</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200428182746692.PNG" alt="UserID          0
ItemID          0
CatogoryID      0
BehaviorType    0
TimeStamps      1
dtype: int64"></p>
<p>仅一条数据含有缺失值，删除即可。</p>
<h3 id="3-3-3-选取时间范围"><a href="#3-3-3-选取时间范围" class="headerlink" title="3.3.3 选取时间范围"></a>3.3.3 选取时间范围</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_unixtime</span><span class="params">(timeStr)</span>:</span></span><br><span class="line">    formatStr = <span class="string">"%Y-%m-%d %H:%M:%S"</span></span><br><span class="line">    tmObject = time.strptime(timeStr, formatStr)</span><br><span class="line">    tmStamp = time.mktime(tmObject)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> int(tmStamp)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 数据集描述的时间范围</span></span><br><span class="line">startTime = get_unixtime(<span class="string">"2017-11-25 00:00:00"</span>)</span><br><span class="line">endTime = get_unixtime(<span class="string">"2017-12-3 23:59:59"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选出符合时间范围的数据</span></span><br><span class="line">data_user[<span class="string">'TimeStamps'</span>] = data_user[<span class="string">'TimeStamps'</span>].astype(<span class="string">'int64'</span>)</span><br><span class="line">data_user = data_user.loc[(data_user[<span class="string">'TimeStamps'</span>] &gt;= startTime) &amp; (data_user[<span class="string">'TimeStamps'</span>] &lt;= endTime)]</span><br></pre></td></tr></table></figure>

<h3 id="3-3-4-时间格式处理"><a href="#3-3-4-时间格式处理" class="headerlink" title="3.3.4 时间格式处理"></a>3.3.4 时间格式处理</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#时间处理</span></span><br><span class="line">data_user[<span class="string">'time'</span>] = data_user[<span class="string">'TimeStamps'</span>].apply(<span class="keyword">lambda</span> t: time.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>, time.localtime(t)))</span><br><span class="line">data_user[<span class="string">'date'</span>] = data_user[<span class="string">'time'</span>].str[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">data_user[<span class="string">'hour'</span>] = data_user[<span class="string">'time'</span>].str[<span class="number">11</span>:<span class="number">13</span>].astype(int)</span><br><span class="line">data_user[<span class="string">'date'</span>] = pd.to_datetime(data_user[<span class="string">'date'</span>])</span><br><span class="line"></span><br><span class="line">data_user.head()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200428182859412.PNG" alt="在这里插入图片描述"></p>
<h2 id="3-4-构建模型"><a href="#3-4-构建模型" class="headerlink" title="3.4 构建模型"></a>3.4 构建模型</h2><h3 id="3-4-1-用户行为转化（AARRR模型）"><a href="#3-4-1-用户行为转化（AARRR模型）" class="headerlink" title="3.4.1 用户行为转化（AARRR模型）"></a>3.4.1 用户行为转化（AARRR模型）</h3><p><strong>跳失率计算：</strong><br>跳失率 = 只浏览一个页面就离开的访问次数 / 该页面的全部访问次数<br>结果显示只有点击行为没有收藏、加购物车以及购买行为的总用户数是2196，除以总用户数37376得到跳失率为5.88%。说明用户对商品详情页的关注很大，商品详情页的商品描述，细节等吸引点不足，是流失用户的的重要原因之一。具体造成用户在浏览商品详情页后流失的原因，要根据实际情况分析，建议可以采用在线问卷调查的方式get用户的痛点，针对性调整。</p>
<p><strong>日ARPPU计算：</strong><br>ARPPU全称为Average Revenue Per Paying User，也就是每付费用户平均收益。这个指标考核的是某时间段内平均每个付费用户为应用创造的收入。在用户数量上，ARPPU只考虑某一时间段内的付费用户，而非该时间段内所有的活跃用户。<br>对于同一时间的同一应用而言，ARPPU的数值会明显高于ARPU。<br>ARPPU能够反映付费用户为你的应用带来了多少收益，显示出一个忠诚付费用户实际上愿意支付的金额。同时，这个指标也可以显示用户对一些付费项目的反应。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_user_buy1 = data_user[data_user.BehaviorType == <span class="string">'buy'</span>].groupby([<span class="string">'date'</span>,<span class="string">'UserID'</span>]).count()[<span class="string">'BehaviorType'</span>].reset_index().rename(columns=&#123;<span class="string">'BehaviorType'</span>:<span class="string">'total'</span>&#125;)</span><br><span class="line"></span><br><span class="line">data_user_buy2 = data_user_buy1.groupby(<span class="string">'date'</span>).sum()[<span class="string">'total'</span>] / data_user_buy1.groupby(<span class="string">'date'</span>).count()[<span class="string">'total'</span>]</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">data_user_buy2.plot()</span><br><span class="line">plt.ylabel(<span class="string">'日ARPPU'</span>)</span><br><span class="line">plt.title(<span class="string">'ARPPU变化情况'</span>)</span><br><span class="line">plt.savefig(<span class="string">'ARPPU变化情况'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200428195148932.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt=""><br><img src="https://img-blog.csdnimg.cn/20200428195401501.PNG" alt="在这里插入图片描述"><br>由图像可以看出，在12月2日及12月3日的日ARPPU为最低位，分析可能是由于高的PV值但实际消费的用户数并不多。</p>
<p><strong>日ARPU计算：</strong><br>ARPU的全称是Average Revenue Per User，也就是每用户平均收入。这个指标计算的是某时间段内平均每个活跃用户为应用创造的收入。<br>ARPU的计算中，所有的用户都被纳入了计算范围——无论是付费用户或非付费用户。ARPU是评估应用变现有效性的指标：ARPU越高，就代表用户在这段时间内为应用带来的变现收入就越多。<br>ARPU可用于评估应用中的变动是否能有效提升变现收益：如果ARPU提升，证明应用的变动有利于提升应用变现收益；如果ARPU不升反降，应用开发者可能就需要确认一下变动的有效性了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_user[<span class="string">'operation'</span>] = <span class="number">1</span></span><br><span class="line">data_user_buy2 = data_user.groupby([<span class="string">'date'</span>, <span class="string">'UserID'</span>, <span class="string">'BehaviorType'</span>])[<span class="string">'operation'</span>].count().reset_index().rename(columns = &#123;<span class="string">'operation'</span>:<span class="string">'total'</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#每天消费总次数/每天总活跃人数</span></span><br><span class="line">data_user_buy2.groupby(<span class="string">'date'</span>).apply(<span class="keyword">lambda</span> x: x[x[<span class="string">'BehaviorType'</span>] == <span class="string">'buy'</span>].total.sum()/len(x.UserID.unique()) ).plot()</span><br><span class="line">plt.ylabel(<span class="string">'日ARPU'</span>)</span><br><span class="line">plt.title(<span class="string">'ARPU变化情况'</span>)</span><br><span class="line">plt.savefig(<span class="string">'ARPU变化情况'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200429160428770.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#（付费率）每天消费人数/每天总活跃人数</span></span><br><span class="line">data_user_buy2.groupby(<span class="string">'date'</span>).apply(<span class="keyword">lambda</span> x: x[x[<span class="string">'BehaviorType'</span>] == <span class="string">'buy'</span>].total.count()/len(x.UserID.unique()) ).plot()</span><br><span class="line">plt.ylabel(<span class="string">'付费率'</span>)</span><br><span class="line">plt.title(<span class="string">'付费率变化情况'</span>)</span><br><span class="line">plt.savefig(<span class="string">'付费率变化情况'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200429160413221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>日ARPU图像、付费率图像相似，均在12月2日和12月3日处于低位，而在工作日处于较高的水平。</p>
<p><strong>用户行为情况</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 多子图绘制 如：将上面用到的图形一起绘制</span></span><br><span class="line"><span class="comment"># 导入subplots（类似matplotlib）</span></span><br><span class="line"><span class="keyword">from</span> plotly.subplots <span class="keyword">import</span> make_subplots</span><br><span class="line"></span><br><span class="line">labels = df_userbehavior[<span class="string">'behavior'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create subplots: use 'domain' type for Pie subplot</span></span><br><span class="line">fig = make_subplots(rows=<span class="number">1</span>, cols=<span class="number">2</span>, specs=[[&#123;<span class="string">'type'</span>:<span class="string">'domain'</span>&#125;, &#123;<span class="string">'type'</span>:<span class="string">'domain'</span>&#125;]])</span><br><span class="line">fig.add_trace(go.Pie(labels=labels, values=data_user_count.values, name=<span class="string">"淘宝用户行为"</span>),</span><br><span class="line">              <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">fig.add_trace(go.Pie(labels=labels, values=df_userbehavior[<span class="string">'count'</span>], name=<span class="string">"淘宝独立用户行为"</span>),</span><br><span class="line">              <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use `hole` to create a donut-like pie chart</span></span><br><span class="line">fig.update_traces(hole=<span class="number">.4</span>, hoverinfo=<span class="string">"label+percent+name"</span>)</span><br><span class="line"></span><br><span class="line">fig.update_layout(</span><br><span class="line">    title_text=<span class="string">"淘宝用户行为情况 | 左：淘宝用户行为， 右：淘宝独立用户行为"</span>,</span><br><span class="line">    <span class="comment"># Add annotations in the center of the donut pies.</span></span><br><span class="line">    annotations=[dict(text=<span class="string">'非独立'</span>, x=<span class="number">0.18</span>, y=<span class="number">0.5</span>, font_size=<span class="number">20</span>, showarrow=<span class="literal">False</span>),</span><br><span class="line">                 dict(text=<span class="string">'独立'</span>, x=<span class="number">0.8</span>, y=<span class="number">0.5</span>, font_size=<span class="number">20</span>, showarrow=<span class="literal">False</span>)])</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200430152910340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>用户点击行为占总行为数的89.5%，收藏和加购行为加起来的行为数只占总行为数的8.47%，而对于独立用户来说，点击行为的占比明显缩小为35.2%。推测用户可能在挑选产品环节浪费了较多的时间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Funnel</span><br><span class="line"><span class="keyword">from</span> pyecharts.faker <span class="keyword">import</span> Faker</span><br><span class="line"></span><br><span class="line">attr = [<span class="string">'浏览'</span>, <span class="string">'放入购物车'</span>, <span class="string">'收藏'</span>, <span class="string">'购买'</span>]</span><br><span class="line">value = [<span class="number">3431904</span>, <span class="number">213634</span>, <span class="number">111140</span>, <span class="number">76707</span>]    <span class="comment">#这里有个bug</span></span><br><span class="line">funnel = Funnel()</span><br><span class="line">funnel.add(<span class="string">"淘宝用户行为"</span>, [list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)])</span><br><span class="line">funnel.set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"淘宝用户行为"</span>))</span><br><span class="line">funnel.render(<span class="string">"funnel_base.html"</span>) </span><br><span class="line">funnel.render_notebook()</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200429202820614.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<table>
<thead>
<tr>
<th>项目</th>
<th>流失率</th>
</tr>
</thead>
<tbody><tr>
<td>pv_to_cart</td>
<td>93.78%</td>
</tr>
<tr>
<td>cart_to_fav</td>
<td>47.98%</td>
</tr>
<tr>
<td>fav_to_buy</td>
<td>30.98%</td>
</tr>
<tr>
<td>pv_to_buy</td>
<td>97.76%</td>
</tr>
</tbody></table>
<p>从点击到购买的全过程中，流失率主要集中在点击到加入购物车这一环节，流失率高达93.78%，收藏及加入购物车后购买商品的可能性增大。</p>
<p><strong>用户留存率</strong><br>留存用户：在某段时间开始使用产品，经过一段时间后仍然继续使用产品的用户，即为留存用户。<br>留存率=仍旧使用产品的用户量/最初的总用户量。<br>根据时间维度进行分类，留存率经常分为次日留存、3日留存、7日留存以及30日留存等。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line"><span class="comment">#建立n日留存率计算函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_retention</span><span class="params">(data,n)</span>:</span> <span class="comment">#n为n日留存</span></span><br><span class="line">    user=[]</span><br><span class="line">    date=pd.Series(data.date.unique()).sort_values()[:-n] <span class="comment">#时间截取至最后一天的前n天</span></span><br><span class="line">    retention_rates=[]</span><br><span class="line">    new_users=[]</span><br><span class="line">    retention_user=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> date:</span><br><span class="line">        new_user=set(data[data.date==i].UserID.unique())-set(user) <span class="comment">#识别新用户，本案例中设初始用户量为零</span></span><br><span class="line">        user.extend(new_user)  <span class="comment">#将新用户加入用户群中</span></span><br><span class="line">        <span class="comment">#第n天留存情况</span></span><br><span class="line">        user_nday=data[data.date==i+timedelta(n)].UserID.unique() <span class="comment">#第n天登录的用户情况</span></span><br><span class="line">        a=<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> UserID <span class="keyword">in</span> user_nday:</span><br><span class="line">            <span class="keyword">if</span> UserID <span class="keyword">in</span> new_user:</span><br><span class="line">                a+=<span class="number">1</span></span><br><span class="line">        b = len(new_user)</span><br><span class="line">        retention_rate=a/b <span class="comment">#计算该天第n日留存率</span></span><br><span class="line">        retention_rates.append(retention_rate) <span class="comment">#汇总n日留存数据</span></span><br><span class="line">        new_users.append(b) <span class="comment">#汇总n日的新用户数</span></span><br><span class="line">        retention_user.append(a) <span class="comment">#汇总n日留存的用户数</span></span><br><span class="line">    data_new_user = pd.Series(new_users, index=date)</span><br><span class="line">    data_retention_user = pd.Series(retention_user, index=date)</span><br><span class="line">    data_retention_rate = pd.Series(retention_rates,index=date)</span><br><span class="line">    data_retention = pd.concat([data_new_user,data_retention_user,data_retention_rate], axis=<span class="number">1</span>)</span><br><span class="line">    data_retention.columns=[<span class="string">'new_user'</span>,<span class="string">'retention_user'</span>,<span class="string">'retention_rate'</span>]</span><br><span class="line">    <span class="keyword">return</span> data_retention</span><br><span class="line"></span><br><span class="line">data_retention1=cal_retention(data_user,<span class="number">1</span>)</span><br><span class="line">data_retention2=cal_retention(data_user,<span class="number">2</span>)</span><br><span class="line">data_retention6=cal_retention(data_user,<span class="number">6</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429202657966.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>用户的次日留存率及3日留存率均约为60%-70%的范围内，现有数据可以看出7日的留存率较高，推测是由于临近双十二，商家纷纷举办活动，促使留存率提高。可继续观测留存率等指标，以确定留存率的变化规律。</p>
<p><strong>复购</strong><br><img src="https://img-blog.csdnimg.cn/20200429160546213.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200429144949479.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_rebuy[data_rebuy&gt;=<span class="number">2</span>].count()/data_rebuy.count()</span><br></pre></td></tr></table></figure>
<p>复购率=54.94%<br><img src="https://img-blog.csdnimg.cn/20200429221206329.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200429221828232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>淘宝平台和用户的粘性很高，9日内的复购率达到54.94%。但有的用户购买次数高达到84次。9天里有84次的购买行为，平均一天有9次购买行为，这不符合常理，为什么他们的购买次数如此高呢？是否存在刷单现象？进一步分析验证购买次数较高的用户平时购买情况，以及账户，购物，物流等信息才能判断。这里数据有限，不深入探究其原由。</p>
<h3 id="3-4-2-用户活跃时间"><a href="#3-4-2-用户活跃时间" class="headerlink" title="3.4.2 用户活跃时间"></a>3.4.2 用户活跃时间</h3><p>找出用户最活跃的日期以及活跃时间段，了解用户的行为时间模式。</p>
<p> <strong>按日统计流量指标</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pv_daily = data_user.groupby(<span class="string">'date'</span>).count()[<span class="string">'UserID'</span>]</span><br><span class="line">uv_daily = data_user.groupby(<span class="string">'date'</span>)[<span class="string">'UserID'</span>].apply(<span class="keyword">lambda</span> x: x.drop_duplicates().count())</span><br><span class="line"></span><br><span class="line">pv_uv_daily = pd.concat([pv_daily,uv_daily], axis=<span class="number">1</span>)</span><br><span class="line">pv_uv_daily.columns=[<span class="string">'pv'</span>,<span class="string">'uv'</span>]</span><br><span class="line">pv_uv_daily</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200428182946544.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428183309451.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/2020042818371289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>可以发现，PV与UV的每日变化趋势大致相同：工作日维持在低值，其中周二（11-27）的访问量达到统计范围内最低值；而11月25日、11月26日和12月2日、12月3日同为周末，但后者却有更多的活跃用户，环比增长率约为32%，推测可能是平台做促销活动。检索可知正值“双十二”前夕，各类预热活动促进用户访问增长。</p>
<p><strong>按小时统计流量指标</strong><br><img src="https://img-blog.csdnimg.cn/20200428183945718.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428183945615.PNG" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428184115560.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200428185100247.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>结合人们日常作息规律，0点至6点是休息时间，点击量处于低谷阶段；6点至10点，人们慢慢开始工作，点击量开始回暖；10点至18点为正常工作时间，点击量保持平稳；18点至20点，人们相继下班休息，点击量不断升高；在21点至22点期间，点击量到达高峰。</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>数值</th>
</tr>
</thead>
<tbody><tr>
<td>pv</td>
<td>3833385</td>
</tr>
<tr>
<td>uv</td>
<td>264304</td>
</tr>
<tr>
<td>pv/uv</td>
<td>14.50</td>
</tr>
</tbody></table>
<h3 id="3-4-3-用户价值分析（RFM模型）"><a href="#3-4-3-用户价值分析（RFM模型）" class="headerlink" title="3.4.3 用户价值分析（RFM模型）"></a>3.4.3 用户价值分析（RFM模型）</h3><p>因为本数据集没有提供M（消费金额）列，因此只能通过R（最近一次购买时间）和F（消费频率）的数据对客户价值进行打分。<br>|RFM|业务含义|1分|2分|<br>|–|–|–|–|<br>|R|最近交易日期与2017.12.4距离天数|3<del>9|0</del>3|<br>|F|购买次数|0<del>2|2</del>84|<br>其中，<br>RF=11为重要挽回客户；<br>RF=12为重要唤回客户；<br>RF=21为重要深耕客户：<br>RF=22为重要价值客户。</p>
<p><img src="https://img-blog.csdnimg.cn/20200429205729118.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trace_basic = [go.Bar(x = rfm[<span class="string">'rank'</span>].value_counts().index,</span><br><span class="line">                     y = rfm[<span class="string">'rank'</span>].value_counts().values,</span><br><span class="line">                     marker = dict(color=<span class="string">'orange'</span>), opacity=<span class="number">0.50</span>)]</span><br><span class="line">layout = go.Layout(title=<span class="string">'用户等级情况'</span>, xaxis=dict(title=<span class="string">'用户重要度'</span>))</span><br><span class="line">figure_basic = go.Figure(data=trace_basic, layout=layout)</span><br><span class="line">figure_basic</span><br><span class="line"></span><br><span class="line">trace = [go.Pie(labels=rfm[<span class="string">'rank'</span>].value_counts().index,</span><br><span class="line">                values = rfm[<span class="string">'rank'</span>].value_counts().values,</span><br><span class="line">               textfont = dict(size=<span class="number">12</span>,color=<span class="string">'white'</span>))]</span><br><span class="line">layout = go.Layout(title=<span class="string">'用户等级比例'</span>)</span><br><span class="line">figure_pie = go.Figure(data=trace, layout=layout)</span><br><span class="line">figure_pie</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429134429735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20200429134429728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-4-4-用户产品偏好"><a href="#3-4-4-用户产品偏好" class="headerlink" title="3.4.4 用户产品偏好"></a>3.4.4 用户产品偏好</h3><p><strong>商品</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">16</span>,<span class="number">12</span>))</span><br><span class="line"><span class="comment">#柱形图</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">ax1.bar(data_item_count.index, data_item_count.values)</span><br><span class="line"><span class="keyword">for</span> a,b <span class="keyword">in</span> zip(data_item_count.index,data_item_count.values):</span><br><span class="line">    plt.text(a, b+<span class="number">100</span>,<span class="string">'%s'</span>% b, ha=<span class="string">'center'</span>, va= <span class="string">'bottom'</span>,fontsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#平滑化</span></span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"></span><br><span class="line">x = data_item_count.index</span><br><span class="line">y = df_item_count[<span class="string">'percentage'</span>]</span><br><span class="line">tck = interpolate.splrep(x, y, s=<span class="number">0</span>)</span><br><span class="line">xnew = np.linspace(x.min(),x.max(),<span class="number">100</span>)</span><br><span class="line">ynew = interpolate.splev(xnew, tck, der=<span class="number">0</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">#折线图</span></span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">ax2.plot(xnew, ynew, label=<span class="string">"percentage"</span>, color=<span class="string">'red'</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_ylabel(<span class="string">'商品数目'</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">'所占百分比'</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">'购买次数'</span>)</span><br><span class="line">plt.title(<span class="string">'商品销售分布'</span>, fontsize=<span class="number">25</span>)</span><br><span class="line">plt.savefig(<span class="string">'商品销售分布'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429134737600.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>没有出现购买数量非常集中的商品，说明店铺盈利主要依靠长尾商品的累积效应。在电子商务行业中，相较于传统零售行业成本减少，使得后80%的商品也可以销售出去，并且实现盈利，因此将长尾部分的商品优化推荐好，能够给企业带来更大的收益。</p>
<p><strong>商品种类</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax1 = df_catogory_buy[[<span class="string">'buy'</span>, <span class="string">'fav'</span>, <span class="string">'cart'</span>, <span class="string">'pv'</span>]].plot.bar()</span><br><span class="line"></span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">df_catogory_buy.index = df_catogory_buy.index.astype(str)</span><br><span class="line">ax2.plot(df_catogory_buy.index, df_catogory_buy[[<span class="string">'buy/pv'</span>]])</span><br><span class="line"></span><br><span class="line">ax1.set_ylabel(<span class="string">'次数'</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">'转化率'</span>)</span><br><span class="line">plt.title(<span class="string">'购买次数前二十的商品种类'</span>)</span><br><span class="line">plt.savefig(<span class="string">'购买次数前二十的商品种类'</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429134857925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> plotly.express <span class="keyword">as</span> px</span><br><span class="line">fig = px.treemap(</span><br><span class="line">    df_buy, path=[<span class="string">'CatogoryID'</span>], values=<span class="string">'购买次数'</span>, title=<span class="string">'购买次数前二十的商品种类'</span></span><br><span class="line">)</span><br><span class="line">fig.show() </span><br><span class="line"></span><br><span class="line">fig = px.treemap(</span><br><span class="line">    df_item_buy, path=[<span class="string">'CatogoryID'</span>,<span class="string">'ItemID'</span>], values=<span class="string">'count'</span>, title=<span class="string">'商品购买情况(销量前100)'</span></span><br><span class="line">)</span><br><span class="line">fig.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://img-blog.csdnimg.cn/20200429150740642.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><img src="https://img-blog.csdnimg.cn/20200429154952128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="4-结论与建议"><a href="#4-结论与建议" class="headerlink" title="4 结论与建议"></a>4 结论与建议</h1><p>本报告基于AARRR模型和RFM模型，从四个维度提出关于淘宝业务问题。<br><strong>A.  通过AARRR模型分析用户行为转化的各个环节</strong></p>
<p><strong>获取用户（Acquisition）</strong><br>根据12月2日和12月3日活跃用户明显增长，推测在此期间店铺举办了营销活动。检索可知正值“双十二”前夕，各类预热活动促进用户访问增长。<br>获取用户意味着需要拓展页面流量，相对较大型的电商营销活动至少可以从以下三个方面获取流量：</p>
<ul>
<li><input disabled="" type="checkbox"> 充分利用站内资源</li>
<li><input disabled="" type="checkbox"> 跨行合作</li>
<li><input disabled="" type="checkbox"> 产品功能辅助流量增长（场次预约、SNS后置奖品分享）</li>
</ul>
<p><strong>激活用户（Activation）</strong><br>计算跳失率为5.88%，独立访客从浏览到购买的转化率为xxx%，说明产品详情页对用户有着不错的吸引力；但从用户行为转化漏斗来看，用户行为转化夹点位置在点击-加购环节，其中用户点击行为占总行为数的89.50%，而收藏和加购行为加起来的行为数只占总行为数的8.47%，推测用户可能在挑选产品环节浪费了较多的时间，另外低购买意愿转化率还可能与刚完成的双11大促有关。</p>
<p>提高加购转化率的建议：</p>
<ul>
<li><input disabled="" type="checkbox"> 优化搜索引擎，利用用户画像优化商品匹配，个性化地推荐用户感兴趣的商品</li>
<li><input disabled="" type="checkbox"> 优化商品界面加购与收藏按键布局，以便用户触达</li>
<li><input disabled="" type="checkbox"> 分析双十一活动对双十二的影响，合理设置活动内容</li>
</ul>
<p><strong>留存用户（Retention）</strong><br>用户留存其指标之于电商就是回访率。用户的次日留存率及3日留存率均约为60%-70%的范围内，现有数据可以看出7日的留存率较高，推测是由于临近双十二，商家纷纷举办活动，促使留存率提高。<br>活动基本都会划分为三个阶段：</p>
<ul>
<li><input disabled="" type="checkbox"> 预热期：预约造势，通过sns、定金裂变等玩法吸引用户关注</li>
<li><input disabled="" type="checkbox"> 正式期：前面如果证实是好的激励体系，可以让活动健康持续发展</li>
<li><input disabled="" type="checkbox"> 高潮期：进一步引爆高潮，使用的激励方式，成长值会员体系、签到体系、积分任务体系等</li>
</ul>
<p><strong>增加收入（Revenue）</strong><br>在有购买行为的用户中，54.94%的用户选择重复购买。<br>对于用户复购情况，9天内网站有复购现象的用户数接近60%，但是总体上约30%的用户产生了80%的消费次数，复购次数多的用户偏少，可能与双11刚结束，双12未开始的特殊时段有关，建议拉长分析区间分析复购情况。<br>提高收入的建议：</p>
<ul>
<li><input disabled="" type="checkbox"> 开展营销活动，比如淘宝的达成金主的条件限制，鼓励用户复购</li>
<li><input disabled="" type="checkbox"> 在客户发生首购行为后，定时通过客服/短信发放特殊优惠，以提高复购率</li>
<li><input disabled="" type="checkbox"> 优惠券的和优惠策略的在制定时需考虑成本，充分使用推广资金</li>
</ul>
<p><strong>自传播（Refer）</strong><br>通过自传播获取用户的成本很低，而且效果有可能非常好，唯一的前提是产品自身要足够好，有很好的口碑。因此平台需要建立对产品的质量监控机制，如在产品的差评率较高时需对产品进行检测。</p>
<ul>
<li><input disabled="" type="checkbox"> 优化产品，保证产品的质量</li>
<li><input disabled="" type="checkbox"> 提高服务售前及售后质量</li>
</ul>
<p><strong>B.  研究用户时间模式，找到用户在不同时间周期下的活跃规律</strong><br>a)  分析2017年11月25日至12月3日9天里用户每天的点击量：</p>
<p>发现工作日维持在低值，其中周二（11-27）的访问量达到统计范围内最低值；而11月25日、11月26日和12月2日、12月3日同为周末，但后者却有更多的活跃用户，环比增长率约为32%，推测可能是平台做促销活动。检索可知正值“双十二”前夕，各类预热活动促进用户访问增长。</p>
<p>b)  分析2017年11月25日至12月3日9天里用户每时段的点击量：</p>
<p>结合人们日常作息规律，0点至6点是休息时间，点击量处于低谷阶段；6点至10点，人们慢慢开始工作，点击量开始回暖；10点至18点为正常工作时间，点击量保持平稳；18点至20点，人们相继下班休息，点击量不断升高；在21点至22点期间，点击量到达高峰。高峰期用户最活跃，建议商家在用户该时段，经常更新产品信息，黄金展位，活动推荐商品等 。 </p>
<p><strong>C.  通过RFM模型对用户价值分层</strong><br>通过RFM模型分析得到的不同类型的用户，应该采取不同的激励方案。<br>对于RF=22的重要价值客户，应该提高满意度，增加留存。<br>对于RF=21的重要深耕客户，可通过折扣或捆绑销售等活动，提高购买频率。<br>对于RF=12的重要唤回客户，分析其偏好，更精准地推送商品，以防流失。<br>对于RF=11的重要挽回客户，可考虑发放限时优惠券，促进关注与消费。</p>
<p><strong>D.  找出用户产品偏好，制定商品营销策略</strong><br>用户偏好商品类别里并没有出现购买数量非常集中的商品，说明商品售卖主要依靠长尾商品的累积效应，而非爆款商品的带动，这也是双11之后用户的补充采买的特征，同时发现此时用户购买的品类以及商品的浏览量很低，用户的个人喜好特征表现明显，同时浏览量高的商品购买转化率低。<br>对于高浏览量商品，可以将重心转移至定价上，实行差异化定价，同时改善商品页面、详情页以及评论区的管理，以提高购买量<br>对于高购买率商品，建议提高曝光率，结合多平台宣传，提高浏览量<br>对于明星商品，建议平台给予表扬与内部公开，以保证持续的优质</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1] <a href="http://www.zuopm.com/data/188.html" target="_blank" rel="noopener">http://www.zuopm.com/data/188.html</a><br>[2] <a href="https://blog.csdn.net/MsSpark/article/details/86727058" target="_blank" rel="noopener">https://blog.csdn.net/MsSpark/article/details/86727058</a><br>[3] <a href="https://zhuanlan.zhihu.com/p/63853715" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63853715</a></p>
]]></content>
      <categories>
        <category>python</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>用户行为</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫爬取招聘信息并进行数据分析</title>
    <url>/2020/06/18/%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E6%8B%9B%E8%81%98%E4%BF%A1%E6%81%AF%E5%B9%B6%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200618161152222.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h1 id="一、结果放在最前面"><a href="#一、结果放在最前面" class="headerlink" title="一、结果放在最前面"></a>一、结果放在最前面</h1><p><img src="https://img-blog.csdnimg.cn/20200531144422829.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="请忽略"><br>（请忽略截图右边的蓝色正方形）<br>使用爬虫爬取智联招聘上关于“数据分析师”岗位的信息，并应用flask和echarts技术实现数据分析结果。</p>
<h1 id="二、爬虫"><a href="#二、爬虫" class="headerlink" title="二、爬虫"></a>二、爬虫</h1><p>主函数(main)：实现网页解析以及数据存储。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    kw = input(<span class="string">"请输入你要搜索的岗位关键字："</span>).strip()</span><br><span class="line">    keyword = urllib.parse.quote(urllib.parse.quote(kw))   <span class="comment">#二次编码</span></span><br><span class="line">    <span class="comment"># ka = input("请输入你要搜索的地区：").strip()</span></span><br><span class="line">    <span class="comment"># karea = getArea(ka)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">165</span>):</span><br><span class="line">        print(<span class="string">'正在爬取第&#123;&#125;页信息'</span>.format(i))</span><br><span class="line">        baseurl = <span class="string">"https://search.51job.com/list/"</span>+ str(<span class="number">000000</span>) +<span class="string">",000000,0000,00,9,99,"</span>+ keyword +<span class="string">",2,"</span>+ str(i) +<span class="string">".html"</span>    <span class="comment">#全国+keyword</span></span><br><span class="line">        html = askURL(baseurl)</span><br><span class="line">        bs = BeautifulSoup(html,<span class="string">"html.parser"</span>)</span><br><span class="line"></span><br><span class="line">        datalist = getData(bs)</span><br><span class="line">        dbpath = <span class="string">"./51job.db"</span></span><br><span class="line">        saveDB(datalist, dbpath)</span><br></pre></td></tr></table></figure>
<p>网页解析(askURL)：调用request和BeautifulSoup实现网页解析。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">askURL</span><span class="params">(url)</span>:</span></span><br><span class="line">    head = &#123;</span><br><span class="line">        <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    request = urllib.request.Request(url,headers=head)</span><br><span class="line">    html = <span class="string">""</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = urllib.request.urlopen(request)</span><br><span class="line">        html = response.read().decode(<span class="string">'gbk'</span>, <span class="string">'ignore'</span>)</span><br><span class="line">        <span class="comment"># print(html)</span></span><br><span class="line">    <span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">if</span> hasattr(e, <span class="string">"code"</span>):</span><br><span class="line">            print(e.code)</span><br><span class="line">        <span class="keyword">if</span> hasattr(e,<span class="string">"reason"</span>):</span><br><span class="line">            print(e.reason)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> html</span><br></pre></td></tr></table></figure>
<p>数据爬取(getData)：获取招聘信息，公司链接、招聘岗位链接、公司名称、岗位名称、地区、薪水；调用getCOM获取公司链接内的信息，调用getREC获取招聘岗位信息，并合并返回给main()。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getData</span><span class="params">(bs)</span>:</span></span><br><span class="line">    datalist = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> bs.select(<span class="string">".dw_table &gt; div.el"</span>):</span><br><span class="line">        data = &#123;&#125;</span><br><span class="line">        item = str(item)</span><br><span class="line"></span><br><span class="line">        link = re.findall(findLink, item)</span><br><span class="line">        data[<span class="string">'link'</span>] = <span class="string">''</span>.join(link)</span><br><span class="line"></span><br><span class="line">        title = re.findall(findTitle, item)</span><br><span class="line">        data[<span class="string">'title'</span>] = <span class="string">''</span>.join(title)</span><br><span class="line"></span><br><span class="line">        area = re.findall(findArea, item)</span><br><span class="line">        data[<span class="string">'area'</span>] = <span class="string">''</span>.join(area)</span><br><span class="line"></span><br><span class="line">        com = re.findall(findCom, item)</span><br><span class="line">        data[<span class="string">'com'</span>] = <span class="string">''</span>.join(com)</span><br><span class="line"></span><br><span class="line">        comlink = re.findall(findComLink, item)</span><br><span class="line">        data[<span class="string">'comlink'</span>] = <span class="string">''</span>.join(comlink)</span><br><span class="line"></span><br><span class="line">        salary = re.findall(findSalary, item)</span><br><span class="line">        data[<span class="string">'salary'</span>] = <span class="string">''</span>.join(salary)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        strhtml = <span class="string">'https://jobs.51job.com/'</span></span><br><span class="line">        <span class="keyword">if</span> data[<span class="string">"link"</span>].startswith(strhtml) <span class="keyword">and</span> data[<span class="string">'comlink'</span>].startswith(strhtml):</span><br><span class="line"></span><br><span class="line">            com_link = data[<span class="string">'comlink'</span>]</span><br><span class="line">            com_data = getCOM(com_link)</span><br><span class="line">            data = dict(data.items(), **com_data)</span><br><span class="line"></span><br><span class="line">            rec_link = data[<span class="string">'link'</span>]</span><br><span class="line">            recruit_data = getREC(rec_link)</span><br><span class="line">            data = dict(data.items(), **recruit_data)</span><br><span class="line">            datalist.append(data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> datalist</span><br></pre></td></tr></table></figure>
<p>爬取公司信息(getCOM)：获取公司链接内的信息，公司性质、公司规模、公司行业</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCOM</span><span class="params">(com_link)</span>:</span></span><br><span class="line">    com_html = askURL(com_link)</span><br><span class="line">    bs = BeautifulSoup(com_html, <span class="string">"html.parser"</span>)</span><br><span class="line">    <span class="comment"># 公司信息</span></span><br><span class="line">    CP_TYPE = [<span class="string">'民营公司'</span>, <span class="string">'上市公司'</span>, <span class="string">'事业单位'</span>, <span class="string">'国企'</span>, <span class="string">'外资（欧美）'</span>, <span class="string">'外资（非欧美）'</span>,</span><br><span class="line">               <span class="string">'创业公司'</span>, <span class="string">'政府机关'</span>, <span class="string">'合资'</span>, <span class="string">'外资'</span>, <span class="string">'合资'</span>, <span class="string">'外企代表处'</span>, <span class="string">'非营利组织'</span>]</span><br><span class="line">    CP_SCALE = [<span class="string">'少于50人'</span>, <span class="string">'50-150人'</span>, <span class="string">'150-500人'</span>, <span class="string">'500-1000人'</span>,</span><br><span class="line">                <span class="string">'1000-5000人'</span>, <span class="string">'5000-10000人'</span>, <span class="string">'10000人以上'</span>]</span><br><span class="line"></span><br><span class="line">    cp_info = bs.select(<span class="string">'.in &gt; p.ltype'</span>)[<span class="number">0</span>].text.split(<span class="string">'\xa0\xa0|\xa0\xa0'</span>)</span><br><span class="line">    com_data = &#123;&#125;</span><br><span class="line">    com_data[<span class="string">'cp_type'</span>] = com_data[<span class="string">'cp_scale'</span>] = com_data[<span class="string">'industry'</span>] = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> CP_TYPE:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> cp_info:</span><br><span class="line">            com_data[<span class="string">'cp_type'</span>] = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> CP_SCALE:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> cp_info:</span><br><span class="line">            com_data[<span class="string">'cp_scale'</span>] = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> cp_info:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> CP_TYPE <span class="keyword">and</span> i <span class="keyword">not</span> <span class="keyword">in</span> CP_SCALE:</span><br><span class="line">            com_data[<span class="string">'industry'</span>] = i</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> com_data</span><br></pre></td></tr></table></figure>
<p>爬取招聘信息(getREC)：获取招聘岗位链接内的信息，经验、学历、招聘人数、发布日期、工作描述</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getREC</span><span class="params">(rec_link)</span>:</span></span><br><span class="line">    jobHtml = askURL(rec_link)  <span class="comment">#获取详情页</span></span><br><span class="line">    bs = BeautifulSoup(jobHtml,<span class="string">"html.parser"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 经验、学历、招聘人数、发布日期</span></span><br><span class="line">    text = bs.select(<span class="string">".ltype"</span>)</span><br><span class="line">    job = &#123;&#125;</span><br><span class="line">    <span class="keyword">if</span> len(text) != <span class="number">0</span>:</span><br><span class="line">        info = text[<span class="number">0</span>].text.split(<span class="string">'\xa0\xa0|\xa0\xa0'</span>)</span><br><span class="line">        EDU = [<span class="string">'博士'</span>, <span class="string">'硕士'</span>, <span class="string">'本科'</span>, <span class="string">'大专'</span>,</span><br><span class="line">               <span class="string">'中专'</span>, <span class="string">'中技'</span>, <span class="string">'高中'</span>, <span class="string">'初中及以下'</span>]</span><br><span class="line"></span><br><span class="line">        job[<span class="string">'exp'</span>] = job[<span class="string">'edu'</span>] = job[<span class="string">'other'</span>] = job[<span class="string">'demand'</span>] = job[<span class="string">'pubdate'</span>] = <span class="string">" "</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> info:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'经验'</span> <span class="keyword">in</span> i:</span><br><span class="line">                job[<span class="string">'exp'</span>] = i</span><br><span class="line">            <span class="keyword">elif</span> i <span class="keyword">in</span> EDU:</span><br><span class="line">                job[<span class="string">'edu'</span>] = i</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">'招'</span> <span class="keyword">in</span> i:</span><br><span class="line">                job[<span class="string">'demand'</span>] = i</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">'发布'</span> <span class="keyword">in</span> i:</span><br><span class="line">                job[<span class="string">'pubdate'</span>] = i</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                job[<span class="string">'other'</span>] = i</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        job[<span class="string">'exp'</span>] = job[<span class="string">'edu'</span>] = job[<span class="string">'other'</span>] = job[<span class="string">'demand'</span>] = job[<span class="string">'pubdate'</span>] = <span class="string">" "</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    job[<span class="string">'msg'</span>] = <span class="string">" "</span></span><br><span class="line">    jobMsgList = bs.select(<span class="string">".job_msg &gt; p"</span>)  <span class="comment">#工作描述</span></span><br><span class="line">    jobMsgStr = <span class="string">""</span></span><br><span class="line">    <span class="keyword">for</span> str <span class="keyword">in</span> jobMsgList:</span><br><span class="line">        jobMsgStr = jobMsgStr + str.text</span><br><span class="line">    job[<span class="string">"msg"</span>] = jobMsgStr</span><br><span class="line"></span><br><span class="line">    <span class="comment"># jobList.append(job)</span></span><br><span class="line">    <span class="keyword">return</span> job</span><br></pre></td></tr></table></figure>

<p>数据存储(saveData)：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveDB</span><span class="params">(datalist, dbpath)</span>:</span></span><br><span class="line">    init_db(dbpath)</span><br><span class="line">    conn = sqlite3.connect(dbpath)</span><br><span class="line">    cur = conn.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> datalist:</span><br><span class="line">        print(data)</span><br><span class="line">        sql = <span class="string">'''</span></span><br><span class="line"><span class="string">                insert or ignore into job_quanguo(</span></span><br><span class="line"><span class="string">                link,title,comlink,com,area,salary,cp_type,cp_scale,industry,exp,edu,other,demand,pubdate,msg</span></span><br><span class="line"><span class="string">                 ) </span></span><br><span class="line"><span class="string">                 values(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)'''</span></span><br><span class="line">        <span class="comment"># print(sql)</span></span><br><span class="line">        cur.execute(sql,(data[<span class="string">'link'</span>],data[<span class="string">'title'</span>],data[<span class="string">'comlink'</span>],data[<span class="string">'com'</span>],data[<span class="string">'area'</span>],data[<span class="string">'salary'</span>],data[<span class="string">'cp_type'</span>],</span><br><span class="line">                         data[<span class="string">'cp_scale'</span>],data[<span class="string">'industry'</span>],data[<span class="string">'exp'</span>],data[<span class="string">'edu'</span>],data[<span class="string">'other'</span>],data[<span class="string">'demand'</span>],data[<span class="string">'pubdate'</span>],data[<span class="string">'msg'</span>]))</span><br><span class="line">        conn.commit()</span><br><span class="line">    cur.close()</span><br><span class="line">    conn.close()</span><br></pre></td></tr></table></figure>
<p>爬取结果：<br><img src="https://img-blog.csdnimg.cn/2020053115105068.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>一共爬取了7277条数据，包括：公司名称、链接、岗位名称、地区、薪水、企业性质、企业规模、行业、招聘要求、招聘信息等等。</p>
<h1 id="三、数据处理"><a href="#三、数据处理" class="headerlink" title="三、数据处理"></a>三、数据处理</h1><p>薪水处理：由于薪水是以上下限显示的，故将薪水分成三列，分别为下限，上限以及平均薪水。同时删除一部分没有显示薪水的信息。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getSalary</span><span class="params">()</span>:</span></span><br><span class="line">    datalist = []</span><br><span class="line">    con = sqlite3.connect(<span class="string">"51job.db"</span>)</span><br><span class="line">    cur = con.cursor()</span><br><span class="line">    sql = <span class="string">"SELECT com,title,area,cp_type,cp_scale,industry,exp,edu,salary FROM job_quanguo"</span></span><br><span class="line">    data_quanguo = cur.execute(sql)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> data_quanguo:</span><br><span class="line">        string = <span class="string">""</span>.join(item[<span class="number">8</span>])</span><br><span class="line">        <span class="keyword">if</span> string.endswith(<span class="string">'千/月'</span>):</span><br><span class="line">            num = string.replace(<span class="string">"千/月"</span>,<span class="string">""</span>).split(<span class="string">"-"</span>)</span><br><span class="line">            sal = pd.to_numeric(num)*<span class="number">1000</span></span><br><span class="line">            <span class="comment"># datalist.append(pd.to_numeric(num)*1000)</span></span><br><span class="line">            data1 = append_other(item)</span><br><span class="line">            data2 = append_salary(sal)</span><br><span class="line">        <span class="keyword">elif</span> string.endswith(<span class="string">'万/月'</span>):</span><br><span class="line">            num = string.replace(<span class="string">"万/月"</span>,<span class="string">""</span>).split(<span class="string">"-"</span>)</span><br><span class="line">            sal = pd.to_numeric(num)*<span class="number">10000</span></span><br><span class="line">            <span class="comment"># datalist.append(pd.to_numeric(num)*10000)</span></span><br><span class="line">            data1 = append_other(item)</span><br><span class="line">            data2 = append_salary(sal)</span><br><span class="line">        <span class="keyword">elif</span> string.endswith(<span class="string">'万/年'</span>):</span><br><span class="line">            num = string.replace(<span class="string">"万/年"</span>,<span class="string">""</span>).split(<span class="string">"-"</span>)</span><br><span class="line">            sal = pd.to_numeric(num)*<span class="number">10000</span>/<span class="number">12</span></span><br><span class="line">            <span class="comment"># datalist.append(pd.to_numeric(num)*10000/12)</span></span><br><span class="line">            <span class="comment"># append_other(item)</span></span><br><span class="line">            data1 = append_other(item)</span><br><span class="line">            data2 = append_salary(sal)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        data = dict(data1.items(), **data2)</span><br><span class="line">        datalist.append(data)</span><br><span class="line">    cur.close()</span><br><span class="line">    con.close()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># df_salary = pd.DataFrame(columns=['low-salary','high-salary'])</span></span><br><span class="line">    dbpath = <span class="string">"./51job.db"</span></span><br><span class="line">    saveDB(datalist, dbpath)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_salary</span><span class="params">(sal)</span>:</span></span><br><span class="line">    data1 = &#123;&#125;</span><br><span class="line">    data1[<span class="string">'low-salary'</span>] = sal[<span class="number">0</span>].astype(np.int64)</span><br><span class="line">    data1[<span class="string">'high-salary'</span>] = sal[<span class="number">1</span>].astype(np.int64)</span><br><span class="line">    data1[<span class="string">'avg-salary'</span>] = (sal[<span class="number">0</span>].astype(np.int64)+sal[<span class="number">1</span>].astype(np.int64))/<span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> data1</span><br></pre></td></tr></table></figure>

<h1 id="四、Flask与ECharts"><a href="#四、Flask与ECharts" class="headerlink" title="四、Flask与ECharts"></a>四、Flask与ECharts</h1><p>主要参考了ECharts官方文档，在此就不一一论述了。</p>
]]></content>
      <categories>
        <category>python</category>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>flask</tag>
        <tag>BeautifulSoup</tag>
      </tags>
  </entry>
  <entry>
    <title>用户行为分析（非原创）</title>
    <url>/2020/06/22/%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90%EF%BC%88%E9%9D%9E%E5%8E%9F%E5%88%9B%EF%BC%89/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200622184031885.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h2><p>用户行为分析是对用户在产品上产生的行为及行为背后的数据进行分析，通过构建用户行为模型和用户画像，来改变产品决策，实现精细化运营，指导业务增长。</p>
<p>在产品运营过程中，对用户行为的数据进行收集、存储、跟踪、分析与应用等，可以找到实现用户自增长的病毒因素、群体特征与目标用户。从而深度还原用户使用场景、操作规律、访问路径及行为特点等。</p>
<ul>
<li><input disabled="" type="checkbox"> 用户行为<br>用户行为是用户在产品上产生的行为。</li>
<li><input disabled="" type="checkbox"> 用户行为数据<br>常用的数据采集方式有：平台设置埋点和第三方统计工具。</li>
<li><input disabled="" type="checkbox"> 用户行为分析指标<br>主要分为三类：黏性指标、活跃指标和产出指标。<br><img src="https://img-blog.csdnimg.cn/20200622180444933.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
<li>粘性指标：主要关注用户周期内持续访问的情况，比如新用户数与比例、活跃用户数与比例、用户转化率、用户留存率、用户流失率、用户访问率。</li>
<li>活跃指标：主要考察的是用户访问的参与度，比如活跃用户、新增用户、回访用户、流失用户、平均停留时长、使用频率等。</li>
<li>产出指标：主要衡量用户创造的直接价值输出，比如页面浏览数PV、独立访客数UV、点击次数、消费频次、消费金额等。</li>
</ul>
<h2 id="2-目的"><a href="#2-目的" class="headerlink" title="2. 目的"></a>2. 目的</h2><ol>
<li>对产品而言，帮助验证产品的可行性，研究产品决策，清楚地了解用户的行为习惯，并找出产品的缺陷，以便需求的迭代与优化。</li>
<li>对设计而言，帮助增加体验的友好性，匹配用户情感，细腻地贴合用户的个性服务，并发现交互的不足，以便设计的完善与改进。</li>
<li>对运营而言，帮助裂变增长的有效性，实现精准营销，全面地挖掘用户的使用场景，并分析运营的问题，以便决策的转变与调整。</li>
</ol>
<p>另外，互联网人口红利的天花板让整个市场都进入存量的竞争阶段，大环境互联网获客成本高，需要提效。</p>
<h2 id="3-如何进行用户行为分析？"><a href="#3-如何进行用户行为分析？" class="headerlink" title="3. 如何进行用户行为分析？"></a>3. 如何进行用户行为分析？</h2><p><img src="https://img-blog.csdnimg.cn/20200622180609507.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-1-行为事件分析"><a href="#3-1-行为事件分析" class="headerlink" title="3.1 行为事件分析"></a>3.1 行为事件分析</h3><p>行为事件分析方法主要用于深度研究某行为事件，以及对产品的影响和影响程度。针对某一具体行为，全面的描述、对比，针对其异常表象 深度下钻分析各维度、确认导致该行为数据表现的原因。如快手的播放量徒增:</p>
<ol>
<li><p>同期对比分析：确认历史上是否有发生过，对比 去年/上个季度/上月/上周/昨日的 数据的相对表现。</p>
</li>
<li><p>多事件对比分析：对比浏览量、点赞、评论、分享事件的数据是否存在徒增。通过对比多个事件，确认徒增现象发生的范围。</p>
</li>
<li><p>维度下钻分析：</p>
<ul>
<li><input disabled="" type="checkbox"> 在快手哪个页面的播放量增加呢？是发现、关注、还是同城？-&gt; 对应页面做了哪些调整？是否增加了引流；</li>
<li><input disabled="" type="checkbox"> 哪一部分用户群的播放量增加了？交叉分析用户自然属性（平台、性别、年龄、地域、教育学历、机型、消费能力）、行为属性（新增、回流、常活跃用户；直播用户、短视频用户….）、视频属性（视频类型、作者类型….）</li>
</ul>
</li>
</ol>
<h3 id="3-2-留存分析"><a href="#3-2-留存分析" class="headerlink" title="3.2 留存分析"></a>3.2 留存分析</h3><p>留存是衡量用户是否再次使用产品的指标，也是每一个app赖以生存的指标，能够反映任何一款产品健康度，是产品、运营、推荐效果的整体表现。如果一个app从来没有留存用户，那DAU将永远是新增用户，那么产品将无法运行下去，更别说新用户成本付诸东流。</p>
<p>贴合业务属性、精细化留存过程 将对留存数据更有价值和指导意义。通过留存分析，能够剖析用户留在产品的原因，从而优化产品核心功能提升留存。</p>
<p>留存的类型：</p>
<ul>
<li><input disabled="" type="checkbox"> 用户留存：用户使用app后，经过一段时间仍旧使用。</li>
<li><input disabled="" type="checkbox"> 功能留存：用户使用xxx功能后，经过一段时间仍旧使用该功能，且其他功能均有所变化。此时，该功能对用户留存有正向作用。</li>
</ul>
<h3 id="3-3-漏斗分析"><a href="#3-3-漏斗分析" class="headerlink" title="3.3 漏斗分析"></a>3.3 漏斗分析</h3><p>漏斗分析实质是转化分析，是通过衡量每一个转化步骤的转化率，通过转化率的异常数据找出有问题的环节并解决，进而实现优化整个流程的完成率。</p>
<p>1）在产品初期(处于与市场适配的阶段)：</p>
<ul>
<li>通过漏斗分析找到用户触达的瓶颈，帮助用户触达产品核心价值，真实反映MVP与市场匹配程度；</li>
</ul>
<p>2）在产品中期(处于用户平稳增加的阶段):</p>
<ul>
<li>通过漏斗分析优化渠道，找到目标群体用户;</li>
<li>通过漏斗分析优化用户在各模块的体验(基础的登录模块、产品核心价值模块: 如抖音的播放模块、淘宝的购买模块等)；</li>
</ul>
<p>3）在产品后期(处于用户价值产出的阶段):</p>
<ul>
<li>通过漏斗分析可以改善用户生命周期(优化用户体验提高用户生命周期，间接拉长用户群体的价值产出的时间长度，减少高价值用户群体的流失)；</li>
<li>可以通过漏斗分析优化商业化模块，像商品的购买过程（购物车-提交订单的转化漏斗）、广告的曝光点击等，提高生命周期中单位时间产生的价值。</li>
</ul>
<h3 id="3-4-路径分析"><a href="#3-4-路径分析" class="headerlink" title="3.4 路径分析"></a>3.4 路径分析</h3><p>路径分析可以将纷杂的app日志按照用户的使用过程，呈现出“明确的”用户现存路径。发现路径问题，进而优化，使用户尽可能短路径体验到产品核心价值。</p>
<ul>
<li>通过路径分析，可以了解到像小明这样9点左右播放视频的用户：</li>
<li>他们是通过push点击而来，这部分用户占比是多少；</li>
<li>他们匆匆结束播放，再也没有下一步行为，这部分用户占比又有多少。</li>
</ul>
<p>针对他们利用碎片化时间播放视屏的场景，尤其是突然退出的场景，是否在下一次打开app时，仍旧打开终端的视频。是否有其他策略可以针对该场景来优化？<br>此外，路径分析不仅仅可以用于行为路径分析，也可以用于用户群体转化分析。例如：新用户中分别转化为 忠实用户、常活跃用户、潜在流失用户、流失用户的分析。</p>
<h3 id="3-5-福格模型分析"><a href="#3-5-福格模型分析" class="headerlink" title="3.5 福格模型分析"></a>3.5 福格模型分析</h3><p>福格行为模型是用来研究用户行为原因的分析模型。福格行为模型用公式来简化就是B=MAT，即B=MAT。B代表行为，M代表动机，A代表能力，T代表触发。它认为要让一个行为发生，必须同时具备三个元素：动机、能力和触发器。因此可以借助福格行为模型来评估产品的合理性和能否达到预期目标。<br><img src="https://img-blog.csdnimg.cn/20200622180758638.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>以活动分享为例，投资人完成活动分享的行为，也是必须满足福格行为模型的三个元素。即通过邀请有奖让用户有足够的内驱力，自主性的分享活动给好友，且活动专题页有醒目的按钮和文案提示激励用户完成任务。<br><img src="https://img-blog.csdnimg.cn/20200622180858754.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="3-6-用户分群分析"><a href="#3-6-用户分群分析" class="headerlink" title="3.6 用户分群分析"></a>3.6 用户分群分析</h3><p><img src="https://img-blog.csdnimg.cn/20200622173746756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 通过用户分群行为表现对比，可以进一步了解不同群体对产品的反馈，有针对性的优化产品。</p>
<ul>
<li>发现中、西南地区的低端机型使用app时，奔溃率特别高，开发可以针对该点进行优化、降低奔溃率；</li>
<li>可以针对不同的用户群体的行为表现 做 定向投放、push等，从而实现精细化运营。</li>
</ul>
<p>业内的商业化行为分析产品，基本上将用户画像的生成、标签的过程均合并在用户分群的群体定义中，降低了操作流程。</p>
<h2 id="4-用户行为分析的完整链路"><a href="#4-用户行为分析的完整链路" class="headerlink" title="4. 用户行为分析的完整链路"></a>4. 用户行为分析的完整链路</h2><p>以小明为case的用户行为每天数以万/亿计的产生，如何对“这类人群”进行“行为分析”？需要行为分析将明细级别的日志聚合后再以较为可读的形式展示出来。<br><img src="https://img-blog.csdnimg.cn/20200622173900460.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 为了保障行为数据分析有效，需要可靠的埋点、及时的数据上报、严谨的数据模型、清晰的可视化展示。一套完整的用户行为分析系统，需要覆盖 数据埋点设计、埋点开发、数据上报、数据模型开发、行为数据分析的 所有过程；过程中也需要多方协作完成。如何通过系统、流程等 保障多方协作中高效、便利的完成、产出具有业务价值的数据分析结论呢？后续将介绍 用户行为分析平台的搭建。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>用户行为分析是什么？怎么做？ <a href="http://www.woshipm.com/user-research/3661625.html" target="_blank" rel="noopener">http://www.woshipm.com/user-research/3661625.html</a><br>用户研究：如何做用户行为分析？ <a href="http://www.woshipm.com/user-research/3236774.html" target="_blank" rel="noopener">http://www.woshipm.com/user-research/3236774.html</a></p>
]]></content>
      <categories>
        <category>产品/运营</category>
      </categories>
      <tags>
        <tag>用户行为</tag>
      </tags>
  </entry>
  <entry>
    <title>运营指标</title>
    <url>/2020/06/22/%E8%BF%90%E8%90%A5%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200622160118760.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="商品"><a href="#商品" class="headerlink" title="商品"></a>商品</h2><p><img src="https://img-blog.csdnimg.cn/20200622160714145.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="营收"><a href="#营收" class="headerlink" title="营收"></a>营收</h2><p><img src="https://img-blog.csdnimg.cn/20200622161148322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="传播-活动"><a href="#传播-活动" class="headerlink" title="传播/活动"></a>传播/活动</h2><p><img src="https://img-blog.csdnimg.cn/20200622161407440.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="营销"><a href="#营销" class="headerlink" title="营销"></a>营销</h2><p><img src="https://img-blog.csdnimg.cn/20200622161650584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="用户获取"><a href="#用户获取" class="headerlink" title="用户获取"></a>用户获取</h2><p><img src="https://img-blog.csdnimg.cn/20200622162035539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="用户活跃"><a href="#用户活跃" class="headerlink" title="用户活跃"></a>用户活跃</h2><p><img src="https://img-blog.csdnimg.cn/20200622162101254.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="用户留存"><a href="#用户留存" class="headerlink" title="用户留存"></a>用户留存</h2><p><img src="https://img-blog.csdnimg.cn/20200622162124762.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
]]></content>
      <categories>
        <category>产品/运营</category>
      </categories>
      <tags>
        <tag>运营指标</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】机器学习系统的设计(Machine Learning System Design)</title>
    <url>/2020/07/15/%5BMachine%20Learning%5D%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1(Machine%20Learning%20System%20Design)/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200715144610243.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>

<h2 id="9-Machine-Learning-System-Design-机器学习系统的设计"><a href="#9-Machine-Learning-System-Design-机器学习系统的设计" class="headerlink" title="9 Machine Learning System Design(机器学习系统的设计)"></a>9 Machine Learning System Design(机器学习系统的设计)</h2><h3 id="9-1-Prioritizing-What-to-Work-On"><a href="#9-1-Prioritizing-What-to-Work-On" class="headerlink" title="9.1 Prioritizing What to Work On"></a>9.1 Prioritizing What to Work On</h3><p>例子：一个垃圾邮件分类器算法。</p>
<p>为了解决这样一个问题，首先要确定如何选择并表达特征向量𝑥。例如可以选择由 100 个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得特征向量（出现为 1，不出现为 0），尺寸为 100×1。<br><img src="https://img-blog.csdnimg.cn/2020071512515334.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>为了构建这个分类器算法，可以做很多事，例如：</p>
<ol>
<li>收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本</li>
<li>基于邮件的路由信息开发一系列复杂的特征</li>
<li>基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理</li>
<li>为探测刻意的拼写错误（把 watch 写成 w4tch）开发复杂的算法</li>
</ol>
<p>对于上面这些选项，难以决定应该在哪一项上花费时间和精力。不过当使用机器学习时，总是可以“头脑风暴”一下，想出一堆方法来试试，作出明智的选择，比随着感觉走要更好。</p>
<h3 id="9-2-Error-Analysis"><a href="#9-2-Error-Analysis" class="headerlink" title="9.2 Error Analysis"></a>9.2 Error Analysis</h3><p>构建一个学习算法的推荐方法为：</p>
<ol>
<li>构建一个简单并且能快速实现的算法，即便运行得不完美，但是也把它运行一遍，最后通过交叉验证来检验数据。</li>
<li>一旦做完，可以画出学习曲线，通过画出学习曲线，以及检验误差，来找出算法是否有高偏差和高方差的问题，或者别的问题。在这样分析之后，再来决定用更多的数据训练，或者加入更多的特征变量是否有用。</li>
<li>除了画出学习曲线之外，一件非常有用的事是误差分析。例如，当在构造垃圾邮件分类器时，看一看交叉验证数据集，然后亲自看一看哪些邮件被算法错误地分类。因此，通过这些被算法错误分类的垃圾邮件与非垃圾邮件，可以发现某些系统性的规律：什么类型的邮件总是被错误分类。思考怎样能改进分类器。例如，发现是否缺少某些特征，记下这些特征出现的次数。</li>
</ol>
<p>误差分析并不总能帮助我们判断应该采取怎样的行动。有时需要尝试不同的模型，然后进行比较，在模型比较时，用数值来判断哪一个模型更好更有效，通常是看交叉验证集的误差。</p>
<p>在垃圾邮件分类器例子中 ，对于“是否应该将 discount/discounts/discounted/discounting 处理成同一个词？”如果这样做可以改善算法，则会采用一些截词软件。误差分析并不能帮助做出这类判断，只能尝试采用和不采用截词软件这两种不同方案，然后根据数值检验的结果来判断哪一种更好。</p>
<p>推荐在交叉验证集上来实施误差分析，而不是在测试集上。</p>
<h3 id="9-3-Error-Metrics-for-Skewed-Classes-偏斜类的误差评估"><a href="#9-3-Error-Metrics-for-Skewed-Classes-偏斜类的误差评估" class="headerlink" title="9.3 Error Metrics for Skewed Classes(偏斜类的误差评估)"></a>9.3 Error Metrics for Skewed Classes(偏斜类的误差评估)</h3><p><label style="color:red">类偏斜（Skewed Classes）</label> 情况表现为训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例。例如以算法来预测癌症是否是恶性的，在训练集中，只有 0.5%的实例是恶性肿瘤。假设编写一个非学习的算法，在所有情况下都预测肿瘤是良性的，那么误差只有 0.5%。然而通过训练而得到的神经网络算法却有 1%的误差。这时，误差的大小是不能视为评判算法效果的依据的。</p>
<p><label style="color:red">查准率（Precision）和查全率（Recall）</label> 将算法预测的结果分成四种情况：</p>
<ol>
<li>正确肯定（True Positive,TP）：预测为真，实际为真</li>
<li>正确否定（True Negative,TN）：预测为假，实际为假</li>
<li>错误肯定（False Positive,FP）：预测为真，实际为假</li>
<li>错误否定（False Negative,FN）：预测为假，实际为真</li>
</ol>
<p>则：查准率=TP/(TP+FP)。例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。<br>查全率=TP/(TP+FN)。例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。</p>
<p>这样，对于我们刚才那个总是预测病人肿瘤为良性的算法，其查全率是 0。<br><img src="https://img-blog.csdnimg.cn/20200715134329675.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="9-4-Trading-Off-Precision-and-Recall-查准率和查全率之间的权衡"><a href="#9-4-Trading-Off-Precision-and-Recall-查准率和查全率之间的权衡" class="headerlink" title="9.4 Trading Off Precision and Recall(查准率和查全率之间的权衡)"></a>9.4 Trading Off Precision and Recall(查准率和查全率之间的权衡)</h3><p>在很多应用中，我们希望能够保证查准率和查全率的相对平衡。</p>
<p>继续沿用刚才预测肿瘤性质的例子。假使，算法输出的结果在 0-1 之间，使用阀值 0.5 来预测真和假。<br><img src="https://img-blog.csdnimg.cn/20200715140646134.PNG#pic_center" alt="在这里插入图片描述"></p>
<ul>
<li>查准率(Precision)=TP/(TP+FP) 。在所有预测有恶性肿瘤的病人中，实际上有恶 性肿瘤的病人的百分比，越高越好。</li>
<li>查全率(Recall)=TP/(TP+FN)。在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。</li>
<li>如果希望只在非常确信的情况下预测为真（肿瘤为恶性），即希望更高的查准率，可以使用比 0.5 更大的阀值，如0.7，0.9。这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。</li>
<li>如果希望提高查全率，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地 检查、诊断，可以使用比 0.5 更小的阀值，如 0.3。</li>
</ul>
<p>将不同阈值情况下，查全率与查准率的关系绘制成图表，曲线的形状根据数据的不同而不同：<br><img src="https://img-blog.csdnimg.cn/20200715141018277.PNG#pic_center" alt="在这里插入图片描述"><br>希望有一个帮助我们选择这个阈值的方法。<br><img src="https://img-blog.csdnimg.cn/20200715141425862.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>一种方法是计算 F1 值（F1 Score），其计算公式为：<br><img src="https://img-blog.csdnimg.cn/20200715141508777.png#pic_center" alt="在这里插入图片描述"><br>选择使得 F1 值最高的阀值。</p>
<h3 id="9-5-Data-For-Machine-Learning"><a href="#9-5-Data-For-Machine-Learning" class="headerlink" title="9.5 Data For Machine Learning"></a>9.5 Data For Machine Learning</h3><p>例：希望通过机器学习算法来区分常见的易混淆的单词，尝试了许多种不同的算法，发现数据量非常大时，这些不同类型的算法效果都很好。<br><img src="https://img-blog.csdnimg.cn/20200715143139923.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>如上折线图所示，首先大部分算法，都具有相似的性能，其次，随着训练数据集的增大，在横轴上代表以百万为单位的训练集大小，从 0.1 个百万到 1000 百万，也就是到了 10亿规模的训练集的样本，这些算法的性能也都对应地增强了。</p>
<p>事实上，如果选择任意一个算法，可能是选择了一个”劣等的”算法，如果给这个劣等算法更多的数据，那么从这些例子中看起来的话，它看上去很有可能会其他算法更好，甚至会比”优等算法”更好。像这样的结果，引起了一种在机器学习中的普遍共识：”取得成功的人不是拥有最好算法的人，而是拥有最多数据的人”。</p>
<p>另一种考虑这个问题的角度是为了有一个高性能的学习算法，希望它不要有高的偏差和方差。因此偏差问题，将通过确保有一个具有很多参数的学习算法来解决，以便能够得到一个较低偏差的算法，并且通过用非常大的训练集来保证。<br><img src="https://img-blog.csdnimg.cn/20200715144013603.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>在此没有方差问题，这算法将没有方差，并且通过将这两个值放在一起，最终可以得到一个低误差和低方差的学习算法，能够很好地测试测试数据集。从根本上来说，这是一个关键的假设：特征值有足够的信息量，且有一类很好的函数，这是为什么能保证低误差的关键所在。它有大量的训练数据集，这能保证得到更多的方差值，因此这提出了一些可能的条件，如果你有大量的数据，而且你训练了一种带有很多参数的学习算法，那么这将会是一个很好的方式，来提供一个高性能的学习算法。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Skewed Classes</tag>
      </tags>
  </entry>
  <entry>
    <title>【Machine Learning】概述</title>
    <url>/2020/07/05/%5BMachine%20Learning%5D%20%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20200705203342231.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<a id="more"></a>


<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1 概述"></a>1 概述</h2><p>机器学习即在进行特定编程的情况下，使用计算机作为工具并致力于真实实时的模拟人类学习方式， 并将现有内容进行知识结构划分来有效提高学习效率。</p>
<p>根据训练数据是否拥有标记信息，学习任务可大致分为：“监督学习”、“无监督学习”。可理解为，监督学习这个想法是指我们将教计算机如何去完成任务；而在无监督学习中我们打算让它自己进行学习。分类和回归是前者的代表，聚类是后者的代表。</p>
<h3 id="1-1-Learning-Map"><a href="#1-1-Learning-Map" class="headerlink" title="1.1 Learning Map"></a>1.1 Learning Map</h3><p>蓝色方块指的是scenario，即学习的情境。通常学习的情境是我们没有办法控制的，比如做reinforcement Learning是因为我们没有data、没有办法来做supervised Learning的情况下才去做的。如果有data，supervised Learning当然比reinforcement Learning要好；因此手上有什么样的data，就决定你使用什么样的scenario。</p>
<p>红色方块指的是task，即要解决的问题。你要解的问题，随着你要找的function的output的不同，有输出scalar的regression、有输出options的classification、有输出structured object的structured Learning…</p>
<p>绿色的方块指的是model，即用来解决问题的模型(function set)。在这些task里面有不同的model，也就是说，同样的task，我们可以用不同的方法来解它，比如linear model、Non-linear model(deep Learning、SVM、decision tree、K-NN…)</p>
<p><img src="https://img-blog.csdnimg.cn/20200704201834783.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="&lt;img src=&quot;https://github.com/Sakura-gh/ML-notes/blob/master/img/learningMap.png?raw=true&quot; alt=&quot;learning map&quot; style=&quot;width: 60%;&quot; /&gt;"></p>
<h3 id="1-2-Supervised-Learning-监督学习"><a href="#1-2-Supervised-Learning-监督学习" class="headerlink" title="1.2 Supervised Learning(监督学习)"></a>1.2 Supervised Learning(监督学习)</h3><p>supervised learning 需要大量的training data，这些training data要求我们找到function，当这个function看到某种input则输出a，看到另一种input输出b，看到……</p>
<p>而这种function的output，通常被叫做==label(标签)==，也就是说，我们要使用supervised learning这样一种技术，我们需要告诉机器，function的input和output分别是什么，而这种output通常是通过人工的方式标注出来的，因此称为人工标注的label，它的缺点是需要大量的人工effort。</p>
<h4 id="1-2-1-Case1-Housing-price-prediction"><a href="#1-2-1-Case1-Housing-price-prediction" class="headerlink" title="1.2.1 Case1: Housing price prediction"></a>1.2.1 Case1: Housing price prediction</h4><p>通过收集的房价数据绘制如下图，那基于这组数据，若有一套 750 平方英尺房子，那么这房子能卖多少钱。</p>
<p>关于这个问题，机器学习算法将会怎么帮助你呢？<br><img src="https://img-blog.csdnimg.cn/20200705162412478.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>应用学习算法，可以在这组数据中画一条直线，即==拟合一条直线==，根据这条线我们可以推测出，这套房子可能卖$150,000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，==用二次方程去拟合==可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200,000。稍后我们将讨论如何选择学习算法，如何决定用直线还是二次方程来拟合。两个方案中有一个能让你朋友的房子出售得更合理。这些都是学习算法里面很好的例子。以上就是监督学习的例子。</p>
<p>可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做==回归问题 (Regression)==。我们试着推测出一个连续值的结果，即房子的价格。</p>
<blockquote>
<p>regression是machine learning的一个task，特点是通过regression找到的function，它的输出是一个scalar数值。<br>比如PM2.5的预测，给machine的training data是过去的PM2.5资料，而输出的是对未来PM2.5的预测<strong>数值</strong>，这就是一个典型的regression的问题。</p>
</blockquote>
<p>一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。</p>
<h4 id="1-2-2-Case2-Breast-cancer-malignant-benign"><a href="#1-2-2-Case2-Breast-cancer-malignant-benign" class="headerlink" title="1.2.2 Case2: Breast cancer (malignant,benign)"></a>1.2.2 Case2: Breast cancer (malignant,benign)</h4><p>现有有 5 个良性肿瘤样本（O），5 个恶性肿瘤样本（X）。假设已知一个肿瘤的尺寸，那么机器学习的工作就在于能否估算出肿瘤是恶性的或是良性的概率。<br><img src="https://img-blog.csdnimg.cn/20200705163240876.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>用术语来讲，这是一个==分类问题 (Classification)==。分类指的是，我们试着推测出离散的输出值：0 或 1 良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出 0、1、2、3。0 代表良性，1 表示第 1 类乳腺癌，2 表示第 2 类癌症，3 表示第 3 类，但这也是分类问题。</p>
<blockquote>
<p>regression和classification的区别是，我们要机器输出的东西的类型是不一样的，在regression里机器输出的是scalar（标量），而classification又分为两类：Binary Classification(二元分类)、Multi-class classification(多元分类)。<br><strong>在binary classification里</strong>，我们要机器输出的是yes or no，是或否。比如G-mail的spam filtering(垃圾邮件过滤器)，输入是邮件，输出是该邮件是否是垃圾邮件。<br><strong>在multi-class classification里</strong>，机器要做的是选择题，等于给他数个选项，每一个选项就是一个类别，它要从数个类别里面选择正确的类别。比如document classification(新闻文章分类)，输入是一则新闻，输出是这个新闻属于哪一个类别(选项)。</p>
</blockquote>
<p>在其它机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。</p>
<p><img src="https://img-blog.csdnimg.cn/20200705164946740.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"><br>上图中，总共列举了 5 种不同的特征，坐标轴上的两种和右边的 3 种，但在一些学习问题上需要使用多种特征甚至无限，好让算法可以利用大量的特征，或者说线索来做推测。那如何处理无限多个特征，甚至如何存储这些特征都存在问题，你电脑的内存肯定不够用。我们以后会讲一个算法，叫==支持向量机==，里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。</p>
<p>现在来回顾一下，这节课我们介绍了监督学习。其基本思想是，我们数据集中的每个样本都有相应的“正确答案”。再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。</p>
<p>我们还介绍了回归问题，即通过回归来推出一个连续的输出，之后我们介绍了分类问题，其目标是推出一组离散的结果。</p>
<h3 id="1-3-Unsupervised-Learning-无监督学习"><a href="#1-3-Unsupervised-Learning-无监督学习" class="headerlink" title="1.3 Unsupervised Learning(无监督学习)"></a>1.3 Unsupervised Learning(无监督学习)</h3><p>区别于supervised learning，unsupervised learning希望机器学到无师自通，在完全没有任何label的情况下，机器到底能学到什么样的知识。</p>
<p><img src="https://img-blog.csdnimg.cn/20200705192208335.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>在无监督学习中，已知的数据不同于监督学习的数据，无监督学习中没有任何的标签或者是有相同的标签或者就是没标签。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做==聚类算法（Clustering Algorithm）==。</p>
<p>聚类应用的一个例子就是在谷歌新闻中。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起，显示到一起。</p>
<h4 id="1-3-1-Case-Cocktail-party-problem-algorithm"><a href="#1-3-1-Case-Cocktail-party-problem-algorithm" class="headerlink" title="1.3.1 Case: Cocktail party problem algorithm"></a>1.3.1 Case: Cocktail party problem algorithm</h4><p>在鸡尾酒宴上，人们都在聊天，这么多人同时在聊天，声音彼此重叠，所以可能会发生两个人同时都在说话的情形。现假设在一个小型鸡尾酒宴上，房间中有两个麦克风，因为这些麦克风在两个地方，每个麦克风记录下不同的声音，两份录音被叠加到一起，或是被归结到一起，产生了我们现在的这些录音。</p>
<p>为区分出两个音频资源，似乎需要写大量复杂的代码或链接到一堆的合成器 JAVA 库。事实上，只要一行代码即可完成。</p>
<p>[W,s,v] = svd((repmat(sum(x.<em>x,1),size(x,1),1).</em>x)*x’);</p>
<h3 id="1-4-Semi-supervised-Learning-半监督学习"><a href="#1-4-Semi-supervised-Learning-半监督学习" class="headerlink" title="1.4 Semi-supervised Learning(半监督学习)"></a>1.4 Semi-supervised Learning(半监督学习)</h3><p>举例：如果想要做一个区分猫和狗的function。手头上有少量的labeled data，它们标注了图片上哪只是猫哪只是狗；同时又有大量的unlabeled data，它们仅仅只有猫和狗的图片，但没有标注去告诉机器哪只是猫哪只是狗。</p>
<p>在Semi-supervised Learning的技术里面，这些没有labeled的data，对机器学习也是有帮助的。</p>
<h3 id="1-5-Transfer-Learning-迁移学习"><a href="#1-5-Transfer-Learning-迁移学习" class="headerlink" title="1.5 Transfer Learning(迁移学习)"></a>1.5 Transfer Learning(迁移学习)</h3><p>假设一样我们要做猫和狗的分类问题。我们也一样只有少量的有labeled的data；但是我们现在有大量的不相干的data(不是猫和狗的图片，而是一些其他不相干的图片)，在这些大量的data里面，它可能有label也可能没有label。</p>
<p>Transfer Learning要解决的问题是，这一堆不相干的data可以对结果带来什么样的帮助。</p>
<p><img src="https://img-blog.csdnimg.cn/2020070520234656.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-6-Structured-Learning-结构化学习"><a href="#1-6-Structured-Learning-结构化学习" class="headerlink" title="1.6 Structured Learning(结构化学习)"></a>1.6 Structured Learning(结构化学习)</h3><p>在structured Learning里，我们要机器输出的是，一个有结构性的东西。</p>
<p>在分类的问题中，机器输出的只是一个选项；在structured类的problem里面，机器要输出的是一个复杂的物件。举例来说，在语音识别的情境下，机器的输入是一个声音信号，输出是一个句子；句子是由许多词汇拼凑而成，它是一个有结构性的object；或者说机器翻译、人脸识别(标出不同的人的名称)。</p>
<p>比如<strong>GAN</strong>也是structured Learning的一种方法。</p>
<p><img src="https://img-blog.csdnimg.cn/20200705203242595.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<h3 id="1-7-Reinforcement-Learning-强化学习"><a href="#1-7-Reinforcement-Learning-强化学习" class="headerlink" title="1.7 Reinforcement Learning(强化学习)"></a>1.7 Reinforcement Learning(强化学习)</h3><p><strong>Supervised Learning</strong>：我们会告诉机器正确的答案是什么 ，其特点是<strong>Learning from teacher</strong>。</p>
<ul>
<li>比如训练一个聊天机器人，告诉他如果使用者说了“Hello”，你就说“Hi”；如果使用者说了“Bye bye”，你就说“Good bye”；就好像有一个家教在它的旁边手把手地教他每一件事情。</li>
</ul>
<p><strong>Reinforcement Learning</strong>：我们没有告诉机器正确的答案是什么，机器最终得到的只有一个分数，就是它做的好还是不好，但他不知道自己到底哪里做的不好，他也没有正确的答案；很像真实社会中的学习，你没有一个正确的答案，你只知道自己是做得好还是不好。其特点是<strong>Learning from critics</strong>。</p>
<ul>
<li>比如训练一个聊天机器人，让它跟客人直接对话；如果客人勃然大怒把电话挂掉了，那机器就学到一件事情，刚才做错了，它不知道自己哪里做错了，必须自己回去反省检讨到底要如何改进，比如一开始不应该打招呼吗？还是中间不能骂脏话之类的。</li>
</ul>
<p><img src="https://img-blog.csdnimg.cn/20200705202235316.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTM5OTA3NA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>拿下棋这件事举例，supervised Learning是说看到眼前这个棋盘，告诉机器下一步要走什么位置；而reinforcement Learning是说让机器和对手互弈，下了好几手之后赢了，机器就知道这一局棋下的不错，但是到底哪一步是赢的关键，机器是不知道的，他只知道自己是赢了还是输了。</p>
<p>其实Alpha Go是用supervised Learning+reinforcement Learning的方式去学习的，机器先是从棋谱学习，有棋谱就可以做supervised的学习；之后再做reinforcement Learning，机器的对手是另外一台机器，Alpha Go就是和自己下棋，然后不断的进步。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
</search>
